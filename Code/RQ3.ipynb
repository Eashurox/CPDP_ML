{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e3caeff-2799-42e1-9dc4-b41bdf54e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score \n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa59903-92de-4779-bf3b-8620be8e5e45",
   "metadata": {},
   "source": [
    "# Domain Adaptation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d272491-8eb6-4c48-b2e2-65f7147cc0f9",
   "metadata": {},
   "source": [
    "## Bruakfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd9f1deb-e04a-4317-8d0e-d7efb9c6409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bruakfilter(object):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        Xsource = np.log(Xsource + 1)\n",
    "        Xtarget = np.log(Xtarget + 1)\n",
    "\n",
    "        if self.n_neighbors > Xsource.shape[0]:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        knn = NearestNeighbors()\n",
    "        knn.fit(Xsource)\n",
    "        data = []\n",
    "        ysel = []\n",
    "\n",
    "        for item in Xtarget:\n",
    "            tmp = knn.kneighbors(item.reshape(1, -1), self.n_neighbors, return_distance=False)\n",
    "            tmp = tmp[0]\n",
    "            for i in tmp:\n",
    "                if list(Xsource[i]) not in data:\n",
    "                    data.append(list(Xsource[i]))\n",
    "                    ysel.append(Ysource[i])\n",
    "        Xsource = np.asanyarray(data)\n",
    "        Ysource = np.asanyarray(ysel)\n",
    "\n",
    "        return Xsource, Ysource, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c7dc7-5f10-4a3e-9b67-16f4b82d51ed",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be4d3af9-331e-48ce-ae15-3ecd7cae3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSelection(object):\n",
    "    def __init__(self, topN=5, FSS=0.2):\n",
    "        self.topN = topN\n",
    "        self.FSS = FSS\n",
    "\n",
    "    def _sample(self, Xsource, Xtarget):\n",
    "        K = min(500, Xsource.shape[0], Xtarget.shape[0])\n",
    "        Ltrain = np.ones(K)\n",
    "        Ltest = np.ones(K) * -1\n",
    "\n",
    "        Train = random.sample(range(Xsource.shape[0]), Xsource.shape[0] - K)\n",
    "        Test = random.sample(range(Xtarget.shape[0]), Xtarget.shape[0] - K)\n",
    "        Train = np.delete(Xsource, Train, axis=0)\n",
    "        Test = np.delete(Xtarget, Test, axis=0)\n",
    "\n",
    "        data = np.concatenate((Train, Test), axis=0)\n",
    "        label = np.concatenate((Ltrain, Ltest), axis=0)\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def _calDistance(self, Xsource, Xtarget):\n",
    "        acc = np.zeros(10)\n",
    "        for i in range(10):\n",
    "            x, y = self._sample(Xsource, Xtarget)\n",
    "            lr = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "            acc[i] = np.mean(cross_val_score(lr, x, y, scoring='accuracy', cv=5))\n",
    "        return 2 * abs((np.mean(acc) - 0.5))\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget, loc):\n",
    "        self.topN = min(self.topN, len(loc))\n",
    "        dist = dict()\n",
    "\n",
    "        for i in range(len(loc)):\n",
    "            if i < len(loc) - 1:\n",
    "                train = Xsource[loc[i]:loc[i + 1]]\n",
    "                dist[i] = self._calDistance(train, Xtarget)\n",
    "            else:\n",
    "                train = Xsource[loc[i]:]\n",
    "                dist[i] = self._calDistance(train, Xtarget)\n",
    "\n",
    "        dist = sorted(dist.items(), key=lambda d: d[1])\n",
    "        i = dist[0][0]\n",
    "        if i != len(loc) - 1:\n",
    "            x = Xsource[loc[i]:loc[i + 1] ]\n",
    "            y = Ysource[loc[i]:loc[i + 1] ]\n",
    "        else:\n",
    "            x = Xsource[loc[i]:]\n",
    "            y = Ysource[loc[i]:]\n",
    "\n",
    "        for i in range(1, self.topN):\n",
    "            index = dist[i][0]\n",
    "            if index < len(loc) - 1:\n",
    "                tmp = Xsource[loc[index]:loc[index + 1] ]\n",
    "                temp = Ysource[loc[index]:loc[index + 1] ]\n",
    "            else:\n",
    "                tmp = Xsource[loc[index]:]\n",
    "                temp = Ysource[loc[index]:]\n",
    "            x = np.concatenate((x, tmp), axis=0)\n",
    "            y = np.concatenate((y, temp), axis=0)\n",
    "\n",
    "        fx, fy = self._sample(x, Xtarget)\n",
    "        lr = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "        lr.fit(fx, fy)\n",
    "        coef = dict()\n",
    "        for i in range(Xsource.shape[1]):\n",
    "            coef[i] = lr.coef_[0][i]\n",
    "        coef = sorted(coef.items(), key=lambda d: d[1], reverse=True)\n",
    "\n",
    "        dump = []\n",
    "        for i in range(int(Xsource.shape[1] * self.FSS)):\n",
    "            dump.append(coef[i][0])\n",
    "\n",
    "        x = np.delete(x, dump, axis=1)\n",
    "        Xtarget = np.delete(Xtarget, dump, axis=1)\n",
    "\n",
    "        return x, y, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34012be4-1315-4840-bc1d-e6ac43e090ac",
   "metadata": {},
   "source": [
    "## DSBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da175696-90a9-49ff-bb76-7d7f8ab15e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSBF\n",
    "class DSBF(object):\n",
    "    def __init__(self, topK=1, neighbors=10):\n",
    "        self.topK = int(topK)\n",
    "        self.neighbors = neighbors\n",
    "\n",
    "    def featureReduction(self, source, target):\n",
    "        d = pdist(target.T, metric='euclidean')\n",
    "        D = squareform(d)\n",
    "        dist = D.copy()\n",
    "        D = np.zeros(D.shape)\n",
    "\n",
    "        for i in range(target.shape[1]):\n",
    "            index = np.argsort(dist[i])\n",
    "            count = 0\n",
    "            for j in range(len(index)):\n",
    "                if count < self.topK and index[j] != i:\n",
    "                    D[i][index[j]] = 1\n",
    "                    count += 1\n",
    "\n",
    "        V = np.sum(D, axis=0)\n",
    "        V[V < 1e-6] = 0\n",
    "        index = np.where(V != 0)\n",
    "        target = np.delete(target, index, axis=1)\n",
    "        source = np.delete(source, index, axis=1)\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    def outlierRemove(self, target, ys):\n",
    "        d = pdist(target, metric='euclidean')\n",
    "        D = squareform(d)\n",
    "        dist = D.copy()\n",
    "        D = np.zeros(D.shape)\n",
    "        for i in range(target.shape[0]):\n",
    "            index = np.argsort(dist[i])\n",
    "            count = 0\n",
    "            for j in range(len(index)):\n",
    "                if count < self.topK and index[j] != i:\n",
    "                    D[i][index[j]] = 1\n",
    "                    count += 1\n",
    "        V = np.sum(D, axis=0)\n",
    "        V[V < 1e-6] = 0\n",
    "        index = np.where(V == 0)\n",
    "        target = np.delete(target, index, axis=0)\n",
    "        ys = np.delete(ys, index, axis=0)\n",
    "        return target, ys\n",
    "\n",
    "    def Bruakfilter(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        Xsource = np.log(Xsource + 1)\n",
    "        Xtarget = np.log(Xtarget + 1)\n",
    "\n",
    "        if self.neighbors > Xsource.shape[0]:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        knn = NearestNeighbors()\n",
    "        knn.fit(Xsource)\n",
    "        data = []\n",
    "        ysel = []\n",
    "\n",
    "        for item in Xtarget:\n",
    "            tmp = knn.kneighbors(item.reshape(1, -1), self.neighbors, return_distance=False)\n",
    "            tmp = tmp[0]\n",
    "            for i in tmp:\n",
    "                if list(Xsource[i]) not in data:\n",
    "                    data.append(list(Xsource[i]))\n",
    "                    ysel.append(Ysource[i])\n",
    "        Xsource = np.asanyarray(data)\n",
    "        Ysource = np.asanyarray(ysel)\n",
    "\n",
    "        return Xsource, Ysource, Xtarget, Ytarget\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        Xsource, Xtarget = self.featureReduction(Xsource, Xtarget)\n",
    "        if Xsource.shape[1] == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xsource, Ysource = self.outlierRemove(Xsource, Ysource)\n",
    "        if len(Xsource) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xtarget, Ytarget = self.outlierRemove(Xtarget, Ytarget)\n",
    "        if len(Xtarget) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xsource, Ysource, Xtarget, Ytarget = self.Bruakfilter(Xsource, Ysource, Xtarget, Ytarget)\n",
    "        if len(Xsource) == 0 or len(Xtarget) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xsource, Ysource = self.outlierRemove(Xsource, Ysource)\n",
    "        if len(Xsource) == 0 or len(Xtarget) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        return Xsource, Ysource, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c0cfc-a150-4e1a-8087-55e8f1de1001",
   "metadata": {},
   "source": [
    "## DTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f46f7ff-cfe4-4b42-aedd-74967c613bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTB(object):\n",
    "    def __init__(self, n_neighbors=10, iter=20):\n",
    "        self.n_neighbors = int(n_neighbors)\n",
    "        self.iter = iter\n",
    "\n",
    "    def _NNfilter(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        knn = NearestNeighbors()\n",
    "        knn.fit(Xsource)\n",
    "        data = []\n",
    "        ysel = []\n",
    "\n",
    "        for item in Xtarget:\n",
    "            tmp = knn.kneighbors(item.reshape(1, -1), self.n_neighbors, return_distance=False)\n",
    "            tmp = tmp[0]\n",
    "            for i in tmp:\n",
    "                if list(Xsource[i]) not in data:\n",
    "                    data.append(list(Xsource[i]))\n",
    "                    ysel.append(Ysource[i])\n",
    "        Xsource = np.asanyarray(data)\n",
    "        Ysource = np.asanyarray(ysel)\n",
    "        return Xsource, Ysource\n",
    "\n",
    "    # oversample for minor part\n",
    "    def _SMOTE(self, Xsource, Ysource):\n",
    "        smote = SMOTE()\n",
    "        Xsource, Ysource = smote.fit_resample(Xsource, Ysource)\n",
    "        return Xsource, Ysource\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "      Xsource, Ysource = self._NNfilter(Xsource, Ysource, Xtarget, Ytarget)\n",
    "      Xsource, Ysource = self._SMOTE(Xsource, Ysource)\n",
    "      return Xsource, Ysource, Xtarget, Ytarget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a235e8-eae3-48e5-8f49-5b002fb45c4d",
   "metadata": {},
   "source": [
    "## Peterfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a65ea891-7fea-4e55-82a7-807c0c377b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Peterfilter(object):\n",
    "    def __init__(self, eachCluster=50):\n",
    "        self.eachCluster = eachCluster\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        self.Xsource = Xsource\n",
    "        self.Xtarget = Xtarget\n",
    "        self.Ysource = Ysource\n",
    "        self.Ytarget = Ytarget\n",
    "        data = np.concatenate((self.Xsource, self.Xtarget), axis=0)\n",
    "        if self.eachCluster == 0:\n",
    "            return 0,0,0,0\n",
    "        n_cluster = int(self.Xsource.shape[0] / self.eachCluster)\n",
    "        if n_cluster == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        kmeans = KMeans(n_clusters=n_cluster)\n",
    "        kmeans.fit(data)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # remove the clusters where have no test instance\n",
    "        cluster = dict()\n",
    "        for i in range(n_cluster):\n",
    "            cluster[i] = []\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            cluster[labels[i]].append(i)\n",
    "\n",
    "        chosenCluster = []\n",
    "        for i in range(self.Xsource.shape[0], data.shape[0]):\n",
    "            for j in range(n_cluster):\n",
    "                if i in cluster[j] and (j not in chosenCluster):\n",
    "                    chosenCluster.append(j)\n",
    "\n",
    "        # choose train instance in each cluster\n",
    "        out = []\n",
    "        for i in range(len(chosenCluster)):\n",
    "            test = []\n",
    "            indexTest = []\n",
    "            train = []\n",
    "            indexTrain = []\n",
    "            for item in cluster[chosenCluster[i]]:\n",
    "                if item >= self.Xsource.shape[0] and item < data.shape[0]:\n",
    "                    test.append(list(data[item]))\n",
    "                    indexTest.append(item)\n",
    "                else:\n",
    "                    train.append(list(self.Xsource[item]))\n",
    "                    indexTrain.append(item)\n",
    "\n",
    "            if len(train) == 0:\n",
    "                break\n",
    "            Testfans = np.zeros((len(indexTest), len(indexTrain)))\n",
    "\n",
    "            neigh = NearestNeighbors(n_neighbors=1)\n",
    "            neigh.fit(np.asarray(test))\n",
    "            for item in train:\n",
    "                index = neigh.kneighbors(np.asarray(item).reshape(1, -1), return_distance=False)\n",
    "                Testfans[index[0][0], train.index(item)] += 1\n",
    "\n",
    "            for i in range(len(test)):\n",
    "                index = np.argmax(Testfans[i])\n",
    "                if indexTrain[index] not in out:\n",
    "                    out.append(indexTrain[index])\n",
    "\n",
    "        tmp = np.zeros((len(out), self.Xsource.shape[1]))\n",
    "        tmpl = np.zeros(len(out))\n",
    "        for i in range(len(out)):\n",
    "            tmp[i] = self.Xsource[out[i]]\n",
    "            tmpl[i] = self.Ysource[out[i]]\n",
    "\n",
    "        return tmp, tmpl, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9638f7b-6f14-4615-aab9-445c2755006d",
   "metadata": {},
   "source": [
    "## TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3538dcb-14cc-4364-923a-d69b7893d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(ker, X, X2, gamma):\n",
    "    if not ker or ker == 'primal':\n",
    "        return X\n",
    "    elif ker == 'linear':\n",
    "        if not X2:\n",
    "            K = np.dot(X.T, X)\n",
    "        else:\n",
    "            K = np.dot(X.T, X2)\n",
    "    elif ker == 'rbf':\n",
    "        n1sq = np.sum(X ** 2, axis=0)\n",
    "        n1 = X.shape[1]\n",
    "        if not X2:\n",
    "            D = (np.ones((n1, 1)) * n1sq).T + np.ones((n1, 1)) * n1sq - 2 * np.dot(X.T, X)\n",
    "        else:\n",
    "            n2sq = np.sum(X2 ** 2, axis=0)\n",
    "            n2 = X2.shape[1]\n",
    "            D = (np.ones((n2, 1)) * n1sq).T + np.ones((n1, 1)) * n2sq - 2 * np.dot(X.T, X)\n",
    "        K = np.exp(-gamma * D)\n",
    "    elif ker == 'sam':\n",
    "        if not X2:\n",
    "            D = np.dot(X.T, X)\n",
    "        else:\n",
    "            D = np.dot(X.T, X2)\n",
    "        K = np.exp(-gamma * np.arccos(D) ** 2)\n",
    "        K[K != K] = 0\n",
    "    return K\n",
    "\n",
    "\n",
    "class TCA(object):\n",
    "    def __init__(self, kernel_type='primal', dim=5, lamb=1, gamma=1):\n",
    "        '''\n",
    "        Init func\n",
    "        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf' | 'sam'\n",
    "        :param dim: dimension after transfer\n",
    "        :param lamb: lambda value in equation\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.dim = dim\n",
    "        self.lamb = lamb\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _normalization(self, type):\n",
    "        ss = self.Xsource.shape\n",
    "        tt = self.Xtarget.shape\n",
    "\n",
    "        if type == 'N1':\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                minm = np.min(tmp)\n",
    "                maxm = np.max(tmp)\n",
    "                res[:, i] = (tmp - minm) / (maxm - minm)\n",
    "            self.Xsource = res\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                minm = np.min(tmp)\n",
    "                maxm = np.max(tmp)\n",
    "                res[:, i] = (tmp - minm) / (maxm - minm)\n",
    "            self.Xtarget = res\n",
    "\n",
    "        elif type == 'N2':\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xsource = res\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xtarget = res\n",
    "\n",
    "        elif type == 'N3':\n",
    "            Smean = []\n",
    "            Sstd = []\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                Smean.append(mean)\n",
    "                Sstd.append(std)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xsource = res\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                mean = Smean[i]\n",
    "                std = Sstd\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xtarget = res\n",
    "\n",
    "        elif type == 'N4':\n",
    "            Smean = []\n",
    "            Sstd = []\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                Smean.append(mean)\n",
    "                Sstd.append(std)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xtarget = res\n",
    "\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                mean = Smean[i]\n",
    "                std = Sstd\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xsource = res\n",
    "\n",
    "        elif type == 'N0':\n",
    "            return\n",
    "\n",
    "    def _computDCV(self):\n",
    "        ss = self.Xsource.shape\n",
    "        tt = self.Xtarget.shape\n",
    "        Sdist = []\n",
    "        Tdist = []\n",
    "        SDCV = []\n",
    "        TDCV = []\n",
    "\n",
    "        # compute DCV (dataset characteristic vector) of source dataset\n",
    "        for i in range(ss[0]):\n",
    "            for j in range(i + 1, ss[0]):\n",
    "                Sdist.append(dist.euclidean(self.Xsource[i], self.Xsource[j]))\n",
    "        SDCV.append(np.mean(np.asarray(Sdist)))\n",
    "        SDCV.append((np.median(np.asarray(Sdist))))\n",
    "        SDCV.append(np.min(np.asarray(Sdist)))\n",
    "        SDCV.append(np.max(np.asarray(Sdist)))\n",
    "        SDCV.append(np.std(np.asarray(Sdist)))\n",
    "        SDCV.append(ss[0])\n",
    "\n",
    "        # compute DCV (dataset characteristic vector) of target dataset\n",
    "        for i in range(tt[0]):\n",
    "            for j in range(i + 1, tt[0]):\n",
    "                Tdist.append(dist.euclidean(self.Xtarget[i], self.Xtarget[j]))\n",
    "        TDCV.append(np.mean(np.asarray(Tdist)))\n",
    "        TDCV.append((np.median(np.asarray(Tdist))))\n",
    "        TDCV.append(np.min(np.asarray(Tdist)))\n",
    "        TDCV.append(np.max(np.asarray(Tdist)))\n",
    "        TDCV.append(np.std(np.asarray(Tdist)))\n",
    "        TDCV.append(ss[0])\n",
    "\n",
    "        return np.asarray(SDCV), np.asarray(TDCV)\n",
    "\n",
    "    def _chooseNormalization(self):\n",
    "        SDCV, TDCV = self._computDCV()\n",
    "\n",
    "        nominal = []\n",
    "        for i in range(0, 6):\n",
    "            if SDCV[i] * 1.6 < TDCV[i]:\n",
    "                nominal.append('much-more')\n",
    "            elif TDCV[i] < SDCV[i] * 0.4:\n",
    "                nominal.append('much-less')\n",
    "            elif (SDCV[i] * 1.3 < TDCV[i]) and (TDCV[i] <= SDCV[i] * 1.6):\n",
    "                nominal.append('more')\n",
    "            elif (SDCV[i] * 1.1 < TDCV[i]) and (TDCV[i] <= SDCV[i] * 1.3):\n",
    "                nominal.append('slight-more')\n",
    "            elif (SDCV[i] * 0.9 <= TDCV[i]) and (TDCV[i] <= SDCV[i] * 1.1):\n",
    "                nominal.append('same')\n",
    "            elif (SDCV[i] * 0.7 <= TDCV[i]) and (TDCV[i] < SDCV[i] * 0.9):\n",
    "                nominal.append('slight-less')\n",
    "            elif (SDCV[i] * 0.4 <= TDCV[i]) and (TDCV[i] < SDCV[i] * 0.7):\n",
    "                nominal.append('less')\n",
    "\n",
    "        if (nominal[5] == nominal[2] == nominal[3] == 'much-less') or (\n",
    "                nominal[5] == nominal[2] == nominal[3] == 'much-more'):\n",
    "            self._normalization('N1')\n",
    "\n",
    "        elif ((nominal[4] == 'much-more') and ('less' in nominal[5])) or (\n",
    "                (nominal[4] == 'much-less') and ('more' in nominal[5])):\n",
    "            self._normalization('N3')\n",
    "\n",
    "        elif (nominal[4] == nominal[5] == 'much-more') or (nominal[4] == nominal[5] == 'much-less'):\n",
    "            self._normalization('N4')\n",
    "\n",
    "        elif nominal[0] == nominal[4] == 'same':\n",
    "            self._normalization('N0')\n",
    "\n",
    "        else:\n",
    "            self._normalization('N2')\n",
    "\n",
    "    def run(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Transform Xs and Xt\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :return: Xs_new and Xt_new after TCA\n",
    "        '''\n",
    "        self.Xsource = Xs\n",
    "        self.Xtarget = Xt\n",
    "        self._chooseNormalization()\n",
    "        Xs = self.Xsource\n",
    "        Xt = self.Xtarget\n",
    "\n",
    "        X = np.hstack((Xs.T, Xt.T))\n",
    "        X /= np.linalg.norm(X, axis=0)\n",
    "        m, n = X.shape\n",
    "        ns, nt = len(Xs), len(Xt)\n",
    "        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))\n",
    "        M = e * e.T\n",
    "        M = M / np.linalg.norm(M, 'fro')\n",
    "        H = np.eye(n) - 1 / n * np.ones((n, n))\n",
    "        K = kernel(self.kernel_type, X, None, gamma=self.gamma)\n",
    "        n_eye = m if self.kernel_type == 'primal' else n\n",
    "        a, b = np.linalg.multi_dot([K, M, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])\n",
    "        w, V = scipy.linalg.eig(a, b)\n",
    "        ind = np.argsort(w)\n",
    "        A = V[:, ind[:self.dim]]\n",
    "        Z = np.dot(A.T, K)\n",
    "        Z /= np.linalg.norm(Z, axis=0)\n",
    "        Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T\n",
    "        return Xs_new, Ys, Xt_new, Yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb1dc8b-8e91-4750-b03f-18a1b40cf982",
   "metadata": {},
   "source": [
    "## Universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "833dcaae-6b93-4329-b633-517f0359d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cliffsDelta(lst1, lst2, **dull):\n",
    "\n",
    "    \"\"\"Returns delta and true if there are more than 'dull' differences\"\"\"\n",
    "    if not dull:\n",
    "        dull = {'small': 0.147, 'medium': 0.33, 'large': 0.474} # effect sizes from (Hess and Kromrey, 2004)\n",
    "    m, n = len(lst1), len(lst2)\n",
    "    lst2 = sorted(lst2)\n",
    "    j = more = less = 0\n",
    "    for repeats, x in runs(sorted(lst1)):\n",
    "        while j <= (n - 1) and lst2[j] < x:\n",
    "            j += 1\n",
    "        more += j*repeats\n",
    "        while j <= (n - 1) and lst2[j] == x:\n",
    "            j += 1\n",
    "        less += (n - j)*repeats\n",
    "    d = (more - less) / (m*n)\n",
    "    size = lookup_size(d, dull)\n",
    "    return d, size\n",
    "\n",
    "def lookup_size(delta: float, dull: dict) -> str:\n",
    "    \"\"\"\n",
    "    :type delta: float\n",
    "    :type dull: dict, a dictionary of small, medium, large thresholds.\n",
    "    \"\"\"\n",
    "    delta = abs(delta)\n",
    "    if delta < dull['small']:\n",
    "        return 'negligible'\n",
    "    if dull['small'] <= delta < dull['medium']:\n",
    "        return 'small'\n",
    "    if dull['medium'] <= delta < dull['large']:\n",
    "        return 'medium'\n",
    "    if delta >= dull['large']:\n",
    "        return 'large'\n",
    "\n",
    "\n",
    "def runs(lst):\n",
    "    \"\"\"Iterator, chunks repeated values\"\"\"\n",
    "    for j, two in enumerate(lst):\n",
    "        if j == 0:\n",
    "            one, i = two, 0\n",
    "        if one != two:\n",
    "            yield j - i, one\n",
    "            i = j\n",
    "        one = two\n",
    "    yield j - i + 1, two\n",
    "\n",
    "\n",
    "def cohen(c0, c1):\n",
    "    cohens_d = (mean(c0) - mean(c1)) / (sqrt((stdev(c0) ** 2 + stdev(c1) ** 2) / 2))\n",
    "    t = abs(cohens_d)\n",
    "    if t <= 0.2:\n",
    "        res = 'negligible'\n",
    "    elif t <= 0.5:\n",
    "        res = 'small'\n",
    "    elif t <= 0.8:\n",
    "        res = 'medium'\n",
    "    else:\n",
    "        res = 'large'\n",
    "\n",
    "    return res\n",
    "    \n",
    "class Universal(object):\n",
    "    def __init__(self, pvalue=0.05, QuantifyType='cliff'):\n",
    "        self.p = pvalue\n",
    "        self.type = QuantifyType\n",
    "\n",
    "    def _compareMetricDistribution(self, x1, x2):\n",
    "        s, p = mannwhitneyu(x1, x2)\n",
    "        if p < self.p:\n",
    "            sig_diff = 1\n",
    "        else:\n",
    "            sig_diff = 0\n",
    "        return sig_diff\n",
    "\n",
    "    def _quantifyDifference(self, x1, x2):\n",
    "        if self.type == 'cliff':\n",
    "            d, res = cliffsDelta(x1, x2)\n",
    "        else:\n",
    "            res = cohen(x1, x2)\n",
    "        return res\n",
    "\n",
    "    def cluster(self, No_metric, numGroup, group):\n",
    "        indexOfCluster = 0\n",
    "        clusterOfGroup = np.zeros(numGroup)\n",
    "\n",
    "        for i in range(0, numGroup-1):\n",
    "            indexNewCluster = indexOfCluster + 1\n",
    "            for j in range(i+1, numGroup):\n",
    "                if self._compareMetricDistribution(group[i][:, No_metric], group[j][:, No_metric]) == 1:\n",
    "                    if self._quantifyDifference(group[i][:, No_metric], group[j][:, No_metric]) == 'large':\n",
    "                        clusterOfGroup[j] = indexNewCluster\n",
    "                        indexOfCluster = indexNewCluster\n",
    "\n",
    "        return clusterOfGroup\n",
    "\n",
    "    def rankTransform(self, xsource, xtarget):\n",
    "        #xsource = xsource.to_numpy()\n",
    "        #xtarget = xtarget.to_numpy()\n",
    "        group = [xsource, xtarget]\n",
    "        resGroup = group.copy()\n",
    "\n",
    "        for i in range(xsource.shape[1]):\n",
    "            clusterIndex = self.cluster(i, len(group), group)\n",
    "            cluster = np.unique(clusterIndex)\n",
    "            for item in cluster:\n",
    "                tmp = np.asarray(np.where(clusterIndex == item))[0]\n",
    "                tmp_data = np.asarray([])\n",
    "                for ncs in tmp:\n",
    "                    tmp_data = np.concatenate((tmp_data, group[int(ncs)][:, i]))\n",
    "\n",
    "                percentiles = np.percentile(sorted(tmp_data), [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "                for ncs in tmp:\n",
    "                    ncs = int(ncs)\n",
    "                    t = resGroup[ncs][:, i]\n",
    "                    for it in range(len(t)):\n",
    "                        if t[it] <= percentiles[0]:\n",
    "                            resGroup[ncs][:, i][it] = 1\n",
    "                        elif t[it] <= percentiles[1]:\n",
    "                            resGroup[ncs][:, i][it] = 2\n",
    "                        elif t[it] <= percentiles[2]:\n",
    "                            resGroup[ncs][:, i][it] = 3\n",
    "                        elif t[it] <= percentiles[3]:\n",
    "                            resGroup[ncs][:, i][it] = 4\n",
    "                        elif t[it] <= percentiles[4]:\n",
    "                            resGroup[ncs][:, i][it] = 5\n",
    "                        elif t[it] <= percentiles[5]:\n",
    "                            resGroup[ncs][:, i][it] = 6\n",
    "                        elif t[it] <= percentiles[6]:\n",
    "                            resGroup[ncs][:, i][it] = 7\n",
    "                        elif t[it] <= percentiles[7]:\n",
    "                            resGroup[ncs][:, i][it] = 8\n",
    "                        elif t[it] <= percentiles[8]:\n",
    "                            resGroup[ncs][:, i][it] = 9\n",
    "                        else:\n",
    "                            resGroup[ncs][:, i][it] = 10\n",
    "        return resGroup\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        res = self.rankTransform(Xsource, Xtarget)\n",
    "        source = np.asarray(res[0])\n",
    "        target = res[1]\n",
    "        source = pd.DataFrame(data=source)\n",
    "        target = pd.DataFrame(data=target)\n",
    "\n",
    "        return source, Ysource, target, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0fc64-3a33-4087-ab06-8b752217f2f0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d79982-ed62-4469-94e1-583ee81a3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to find ML files from the project\n",
    "\n",
    "def count_ml_files(directory, keywords, output_csv, project_folder):\n",
    "    ml_file_count = 0\n",
    "    total_python_files_count = 0\n",
    "    total_files = 0\n",
    "    \n",
    "    project_root = os.path.abspath(directory)\n",
    "    \n",
    "    with open(output_csv, mode='w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ML_Files'])\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            total_files += 1\n",
    "            if file.endswith(\".py\"):\n",
    "                total_python_files_count += 1\n",
    "                with open(os.path.join(root, file), 'r', errors='ignore') as f:\n",
    "                    for line in f:\n",
    "                        if any(keyword in line for keyword in keywords):\n",
    "                            ml_file_count += 1\n",
    "                            \n",
    "                            relative_path = os.path.relpath(root, project_root)\n",
    "                            relative_path = relative_path.replace('.', project_folder)\n",
    "                            if not relative_path.startswith(project_folder):\n",
    "                                relative_path = project_folder + '/' + relative_path        \n",
    "                            relative_path = os.path.join(relative_path, file)\n",
    "                            \n",
    "                            with open(output_csv, mode='a', newline='') as csv_file:\n",
    "                                csv_writer = csv.writer(csv_file)\n",
    "                                csv_writer.writerow([relative_path])\n",
    "                            break  # Stop searching once a keyword is found\n",
    "\n",
    "    print(\"Total Files: \", total_files)\n",
    "    print(\"Total Python Files: \", total_python_files_count)\n",
    "    #print(\"Total ML files: \", ml_file_count)\n",
    "    return ml_file_count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a83f01f0-922f-44c6-940b-688f6e2417ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files:  696\n",
      "Total Python Files:  417\n",
      "Number of ML-related files in Jax: 387\n",
      "Processed files saved to /home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/jax_ml_files.csv\n"
     ]
    }
   ],
   "source": [
    "# Jax\n",
    "jax_directory = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/Jax_Versions/jax-jax-v0.3.15'\n",
    "jax_libraries = ['ml_dtypes', 'numpy', 'opt_einsum', 'scipy', 'jax', 'scikit-learn', 'matplotlib']\n",
    "# jax_libraries = ['ml_dtypes', 'opt_einsum', 'scipy', 'jax', 'scikit-learn']\n",
    "output_csv = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/jax_ml_files.csv'\n",
    "ml_count = count_ml_files(jax_directory, jax_libraries, output_csv, 'jax-main')\n",
    "print(f\"Number of ML-related files in Jax: {ml_count}\")\n",
    "print(f\"Processed files saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c523d57-bac2-42e9-a175-dc8f0e2f6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files:  2095\n",
      "Total Python Files:  1061\n",
      "Number of ML-related files in lightning: 579\n",
      "Processed files saved to /home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_ml_files.csv\n"
     ]
    }
   ],
   "source": [
    "lightning_directory = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/Lightning_Versions/lightning-1.8.0'\n",
    "lightning_libraries = ['torch', 'numpy', 'torchmetrics', 'gym', 'matplotlib', 'tensorboardX', 'scikit-learn', 'tensorboard', 'pytorch-lightning', 'torchdata', 'torchvision', 'torchmetrics', 'lightning-colossalai', 'neptune', 'comet-ml', 'mlflow', 'onnx' ] # Add your ML-related keywords to this list for lightning\n",
    "output_csv = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_ml_files.csv'  # Change this to your desired output file path\n",
    "ml_count = count_ml_files(lightning_directory, lightning_libraries, output_csv, 'lightning-master')\n",
    "print(f\"Number of ML-related files in lightning: {ml_count}\")\n",
    "print(f\"Processed files saved to {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440b2bf8-9a77-4150-996b-93efa9aaabed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files:  6621\n",
      "Total Python Files:  3463\n",
      "Number of ML-related files in Ray: 998\n",
      "Processed files saved to /home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_ml_files.csv\n"
     ]
    }
   ],
   "source": [
    "ray_directory = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_versions/ray-ray-2.0.0'\n",
    "ray_libraries = ['numpy', 'scipy', 'gymnasium', 'scikit-learn', 'scikit-image', 'pandas', 'tensorboardX'] # Add your ML-related keywords to this list for ray\n",
    "output_csv = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_ml_files.csv'  # Change this to your desired output file path\n",
    "ml_count = count_ml_files(ray_directory, ray_libraries, output_csv, 'ray-master')\n",
    "print(f\"Number of ML-related files in Ray: {ml_count}\")\n",
    "print(f\"Processed files saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebe9c637-14e9-4deb-94f9-2a8cde90e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files:  2583\n",
      "Total Python Files:  1904\n",
      "Number of ML-related files in transfomers: 1401\n",
      "Processed files saved to /home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_ml_files.csv\n"
     ]
    }
   ],
   "source": [
    "transformers_directory = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_versions/transformers-4.23.0'\n",
    "transformers_libraries = ['deepspeed', 'diffusers', 'evaluate', 'flax', 'huggingface-hub', 'jax', 'jaxlib', 'jieba', 'keras', 'keras-nlp', 'nltk', 'numpy', 'onnxconverter-common', 'onnxruntime-tools', 'onnxruntime', 'opencv-python', 'optuna', 'safetensors', 'sagemaker', 'scikit-learn', 'sentencepiece', 'sigopt', 'tensorboard', 'tensorflow', 'torch', 'torchaudio', 'torchvision' ] # Add your ML-related keywords to this list for transformers\n",
    "output_csv = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_ml_files.csv'  # Change this to your desired output file path\n",
    "ml_count = count_ml_files(transformers_directory, transformers_libraries, output_csv, 'transformers-main')\n",
    "print(f\"Number of ML-related files in transfomers: {ml_count}\")\n",
    "print(f\"Processed files saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6daa6e1b-a465-4e37-99dd-6946271efff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files:  144\n",
      "Total Python Files:  53\n",
      "Number of ML-related files in yolov5: 44\n",
      "Processed files saved to /home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_ml_files.csv\n"
     ]
    }
   ],
   "source": [
    "yolov5_directory = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5-versions/yolov5-7.0'\n",
    "yolov5_libraries = ['numpy', 'scipy', 'matplotlib', 'opencv-python', 'opencv', 'torch', 'torchvision', 'ultralytics', 'tensorboard', 'clearml', 'comet', 'coremltools', 'onnx', 'onnx-simplifier', 'scikit-learn', 'tensorflow', 'tensorflowjs', 'openvino-dev' ] # Add your ML-related keywords to this list for yolov5\n",
    "output_csv = '/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_ml_files.csv'  # Change this to your desired output file path\n",
    "ml_count = count_ml_files(yolov5_directory, yolov5_libraries, output_csv, 'yolov5-master')\n",
    "print(f\"Number of ML-related files in yolov5: {ml_count}\")\n",
    "print(f\"Processed files saved to {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68981b9-f8c1-4db9-a22c-135e5a13e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_ml_files = pd.read_csv(\"/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/jax_ml_files.csv\")\n",
    "#removing \"jax-main\" from the path of ML files\n",
    "jax_ml_files['ML_Files'] = jax_ml_files['ML_Files'].str.replace('jax-main/', '')\n",
    "\n",
    "lightning_ml_files = pd.read_csv(\"/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_ml_files.csv\")\n",
    "#removing \"lightning-master\" from the path of ML files\n",
    "lightning_ml_files['ML_Files'] = lightning_ml_files['ML_Files'].str.replace('lightning-master/', '')\n",
    "\n",
    "ray_ml_files = pd.read_csv(\"/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_ml_files.csv\")\n",
    "#removing \"ray-master\" from the path of ML files\n",
    "ray_ml_files['ML_Files'] = ray_ml_files['ML_Files'].str.replace('ray-master/', '')\n",
    "\n",
    "\n",
    "transformers_ml_files = pd.read_csv(\"/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_ml_files.csv\")\n",
    "#removing \"transformer-main\" from the path of ML files\n",
    "transformers_ml_files['ML_Files'] = transformers_ml_files['ML_Files'].str.replace('transformers-main/', '')\n",
    "\n",
    "yolov5_ml_files = pd.read_csv(\"/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_ml_files.csv\")\n",
    "#removing \"ylov5-master\" from the path of ML files\n",
    "yolov5_ml_files['ML_Files'] = yolov5_ml_files['ML_Files'].str.replace('yolov5-master/', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10933be4-4f7a-4060-bd14-ddc51afc1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_full_data = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/jax_0.3.15.csv')\n",
    "lightning_full_data = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_1.8.0.csv')\n",
    "ray_full_data = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_2.0.0.csv')\n",
    "transformers_full_data = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_4.23.0.csv')\n",
    "yolov5_full_data = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_7.0.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a23dbc92-1b94-4ade-aafe-75397b7c67a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387, 21)\n",
      "(30, 21)\n"
     ]
    }
   ],
   "source": [
    "ml_file_names = jax_ml_files['ML_Files']\n",
    "jax_ml_full_data = jax_full_data[jax_full_data['Files'].isin(ml_file_names)]\n",
    "jax_non_ml_full_data = jax_full_data[~jax_full_data['Files'].isin(ml_file_names)]\n",
    "print(jax_ml_full_data.shape)\n",
    "print(jax_non_ml_full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b25671e3-b54f-40b1-8ff1-be50e09c7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_correct_incorrect(confusion_matrix):\n",
    "    class_label = 0\n",
    "    # Extract the row corresponding to the class label (true labels)\n",
    "    true_labels = confusion_matrix[class_label, :]\n",
    "    \n",
    "    # Extract the column corresponding to the class label (predicted labels)\n",
    "    predicted_labels = confusion_matrix[:, class_label]\n",
    "    \n",
    "    # Calculate the correct predictions for the class by getting the diagonal element\n",
    "    correct_predictions = true_labels[class_label]\n",
    "    \n",
    "    # Calculate the incorrect predictions for the class by summing all elements in the column\n",
    "    incorrect_predictions = np.sum(predicted_labels) - correct_predictions\n",
    "    \n",
    "    # Total predictions for the class is the sum of true labels\n",
    "    total_predictions = np.sum(true_labels)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    correct_percentage = (correct_predictions / total_predictions) * 100\n",
    "    incorrect_percentage = (incorrect_predictions / total_predictions) * 100\n",
    "    \n",
    "    print(\"Number of correct predictions (%):\", correct_percentage)\n",
    "    print(\"Number of incorrect predictions (%):\", incorrect_percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b364b-cccc-49d1-834f-94a89632198f",
   "metadata": {},
   "source": [
    "# WPDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c737f48-ec76-4370-803b-d7ac0ac711b0",
   "metadata": {},
   "source": [
    "## Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1f761e33-edcb-44e8-b692-bada382c1201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For data loading()\n",
    "jax_1_73 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/jax_0.1.73.csv')\n",
    "jax_2_21 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/jax_0.2.21.csv') \n",
    "jax_2_28 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/jax_0.2.28.csv')\n",
    "  \n",
    "jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28])\n",
    "jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "jax_test_data1 =  jax_ml_full_data.copy()\n",
    "jax_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "jax_test_data2 =  jax_non_ml_full_data.copy()\n",
    "jax_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "  #jax_test_data.shape\n",
    "\n",
    "X_source = jax_train_data.drop(columns='Buggy')\n",
    "Y_source = jax_train_data['Buggy']\n",
    "# For ML Files\n",
    "X_target1 = jax_test_data1.drop(columns='Buggy')\n",
    "Y_target1 = jax_test_data1['Buggy']\n",
    "# For Non-ML Files\n",
    "X_target2 = jax_test_data2.drop(columns='Buggy')\n",
    "Y_target2 = jax_test_data2['Buggy']\n",
    "\n",
    "print(\"X_source = \", X_source.shape)\n",
    "print(\"Y_source = \", Y_source.shape)\n",
    "print(\"X_target1 = \", X_target1.shape)\n",
    "print(\"Y_target1 = \", Y_target1.shape)\n",
    "print(\"X_target2 = \", X_target2.shape)\n",
    "print(\"Y_target2 = \", Y_target2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d6f377ae-9db4-4212-98f1-5fe30ebfd51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.4912153782554775\n",
      "precision =  0.125\n",
      "recall =  0.06779661016949153\n",
      "f1 =  0.08791208791208792\n",
      "conf_matrix =  [[300  28]\n",
      " [ 55   4]]\n",
      "conf_matrix =  [[300  28]\n",
      " [ 55   4]]\n",
      "Number of correct predictions (%): 6.779661016949152\n",
      "Number of incorrect predictions (%): 47.45762711864407\n",
      "CART\n",
      "roc_auc =  0.5223749483257545\n",
      "precision =  0.6\n",
      "recall =  0.05084745762711865\n",
      "f1 =  0.09375000000000001\n",
      "conf_matrix =  [[326   2]\n",
      " [ 56   3]]\n",
      "conf_matrix =  [[326   2]\n",
      " [ 56   3]]\n",
      "Number of correct predictions (%): 5.084745762711865\n",
      "Number of incorrect predictions (%): 3.389830508474576\n",
      "KNN\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Ridge\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "MLP\n",
      "roc_auc =  0.4924813972715999\n",
      "precision =  0.14634146341463414\n",
      "recall =  0.3050847457627119\n",
      "f1 =  0.1978021978021978\n",
      "conf_matrix =  [[223 105]\n",
      " [ 41  18]]\n",
      "conf_matrix =  [[223 105]\n",
      " [ 41  18]]\n",
      "Number of correct predictions (%): 30.508474576271187\n",
      "Number of incorrect predictions (%): 177.96610169491524\n",
      "SVM\n",
      "roc_auc =  0.5340791649441918\n",
      "precision =  0.35294117647058826\n",
      "recall =  0.1016949152542373\n",
      "f1 =  0.15789473684210525\n",
      "conf_matrix =  [[317  11]\n",
      " [ 53   6]]\n",
      "conf_matrix =  [[317  11]\n",
      " [ 53   6]]\n",
      "Number of correct predictions (%): 10.16949152542373\n",
      "Number of incorrect predictions (%): 18.64406779661017\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 5, max_features='log2', min_samples_leaf=7, min_samples_split=0.45931853796211086, n_estimators=25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.9650430032505362, n_estimators=45, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='log_loss', max_depth=6, max_features='log2', min_samples_split=8, splitter='random', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=12)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.14172511059817, max_iter=10912, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.006986252579354192, hidden_layer_sizes=(100,), learning_rate='constant', max_iter= 29, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C=2.012999083052283, degree=1, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "234df23a-3659-4a7a-8257-30b5fef0e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.9615384615384616\n",
      "precision =  0.13333333333333333\n",
      "recall =  1.0\n",
      "f1 =  0.23529411764705882\n",
      "conf_matrix =  [[468  39]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 92.3076923076923\n",
      "Number of incorrect predictions (%): 0.0\n",
      "CART\n",
      "roc_auc =  0.5498027613412229\n",
      "precision =  0.02857142857142857\n",
      "recall =  0.16666666666666666\n",
      "f1 =  0.048780487804878044\n",
      "conf_matrix =  [[473  34]\n",
      " [  5   1]]\n",
      "Number of correct predictions (%): 93.29388560157791\n",
      "Number of incorrect predictions (%): 0.9861932938856016\n",
      "KNN\n",
      "roc_auc =  0.46745562130177515\n",
      "precision =  0.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[474  33]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 93.49112426035504\n",
      "Number of incorrect predictions (%): 1.183431952662722\n",
      "Ridge\n",
      "roc_auc =  0.9112426035502958\n",
      "precision =  0.0625\n",
      "recall =  1.0\n",
      "f1 =  0.11764705882352941\n",
      "conf_matrix =  [[417  90]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 82.24852071005917\n",
      "Number of incorrect predictions (%): 0.0\n",
      "MLP\n",
      "roc_auc =  0.5212031558185405\n",
      "precision =  0.015625\n",
      "recall =  0.16666666666666666\n",
      "f1 =  0.02857142857142857\n",
      "conf_matrix =  [[444  63]\n",
      " [  5   1]]\n",
      "Number of correct predictions (%): 87.57396449704143\n",
      "Number of incorrect predictions (%): 0.9861932938856016\n",
      "SVM\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for Non-ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 5, max_features='log2', min_samples_leaf=7, min_samples_split=0.45931853796211086, n_estimators=25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.9650430032505362, n_estimators=45, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='log_loss', max_depth=6, max_features='log2', min_samples_split=8, splitter='random', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=12)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.14172511059817, max_iter=10912, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.006986252579354192, hidden_layer_sizes=(100,), learning_rate='constant', max_iter= 29, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C=2.012999083052283, degree=1, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3fdeb-5877-435e-a30a-cdce1063bc49",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "163809cc-5bb8-4cd1-8ce6-d39c4fc583af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(577, 21)\n",
      "(484, 21)\n"
     ]
    }
   ],
   "source": [
    "ml_file_names = lightning_ml_files['ML_Files']\n",
    "lightning_ml_full_data = lightning_full_data[lightning_full_data['Files'].isin(ml_file_names)]\n",
    "lightning_non_ml_full_data = lightning_full_data[~lightning_full_data['Files'].isin(ml_file_names)]\n",
    "print(lightning_ml_full_data.shape)\n",
    "print(lightning_non_ml_full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d7ae7a1-efe5-4ef1-9285-24985ebf36d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (759, 17)\n",
      "Y_source =  (759,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For data loading()\n",
    "lightning_0_5 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_0.5.1.csv')\n",
    "lightning_1_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_1.0.0.csv')\n",
    "lightning_1_5 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_1.5.0.csv') \n",
    "\n",
    "\n",
    "lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5])\n",
    "lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "lightning_test_data1 = lightning_ml_full_data.copy()\n",
    "lightning_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "lightning_test_data2 =  lightning_non_ml_full_data.copy()\n",
    "lightning_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "  #jax_test_data.shape\n",
    "\n",
    "X_source = lightning_train_data.drop(columns='Buggy')\n",
    "Y_source = lightning_train_data['Buggy']\n",
    "# For ML Files\n",
    "X_target1 = lightning_test_data1.drop(columns='Buggy')\n",
    "Y_target1 = lightning_test_data1['Buggy']\n",
    "# For Non-ML Files\n",
    "X_target2 = lightning_test_data2.drop(columns='Buggy')\n",
    "Y_target2 = lightning_test_data2['Buggy']\n",
    "\n",
    "print(\"X_source = \", X_source.shape)\n",
    "print(\"Y_source = \", Y_source.shape)\n",
    "print(\"X_target1 = \", X_target1.shape)\n",
    "print(\"Y_target1 = \", Y_target1.shape)\n",
    "print(\"X_target2 = \", X_target2.shape)\n",
    "print(\"Y_target2 = \", Y_target2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "308209d1-1d2b-4c65-9f56-001f1d1b346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[446   0]\n",
      " [  0 131]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[446   0]\n",
      " [  0 131]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.9921524663677129\n",
      "precision =  0.9492753623188406\n",
      "recall =  1.0\n",
      "f1 =  0.9739776951672863\n",
      "conf_matrix =  [[439   7]\n",
      " [  0 131]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 5.343511450381679\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[446   0]\n",
      " [  0 131]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.6038150823263616\n",
      "precision =  0.2983050847457627\n",
      "recall =  0.6717557251908397\n",
      "f1 =  0.41314553990610337\n",
      "conf_matrix =  [[239 207]\n",
      " [ 43  88]]\n",
      "Number of correct predictions (%): 67.17557251908397\n",
      "Number of incorrect predictions (%): 158.01526717557252\n",
      "Ridge\n",
      "roc_auc =  0.7277753055146681\n",
      "precision =  0.5189873417721519\n",
      "recall =  0.6259541984732825\n",
      "f1 =  0.5674740484429066\n",
      "conf_matrix =  [[370  76]\n",
      " [ 49  82]]\n",
      "Number of correct predictions (%): 62.59541984732825\n",
      "Number of incorrect predictions (%): 58.01526717557252\n",
      "MLP\n",
      "roc_auc =  0.7268082702906241\n",
      "precision =  0.3848797250859107\n",
      "recall =  0.8549618320610687\n",
      "f1 =  0.5308056872037915\n",
      "conf_matrix =  [[267 179]\n",
      " [ 19 112]]\n",
      "Number of correct predictions (%): 85.49618320610686\n",
      "Number of incorrect predictions (%): 136.64122137404578\n",
      "SVM\n",
      "roc_auc =  0.9885496183206106\n",
      "precision =  1.0\n",
      "recall =  0.9770992366412213\n",
      "f1 =  0.9884169884169884\n",
      "conf_matrix =  [[446   0]\n",
      " [  3 128]]\n",
      "Number of correct predictions (%): 97.70992366412213\n",
      "Number of incorrect predictions (%): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 6, max_features='sqrt', min_samples_leaf=4, min_samples_split=0.6173188814474816, n_estimators=3, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME.R', learning_rate= 0.788035723318785, n_estimators=49, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=6, max_features='log2', min_samples_split= 2, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.15782926553250476, max_iter=4094, solver='svd', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.002941741563655937, hidden_layer_sizes=(100,), learning_rate='constant', max_iter= 80, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C=0.2863651711831961, degree=3, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b53e15b-2c1b-448b-b9a2-9f3942c37dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[391   0]\n",
      " [  0  93]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[391   0]\n",
      " [  0  93]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.9946236559139785\n",
      "precision =  1.0\n",
      "recall =  0.989247311827957\n",
      "f1 =  0.9945945945945946\n",
      "conf_matrix =  [[391   0]\n",
      " [  1  92]]\n",
      "Number of correct predictions (%): 98.9247311827957\n",
      "Number of incorrect predictions (%): 0.0\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[391   0]\n",
      " [  0  93]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.6450375381569177\n",
      "precision =  0.3355263157894737\n",
      "recall =  0.5483870967741935\n",
      "f1 =  0.41632653061224484\n",
      "conf_matrix =  [[290 101]\n",
      " [ 42  51]]\n",
      "Number of correct predictions (%): 54.83870967741935\n",
      "Number of incorrect predictions (%): 108.6021505376344\n",
      "Ridge\n",
      "roc_auc =  0.659777796111432\n",
      "precision =  0.6538461538461539\n",
      "recall =  0.3655913978494624\n",
      "f1 =  0.4689655172413793\n",
      "conf_matrix =  [[373  18]\n",
      " [ 59  34]]\n",
      "Number of correct predictions (%): 36.55913978494624\n",
      "Number of incorrect predictions (%): 19.35483870967742\n",
      "MLP\n",
      "roc_auc =  0.7827049473365785\n",
      "precision =  0.5714285714285714\n",
      "recall =  0.6881720430107527\n",
      "f1 =  0.624390243902439\n",
      "conf_matrix =  [[343  48]\n",
      " [ 29  64]]\n",
      "Number of correct predictions (%): 68.81720430107528\n",
      "Number of incorrect predictions (%): 51.61290322580645\n",
      "SVM\n",
      "roc_auc =  0.9946236559139785\n",
      "precision =  1.0\n",
      "recall =  0.989247311827957\n",
      "f1 =  0.9945945945945946\n",
      "conf_matrix =  [[391   0]\n",
      " [  1  92]]\n",
      "Number of correct predictions (%): 98.9247311827957\n",
      "Number of incorrect predictions (%): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for Non-ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 6, max_features='sqrt', min_samples_leaf=4, min_samples_split=0.6173188814474816, n_estimators=3, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME.R', learning_rate= 0.788035723318785, n_estimators=49, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=6, max_features='log2', min_samples_split= 2, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.15782926553250476, max_iter=4094, solver='svd', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.002941741563655937, hidden_layer_sizes=(100,), learning_rate='constant', max_iter= 80, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C=0.2863651711831961, degree=3, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3c916-9841-4804-a130-1e9d89023443",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40e4dbef-5121-4cec-8645-9d342bc2362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 21)\n",
      "(1915, 21)\n"
     ]
    }
   ],
   "source": [
    "ml_file_names = ray_ml_files['ML_Files']\n",
    "ray_ml_full_data = ray_full_data[ray_full_data['Files'].isin(ml_file_names)]\n",
    "ray_non_ml_full_data = ray_full_data[~ray_full_data['Files'].isin(ml_file_names)]\n",
    "print(ray_ml_full_data.shape)\n",
    "print(ray_non_ml_full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e02708c9-a456-43f1-ab16-67bf8b8a8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (4168, 17)\n",
      "Y_source =  (4168,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For data loading()\n",
    "ray_0_3 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_0.3.0.csv')\n",
    "ray_0_6 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_0.6.1.csv')\n",
    "ray_0_8 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_0.8.0.csv') \n",
    "ray_1_1 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_1.1.0.csv')\n",
    "ray_1_9 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_1.9.0.csv')\n",
    "\n",
    "\n",
    "ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9])\n",
    "ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "ray_test_data1 = ray_ml_full_data.copy()\n",
    "ray_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "ray_test_data2 =  ray_non_ml_full_data.copy()\n",
    "ray_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "  #jax_test_data.shape\n",
    "\n",
    "X_source = ray_train_data.drop(columns='Buggy')\n",
    "Y_source = ray_train_data['Buggy']\n",
    "# For ML Files\n",
    "X_target1 = ray_test_data1.drop(columns='Buggy')\n",
    "Y_target1 = ray_test_data1['Buggy']\n",
    "# For Non-ML Files\n",
    "X_target2 = ray_test_data2.drop(columns='Buggy')\n",
    "Y_target2 = ray_test_data2['Buggy']\n",
    "\n",
    "print(\"X_source = \", X_source.shape)\n",
    "print(\"Y_source = \", Y_source.shape)\n",
    "print(\"X_target1 = \", X_target1.shape)\n",
    "print(\"Y_target1 = \", Y_target1.shape)\n",
    "print(\"X_target2 = \", X_target2.shape)\n",
    "print(\"Y_target2 = \", Y_target2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c522f38-a725-472c-b623-ffe380efe798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[628   0]\n",
      " [  0  67]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[628   0]\n",
      " [  0  67]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.8957006369426752\n",
      "precision =  0.3383838383838384\n",
      "recall =  1.0\n",
      "f1 =  0.5056603773584906\n",
      "conf_matrix =  [[497 131]\n",
      " [  0  67]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 195.5223880597015\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[628   0]\n",
      " [  0  67]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.6663418575910257\n",
      "precision =  0.1941747572815534\n",
      "recall =  0.5970149253731343\n",
      "f1 =  0.29304029304029305\n",
      "conf_matrix =  [[462 166]\n",
      " [ 27  40]]\n",
      "Number of correct predictions (%): 59.70149253731343\n",
      "Number of incorrect predictions (%): 247.76119402985074\n",
      "Ridge\n",
      "roc_auc =  0.6055708717558703\n",
      "precision =  0.6521739130434783\n",
      "recall =  0.22388059701492538\n",
      "f1 =  0.33333333333333337\n",
      "conf_matrix =  [[620   8]\n",
      " [ 52  15]]\n",
      "Number of correct predictions (%): 22.388059701492537\n",
      "Number of incorrect predictions (%): 11.940298507462686\n",
      "MLP\n",
      "roc_auc =  0.7308441867097634\n",
      "precision =  0.7619047619047619\n",
      "recall =  0.47761194029850745\n",
      "f1 =  0.5871559633027523\n",
      "conf_matrix =  [[618  10]\n",
      " [ 35  32]]\n",
      "Number of correct predictions (%): 47.76119402985074\n",
      "Number of incorrect predictions (%): 14.925373134328357\n",
      "SVM\n",
      "roc_auc =  0.966168362011598\n",
      "precision =  0.9264705882352942\n",
      "recall =  0.9402985074626866\n",
      "f1 =  0.9333333333333335\n",
      "conf_matrix =  [[623   5]\n",
      " [  4  63]]\n",
      "Number of correct predictions (%): 94.02985074626866\n",
      "Number of incorrect predictions (%): 7.462686567164178\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 4, max_features='log2', min_samples_leaf=9, min_samples_split= 0.2941037470966731, n_estimators=43, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME.R', learning_rate= 0.5467481993881079, n_estimators=43, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='log2', min_samples_split= 4, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=16)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.6328583171856641, max_iter=14462, solver='cholesky', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.004894991445063436, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 90, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C=0.5761836015907289, degree=3, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "346da7d4-b365-4fca-b539-ff3ef58febc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[1770    0]\n",
      " [   0  145]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[1770    0]\n",
      " [   0  145]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.964406779661017\n",
      "precision =  0.5350553505535055\n",
      "recall =  1.0\n",
      "f1 =  0.6971153846153846\n",
      "conf_matrix =  [[1644  126]\n",
      " [   0  145]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 86.89655172413792\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[1770    0]\n",
      " [   0  145]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.627907656341321\n",
      "precision =  0.19\n",
      "recall =  0.3931034482758621\n",
      "f1 =  0.25617977528089886\n",
      "conf_matrix =  [[1527  243]\n",
      " [  88   57]]\n",
      "Number of correct predictions (%): 39.310344827586206\n",
      "Number of incorrect predictions (%): 167.58620689655172\n",
      "Ridge\n",
      "roc_auc =  0.606672511202026\n",
      "precision =  0.7111111111111111\n",
      "recall =  0.2206896551724138\n",
      "f1 =  0.3368421052631579\n",
      "conf_matrix =  [[1757   13]\n",
      " [ 113   32]]\n",
      "Number of correct predictions (%): 22.06896551724138\n",
      "Number of incorrect predictions (%): 8.96551724137931\n",
      "MLP\n",
      "roc_auc =  0.742343658679135\n",
      "precision =  0.7741935483870968\n",
      "recall =  0.496551724137931\n",
      "f1 =  0.6050420168067228\n",
      "conf_matrix =  [[1749   21]\n",
      " [  73   72]]\n",
      "Number of correct predictions (%): 49.6551724137931\n",
      "Number of incorrect predictions (%): 14.482758620689657\n",
      "SVM\n",
      "roc_auc =  0.9931618936294564\n",
      "precision =  0.9230769230769231\n",
      "recall =  0.993103448275862\n",
      "f1 =  0.9568106312292359\n",
      "conf_matrix =  [[1758   12]\n",
      " [   1  144]]\n",
      "Number of correct predictions (%): 99.3103448275862\n",
      "Number of incorrect predictions (%): 8.275862068965518\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for Non-ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 4, max_features='log2', min_samples_leaf=9, min_samples_split= 0.2941037470966731, n_estimators=43, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME.R', learning_rate= 0.5467481993881079, n_estimators=43, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='log2', min_samples_split= 4, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=16)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.6328583171856641, max_iter=14462, solver='cholesky', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.004894991445063436, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 90, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C=0.5761836015907289, degree=3, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b93bb3-ec99-44e4-a1f1-347c0f6c19e2",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "499567f1-73ef-437e-8f4b-c2c4710ce733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1391, 21)\n",
      "(513, 21)\n"
     ]
    }
   ],
   "source": [
    "ml_file_names = transformers_ml_files['ML_Files']\n",
    "transformers_ml_full_data = transformers_full_data[transformers_full_data['Files'].isin(ml_file_names)]\n",
    "transformers_non_ml_full_data = transformers_full_data[~transformers_full_data['Files'].isin(ml_file_names)]\n",
    "print(transformers_ml_full_data.shape)\n",
    "print(transformers_non_ml_full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2e5c062d-761b-4e88-82d3-7605436ec399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (1935, 17)\n",
      "Y_source =  (1935,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For data loading()\n",
    "transformers_2_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_2.0.0.csv')\n",
    "transformers_3_5 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_3.5.0.csv')\n",
    "transformers_4_13 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_4.13.0.csv')\n",
    "\n",
    "transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13])\n",
    "transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "transformers_test_data1 = transformers_ml_full_data.copy()\n",
    "transformers_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "transformers_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "transformers_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "  #jax_test_data.shape\n",
    "\n",
    "X_source = transformers_train_data.drop(columns='Buggy')\n",
    "Y_source = transformers_train_data['Buggy']\n",
    "# For ML Files\n",
    "X_target1 = transformers_test_data1.drop(columns='Buggy')\n",
    "Y_target1 = transformers_test_data1['Buggy']\n",
    "# For Non-ML Files\n",
    "X_target2 = transformers_test_data2.drop(columns='Buggy')\n",
    "Y_target2 = transformers_test_data2['Buggy']\n",
    "\n",
    "print(\"X_source = \", X_source.shape)\n",
    "print(\"Y_source = \", Y_source.shape)\n",
    "print(\"X_target1 = \", X_target1.shape)\n",
    "print(\"Y_target1 = \", Y_target1.shape)\n",
    "print(\"X_target2 = \", X_target2.shape)\n",
    "print(\"Y_target2 = \", Y_target2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dba30023-bba4-4c1c-8f8c-3fa996263791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[1288    0]\n",
      " [   0  103]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[1288    0]\n",
      " [   0  103]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.6876017608394138\n",
      "precision =  0.21951219512195122\n",
      "recall =  0.5242718446601942\n",
      "f1 =  0.3094555873925502\n",
      "conf_matrix =  [[1096  192]\n",
      " [  49   54]]\n",
      "Number of correct predictions (%): 52.42718446601942\n",
      "Number of incorrect predictions (%): 186.40776699029126\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[1288    0]\n",
      " [   0  103]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.5240833986612796\n",
      "precision =  0.17391304347826086\n",
      "recall =  0.07766990291262135\n",
      "f1 =  0.10738255033557047\n",
      "conf_matrix =  [[1250   38]\n",
      " [  95    8]]\n",
      "Number of correct predictions (%): 7.766990291262135\n",
      "Number of incorrect predictions (%): 36.89320388349515\n",
      "Ridge\n",
      "roc_auc =  0.6407766990291262\n",
      "precision =  1.0\n",
      "recall =  0.2815533980582524\n",
      "f1 =  0.4393939393939394\n",
      "conf_matrix =  [[1288    0]\n",
      " [  74   29]]\n",
      "Number of correct predictions (%): 28.155339805825243\n",
      "Number of incorrect predictions (%): 0.0\n",
      "MLP\n",
      "roc_auc =  0.5371050171862751\n",
      "precision =  0.12686567164179105\n",
      "recall =  0.1650485436893204\n",
      "f1 =  0.14345991561181434\n",
      "conf_matrix =  [[1171  117]\n",
      " [  86   17]]\n",
      "Number of correct predictions (%): 16.50485436893204\n",
      "Number of incorrect predictions (%): 113.59223300970874\n",
      "SVM\n",
      "roc_auc =  0.5856336308267502\n",
      "precision =  0.5277777777777778\n",
      "recall =  0.18446601941747573\n",
      "f1 =  0.2733812949640288\n",
      "conf_matrix =  [[1271   17]\n",
      " [  84   19]]\n",
      "Number of correct predictions (%): 18.446601941747574\n",
      "Number of incorrect predictions (%): 16.50485436893204\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.14925335668960113, n_estimators=28, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=7, max_features='sqrt', min_samples_split= 5, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.6275778011613018, max_iter=12807, solver='cholesky', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.004894991445063436, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 90, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C= 1.2704047468360506, degree=2, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80ac6fc6-76ed-42c1-a277-9429fe9ecb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.4921104536489152\n",
      "precision =  0.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[499   8]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 133.33333333333331\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Ridge\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "MLP\n",
      "roc_auc =  0.4881656804733728\n",
      "precision =  0.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[495  12]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 200.0\n",
      "SVM\n",
      "roc_auc =  0.9127218934911243\n",
      "precision =  0.5555555555555556\n",
      "recall =  0.8333333333333334\n",
      "f1 =  0.6666666666666667\n",
      "conf_matrix =  [[503   4]\n",
      " [  1   5]]\n",
      "Number of correct predictions (%): 83.33333333333334\n",
      "Number of incorrect predictions (%): 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for Non-ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.14925335668960113, n_estimators=28, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=7, max_features='sqrt', min_samples_split= 5, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.6328583171856641, max_iter=14462, solver='cholesky', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='identity', alpha=0.004894991445063436, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 90, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C= 1.2704047468360506, degree=2, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579dad9-40e9-4db6-8d01-a90401bf4771",
   "metadata": {},
   "source": [
    "## Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "228bb18c-37ea-4eef-a539-a8d68abdee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 21)\n",
      "(9, 21)\n"
     ]
    }
   ],
   "source": [
    "ml_file_names = yolov5_ml_files['ML_Files']\n",
    "yolov5_ml_full_data = yolov5_full_data[yolov5_full_data['Files'].isin(ml_file_names)]\n",
    "yolov5_non_ml_full_data = yolov5_full_data[~yolov5_full_data['Files'].isin(ml_file_names)]\n",
    "print(yolov5_ml_full_data.shape)\n",
    "print(yolov5_non_ml_full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e9ce91da-de8f-4e99-8562-7153e03abfb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (50, 17)\n",
      "Y_source =  (50,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For data loading()\n",
    "yolov5_4_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_4.0.csv')\n",
    "yolov5_6_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_6.0.csv')\n",
    "\n",
    "\n",
    "yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0])\n",
    "yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "yolov5_test_data1 = yolov5_ml_full_data.copy()\n",
    "yolov5_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "yolov5_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "yolov5_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "  #jax_test_data.shape\n",
    "\n",
    "X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "Y_source = yolov5_train_data['Buggy']\n",
    "# For ML Files\n",
    "X_target1 = yolov5_test_data1.drop(columns='Buggy')\n",
    "Y_target1 = yolov5_test_data1['Buggy']\n",
    "# For Non-ML Files\n",
    "X_target2 = yolov5_test_data2.drop(columns='Buggy')\n",
    "Y_target2 = yolov5_test_data2['Buggy']\n",
    "\n",
    "print(\"X_source = \", X_source.shape)\n",
    "print(\"Y_source = \", Y_source.shape)\n",
    "print(\"X_target1 = \", X_target1.shape)\n",
    "print(\"Y_target1 = \", Y_target1.shape)\n",
    "print(\"X_target2 = \", X_target2.shape)\n",
    "print(\"Y_target2 = \", Y_target2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bd7f498b-7f76-4c28-9565-e44d771f8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[10  0]\n",
      " [ 0 34]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[10  0]\n",
      " [ 0 34]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.7588235294117648\n",
      "precision =  0.9545454545454546\n",
      "recall =  0.6176470588235294\n",
      "f1 =  0.75\n",
      "conf_matrix =  [[ 9  1]\n",
      " [13 21]]\n",
      "Number of correct predictions (%): 61.76470588235294\n",
      "Number of incorrect predictions (%): 2.941176470588235\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[10  0]\n",
      " [ 0 34]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.4852941176470588\n",
      "precision =  0.7674418604651163\n",
      "recall =  0.9705882352941176\n",
      "f1 =  0.8571428571428571\n",
      "conf_matrix =  [[ 0 10]\n",
      " [ 1 33]]\n",
      "Number of correct predictions (%): 97.05882352941177\n",
      "Number of incorrect predictions (%): 29.411764705882355\n",
      "Ridge\n",
      "roc_auc =  0.5\n",
      "precision =  0.7727272727272727\n",
      "recall =  1.0\n",
      "f1 =  0.8717948717948718\n",
      "conf_matrix =  [[ 0 10]\n",
      " [ 0 34]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 29.411764705882355\n",
      "MLP\n",
      "roc_auc =  0.6\n",
      "precision =  0.8095238095238095\n",
      "recall =  1.0\n",
      "f1 =  0.8947368421052632\n",
      "conf_matrix =  [[ 2  8]\n",
      " [ 0 34]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 23.52941176470588\n",
      "SVM\n",
      "roc_auc =  0.8264705882352942\n",
      "precision =  0.9354838709677419\n",
      "recall =  0.8529411764705882\n",
      "f1 =  0.8923076923076922\n",
      "conf_matrix =  [[ 8  2]\n",
      " [ 5 29]]\n",
      "Number of correct predictions (%): 85.29411764705883\n",
      "Number of incorrect predictions (%): 5.88235294117647\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 2, max_features='log2', min_samples_leaf=4, min_samples_split= 0.07335409800854176, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.3618390422647574, n_estimators=11, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='log_loss', max_depth=3, max_features='log2', min_samples_split=9, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=9)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C= 0.6728812217893367, degree=2, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1e49efef-b331-410d-8422-70f7220e7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "Gaussian NB\n",
      "roc_auc =  0.6341222879684418\n",
      "precision =  0.05714285714285714\n",
      "recall =  0.3333333333333333\n",
      "f1 =  0.09756097560975609\n",
      "conf_matrix =  [[474  33]\n",
      " [  4   2]]\n",
      "Number of correct predictions (%): 33.33333333333333\n",
      "Number of incorrect predictions (%): 550.0\n",
      "CART\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "KNN\n",
      "roc_auc =  0.7652859960552268\n",
      "precision =  0.02459016393442623\n",
      "recall =  1.0\n",
      "f1 =  0.048\n",
      "conf_matrix =  [[269 238]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 3966.6666666666665\n",
      "Ridge\n",
      "roc_auc =  0.5\n",
      "precision =  0.011695906432748537\n",
      "recall =  1.0\n",
      "f1 =  0.023121387283236997\n",
      "conf_matrix =  [[  0 507]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 8450.0\n",
      "MLP\n",
      "roc_auc =  0.7209072978303748\n",
      "precision =  0.020761245674740483\n",
      "recall =  1.0\n",
      "f1 =  0.04067796610169491\n",
      "conf_matrix =  [[224 283]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 4716.666666666666\n",
      "SVM\n",
      "roc_auc =  0.7465483234714003\n",
      "precision =  0.022813688212927757\n",
      "recall =  1.0\n",
      "f1 =  0.0446096654275093\n",
      "conf_matrix =  [[250 257]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 4283.333333333334\n"
     ]
    }
   ],
   "source": [
    "# Setting up classifiers for Non-ML Files\n",
    "# Random Forest \n",
    "print(\"Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 2, max_features='log2', min_samples_leaf=4, min_samples_split= 0.07335409800854176, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print(\"AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.3618390422647574, n_estimators=11, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Gaussian NB\n",
    "print(\"Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#CART\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='log_loss', max_depth=3, max_features='log2', min_samples_split=9, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#KNN\n",
    "print(\"KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=9)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#MLP\n",
    "print(\"MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "#SVM\n",
    "print(\"SVM\")\n",
    "model = SVC(C= 0.6728812217893367, degree=2, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target2)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target2, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target2, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target2, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target2, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target2, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f3b83-07d8-4de7-b6a7-cc8c70fa2dd2",
   "metadata": {},
   "source": [
    "# CPDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d24b3-f22e-48fa-a639-dce4acf96bca",
   "metadata": {},
   "source": [
    "## Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57e0e323-199d-47d2-9f7c-d22dfb632d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "def data_loading_lj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    jax_test_data1 =  jax_ml_full_data.copy()\n",
    "    jax_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    jax_test_data2 =  jax_non_ml_full_data.copy()\n",
    "    jax_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = jax_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = jax_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = jax_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = jax_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "   \n",
    "\n",
    "def data_loading_rj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    ray_0_3 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    jax_test_data1 =  jax_ml_full_data.copy()\n",
    "    jax_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    jax_test_data2 =  jax_non_ml_full_data.copy()\n",
    "    jax_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = jax_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = jax_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = jax_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = jax_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_tj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    jax_test_data1 =  jax_ml_full_data.copy()\n",
    "    jax_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    jax_test_data2 =  jax_non_ml_full_data.copy()\n",
    "    jax_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = jax_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = jax_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = jax_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = jax_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_yj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024_Experiments/Experiment_Type1/MSR_2024/Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    jax_test_data1 =  jax_ml_full_data.copy()\n",
    "    jax_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    jax_test_data2 =  jax_non_ml_full_data.copy()\n",
    "    jax_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = jax_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = jax_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = jax_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = jax_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "29949ad9-fb88-4db0-999c-4f187b4aee94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Peterfilter-SVM\n",
      "roc_auc =  0.5025578751550227\n",
      "precision =  0.16666666666666666\n",
      "recall =  0.05084745762711865\n",
      "f1 =  0.07792207792207792\n",
      "conf_matrix =  [[313  15]\n",
      " [ 56   3]]\n",
      "Number of correct predictions (%): 5.084745762711865\n",
      "Number of incorrect predictions (%): 25.423728813559322\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Peterfilter-Ridge\n",
      "roc_auc =  0.4917062835882596\n",
      "precision =  0.08333333333333333\n",
      "recall =  0.01694915254237288\n",
      "f1 =  0.028169014084507043\n",
      "conf_matrix =  [[317  11]\n",
      " [ 58   1]]\n",
      "Number of correct predictions (%): 1.694915254237288\n",
      "Number of incorrect predictions (%): 18.64406779661017\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "DTB-Gaussian NB\n",
      "roc_auc =  0.49560768912773867\n",
      "precision =  0.125\n",
      "recall =  0.03389830508474576\n",
      "f1 =  0.05333333333333334\n",
      "conf_matrix =  [[314  14]\n",
      " [ 57   2]]\n",
      "Number of correct predictions (%): 3.389830508474576\n",
      "Number of incorrect predictions (%): 23.728813559322035\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Bruakfilter-Random FOrest\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[328   0]\n",
      " [ 59   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Peterfilter-Gaussian NB\n",
      "roc_auc =  0.4446052087639521\n",
      "precision =  0.12727272727272726\n",
      "recall =  0.4745762711864407\n",
      "f1 =  0.2007168458781362\n",
      "conf_matrix =  [[136 192]\n",
      " [ 31  28]]\n",
      "Number of correct predictions (%): 47.45762711864407\n",
      "Number of incorrect predictions (%): 325.42372881355936\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "DSBF-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  0.11818181818181818\n",
      "recall =  1.0\n",
      "f1 =  0.21138211382113822\n",
      "conf_matrix =  [[  0 194]\n",
      " [  0  26]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 746.1538461538462\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "DSBF-MLP\n",
      "roc_auc =  0.49149958660603554\n",
      "precision =  0.147239263803681\n",
      "recall =  0.4067796610169492\n",
      "f1 =  0.2162162162162162\n",
      "conf_matrix =  [[189 139]\n",
      " [ 35  24]]\n",
      "Number of correct predictions (%): 40.67796610169492\n",
      "Number of incorrect predictions (%): 235.59322033898303\n"
     ]
    }
   ],
   "source": [
    "# ML Files\n",
    "\n",
    "# Peterfilter-SVM\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Peterfilter-SVM\")\n",
    "model = SVC(C= 0.6728812217893367, degree=2, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# #TCA-MLP\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "# tca = TCA()\n",
    "# X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "# print(\"TCA-MLP\")\n",
    "# model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "\n",
    "# # TCA-SVM\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "# tca = TCA()\n",
    "# X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "# print(\"Peterfilter-SVM\")\n",
    "# model = SVC(C= 0.6728812217893367, degree=2, kernel='linear')\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "\n",
    "# Peterfilter-ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tj()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Peterfilter-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# DTB-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter- Random Forest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yj()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Bruakfilter-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 2, max_features='log2', min_samples_leaf=4, min_samples_split= 0.07335409800854176, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter - Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Peterfilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yj()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DSBF-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rj()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DSBF-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# # TCA - Naive Bayes\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "# tca = TCA()\n",
    "# X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "# print(\"TCA-Gaussian NB\")\n",
    "# model = GaussianNB(var_smoothing=1e-09)\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "186ebf32-ef74-4241-82b6-a328008f6d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Peterfilter-SVM\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[23  0]\n",
      " [ 7  0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Peterfilter-Ridge\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[23  0]\n",
      " [ 7  0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "DTB-Gaussian NB\n",
      "roc_auc =  0.4782608695652174\n",
      "precision =  0.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[22  1]\n",
      " [ 7  0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 14.285714285714285\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Bruakfilter-Random FOrest\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[23  0]\n",
      " [ 7  0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (387, 17)\n",
      "Y_target1 =  (387,)\n",
      "X_target2 =  (30, 17)\n",
      "Y_target2 =  (30,)\n",
      "Peterfilter-Gaussian NB\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[23  0]\n",
      " [ 7  0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Non-ML Files\n",
    "\n",
    "# Peterfilter-SVM\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Peterfilter-SVM\")\n",
    "model = SVC(C= 0.6728812217893367, degree=2, kernel='linear')\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# #TCA-MLP\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "# tca = TCA()\n",
    "# X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "# print(\"TCA-MLP\")\n",
    "# model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "\n",
    "# # TCA-SVM\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "# tca = TCA()\n",
    "# X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "# print(\"Peterfilter-SVM\")\n",
    "# model = SVC(C= 0.6728812217893367, degree=2, kernel='linear')\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))\n",
    "\n",
    "# Peterfilter-ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tj()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Peterfilter-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# DTB-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter- Random Forest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yj()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Bruakfilter-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth= 2, max_features='log2', min_samples_leaf=4, min_samples_split= 0.07335409800854176, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter - Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Peterfilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF - MLP\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yj()\n",
    "# dsbf = DSBF()\n",
    "# X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target2, Y_target2)\n",
    "# print(\"DSBF-MLP\")\n",
    "# model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "# print(\"conf_matrix = \", conf_mat)\n",
    "# calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - MLP\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rj()\n",
    "# dtb = DTB()\n",
    "# X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target1)\n",
    "# print(\"DTB-MLP\")\n",
    "# model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "# print(\"conf_matrix = \", conf_mat)\n",
    "# calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# # TCA - Naive Bayes\n",
    "# X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lj()\n",
    "# tca = TCA()\n",
    "# X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "# print(\"TCA-Gaussian NB\")\n",
    "# model = GaussianNB(var_smoothing=1e-09)\n",
    "# model.fit(X_source, Y_source)\n",
    "# y_pred = model.predict(X_target1)\n",
    "# print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "# print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "# print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "# print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "# print(\"conf_matrix = \", confusion_matrix(Y_target1, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54df16c-0a54-4901-9109-4b548ff4e3c8",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "147820e9-b6f8-467e-9b56-9b68a34e371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_test_data1 = lightning_ml_full_data.copy()\n",
    "    lightning_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_test_data2 =  lightning_non_ml_full_data.copy()\n",
    "    lightning_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = lightning_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = lightning_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = lightning_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = lightning_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2             \n",
    "\n",
    "\n",
    "def data_loading_rl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    lightning_test_data1 = lightning_ml_full_data.copy()\n",
    "    lightning_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_test_data2 =  lightning_non_ml_full_data.copy()\n",
    "    lightning_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = lightning_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = lightning_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = lightning_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = lightning_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 \n",
    "\n",
    "def data_loading_tl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_test_data1 = lightning_ml_full_data.copy()\n",
    "    lightning_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_test_data2 =  lightning_non_ml_full_data.copy()\n",
    "    lightning_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = lightning_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = lightning_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = lightning_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = lightning_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 \n",
    "\n",
    "def data_loading_yl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_test_data1 = lightning_ml_full_data.copy()\n",
    "    lightning_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_test_data2 =  lightning_non_ml_full_data.copy()\n",
    "    lightning_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = lightning_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = lightning_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = lightning_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = lightning_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c47c855-8a89-4155-8c3b-e60d4ab05168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DS-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[446   0]\n",
      " [131   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "Universal-KNN\n",
      "roc_auc =  0.6927224181015301\n",
      "precision =  0.3501577287066246\n",
      "recall =  0.8473282442748091\n",
      "f1 =  0.49553571428571425\n",
      "conf_matrix =  [[240 206]\n",
      " [ 20 111]]\n",
      "Number of correct predictions (%): 84.7328244274809\n",
      "Number of incorrect predictions (%): 157.25190839694656\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "Bruakfilter-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  0.2270363951473137\n",
      "recall =  1.0\n",
      "f1 =  0.3700564971751412\n",
      "conf_matrix =  [[  0 446]\n",
      " [  0 131]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 340.4580152671756\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.6485297641460993\n",
      "precision =  0.43448275862068964\n",
      "recall =  0.48091603053435117\n",
      "f1 =  0.4565217391304348\n",
      "conf_matrix =  [[364  82]\n",
      " [ 68  63]]\n",
      "Number of correct predictions (%): 48.091603053435115\n",
      "Number of incorrect predictions (%): 62.59541984732825\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DSBF-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[320   0]\n",
      " [ 86   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.5689932564269332\n",
      "precision =  0.41333333333333333\n",
      "recall =  0.2366412213740458\n",
      "f1 =  0.30097087378640774\n",
      "conf_matrix =  [[402  44]\n",
      " [100  31]]\n",
      "Number of correct predictions (%): 23.66412213740458\n",
      "Number of incorrect predictions (%): 33.587786259541986\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "CART\n",
      "roc_auc =  0.9829442371546913\n",
      "precision =  0.9624060150375939\n",
      "recall =  0.9770992366412213\n",
      "f1 =  0.9696969696969696\n",
      "conf_matrix =  [[441   5]\n",
      " [  3 128]]\n",
      "Number of correct predictions (%): 97.70992366412213\n",
      "Number of incorrect predictions (%): 3.816793893129771\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DS-Ridge\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[446   0]\n",
      " [131   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "Peterfilter-Ridge\n",
      "roc_auc =  0.4977578475336323\n",
      "precision =  0.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[444   2]\n",
      " [131   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 1.5267175572519083\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "TCA-Gaussian NB\n",
      "roc_auc =  0.9955156950672646\n",
      "precision =  0.9703703703703703\n",
      "recall =  1.0\n",
      "f1 =  0.9849624060150376\n",
      "conf_matrix =  [[442   4]\n",
      " [  0 131]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 3.0534351145038165\n"
     ]
    }
   ],
   "source": [
    "# ML Files\n",
    "\n",
    "\n",
    "# DS-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jl()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target1, Y_target1, loc)\n",
    "print(\"DS-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#Universal-KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yl()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Universal-KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=9)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yl()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Bruakfilter-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rl()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DSBF-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA-CART\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rl()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=7, max_features='sqrt', min_samples_split= 5, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "\n",
    "# DS-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target1, Y_target1, loc)\n",
    "print(\"DS-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter_Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Peterfilter-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Bruakfilter-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rl()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"TCA-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f9b04887-bfc3-454f-ac8a-abaf96edd0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DS-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[391   0]\n",
      " [ 93   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "Universal-KNN\n",
      "roc_auc =  0.7583120204603581\n",
      "precision =  0.32978723404255317\n",
      "recall =  1.0\n",
      "f1 =  0.496\n",
      "conf_matrix =  [[202 189]\n",
      " [  0  93]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 203.2258064516129\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "Bruakfilter-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  0.1921487603305785\n",
      "recall =  1.0\n",
      "f1 =  0.3223570190641248\n",
      "conf_matrix =  [[  0 391]\n",
      " [  0  93]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 420.4301075268817\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.7365866402662046\n",
      "precision =  0.7\n",
      "recall =  0.5268817204301075\n",
      "f1 =  0.6012269938650306\n",
      "conf_matrix =  [[370  21]\n",
      " [ 44  49]]\n",
      "Number of correct predictions (%): 52.68817204301075\n",
      "Number of incorrect predictions (%): 22.58064516129032\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DSBF-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[149   0]\n",
      " [ 54   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.5857877512856475\n",
      "precision =  0.5405405405405406\n",
      "recall =  0.21505376344086022\n",
      "f1 =  0.3076923076923077\n",
      "conf_matrix =  [[374  17]\n",
      " [ 73  20]]\n",
      "Number of correct predictions (%): 21.50537634408602\n",
      "Number of incorrect predictions (%): 18.27956989247312\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "CART\n",
      "roc_auc =  0.968003190055826\n",
      "precision =  0.9565217391304348\n",
      "recall =  0.946236559139785\n",
      "f1 =  0.9513513513513514\n",
      "conf_matrix =  [[387   4]\n",
      " [  5  88]]\n",
      "Number of correct predictions (%): 94.6236559139785\n",
      "Number of incorrect predictions (%): 4.301075268817205\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "DS-Ridge\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[391   0]\n",
      " [ 93   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "Peterfilter-Ridge\n",
      "roc_auc =  0.5053763440860215\n",
      "precision =  1.0\n",
      "recall =  0.010752688172043012\n",
      "f1 =  0.021276595744680854\n",
      "conf_matrix =  [[391   0]\n",
      " [ 92   1]]\n",
      "Number of correct predictions (%): 1.0752688172043012\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (484, 17)\n",
      "Y_target2 =  (484,)\n",
      "TCA-Gaussian NB\n",
      "roc_auc =  0.9974424552429668\n",
      "precision =  0.9789473684210527\n",
      "recall =  1.0\n",
      "f1 =  0.9893617021276596\n",
      "conf_matrix =  [[389   2]\n",
      " [  0  93]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 2.1505376344086025\n"
     ]
    }
   ],
   "source": [
    "# Non-ML Files\n",
    "\n",
    "\n",
    "# DS-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jl()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target2, Y_target2, loc)\n",
    "print(\"DS-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#Universal-KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yl()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Universal-KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=9)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yl()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Bruakfilter-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rl()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DSBF-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA-CART\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rl()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=7, max_features='sqrt', min_samples_split= 5, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "\n",
    "# DS-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target2, Y_target2, loc)\n",
    "print(\"DS-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter_Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tl()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Peterfilter-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "# Bruakfilter-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rl()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"TCA-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a32af-7a36-41cd-aad9-d1a97a4c538a",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb7c5d9f-1713-4a39-b363-753ef273ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_tr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data1 = ray_ml_full_data.copy()\n",
    "    ray_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data2 =  ray_non_ml_full_data.copy()\n",
    "    ray_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = ray_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = ray_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = ray_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = ray_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_jr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data1 = ray_ml_full_data.copy()\n",
    "    ray_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data2 =  ray_non_ml_full_data.copy()\n",
    "    ray_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = ray_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = ray_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = ray_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = ray_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_lr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data1 = ray_ml_full_data.copy()\n",
    "    ray_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data2 =  ray_non_ml_full_data.copy()\n",
    "    ray_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = ray_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = ray_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = ray_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = ray_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_yr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data1 = ray_ml_full_data.copy()\n",
    "    ray_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    ray_test_data2 =  ray_non_ml_full_data.copy()\n",
    "    ray_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = ray_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = ray_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = ray_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = ray_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ce386ffd-49c2-4797-a9fc-d49c956b631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DSBF-Ridge\n",
      "roc_auc =  0.9148936170212766\n",
      "precision =  1.0\n",
      "recall =  0.8297872340425532\n",
      "f1 =  0.9069767441860465\n",
      "conf_matrix =  [[445   0]\n",
      " [  8  39]]\n",
      "Number of correct predictions (%): 82.97872340425532\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DTB-KNN\n",
      "roc_auc =  0.5388701397471243\n",
      "precision =  0.11507936507936507\n",
      "recall =  0.43283582089552236\n",
      "f1 =  0.18181818181818182\n",
      "conf_matrix =  [[405 223]\n",
      " [ 38  29]]\n",
      "Number of correct predictions (%): 43.28358208955223\n",
      "Number of incorrect predictions (%): 332.8358208955224\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "TCA-AdaBoost\n",
      "roc_auc =  0.917910447761194\n",
      "precision =  1.0\n",
      "recall =  0.835820895522388\n",
      "f1 =  0.9105691056910569\n",
      "conf_matrix =  [[628   0]\n",
      " [ 11  56]]\n",
      "Number of correct predictions (%): 83.5820895522388\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "Bruakfilter - KNN\n",
      "roc_auc =  0.9096515828500807\n",
      "precision =  0.9821428571428571\n",
      "recall =  0.8208955223880597\n",
      "f1 =  0.8943089430894309\n",
      "conf_matrix =  [[627   1]\n",
      " [ 12  55]]\n",
      "Number of correct predictions (%): 82.08955223880598\n",
      "Number of incorrect predictions (%): 1.4925373134328357\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "TCA-Ridge\n",
      "roc_auc =  0.998407643312102\n",
      "precision =  0.9710144927536232\n",
      "recall =  1.0\n",
      "f1 =  0.9852941176470589\n",
      "conf_matrix =  [[626   2]\n",
      " [  0  67]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 2.9850746268656714\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "PeterFilter-Gaussian NB\n",
      "roc_auc =  0.5931290997243084\n",
      "precision =  0.32653061224489793\n",
      "recall =  0.23880597014925373\n",
      "f1 =  0.27586206896551724\n",
      "conf_matrix =  [[595  33]\n",
      " [ 51  16]]\n",
      "Number of correct predictions (%): 23.88059701492537\n",
      "Number of incorrect predictions (%): 49.25373134328358\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "TCA-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[628   0]\n",
      " [ 67   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "Bruakfilter-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  0.09640287769784173\n",
      "recall =  1.0\n",
      "f1 =  0.1758530183727034\n",
      "conf_matrix =  [[  0 628]\n",
      " [  0  67]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 937.3134328358209\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.6829427702253066\n",
      "precision =  0.165625\n",
      "recall =  0.7910447761194029\n",
      "f1 =  0.2739018087855297\n",
      "conf_matrix =  [[361 267]\n",
      " [ 14  53]]\n",
      "Number of correct predictions (%): 79.1044776119403\n",
      "Number of incorrect predictions (%): 398.5074626865672\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.5852623823557371\n",
      "precision =  0.2111111111111111\n",
      "recall =  0.2835820895522388\n",
      "f1 =  0.24203821656050956\n",
      "conf_matrix =  [[557  71]\n",
      " [ 48  19]]\n",
      "Number of correct predictions (%): 28.35820895522388\n",
      "Number of incorrect predictions (%): 105.97014925373134\n"
     ]
    }
   ],
   "source": [
    "# ML Files\n",
    "\n",
    "# DSBF-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yr()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DSBF-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#DTB-KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA_AdaBoost\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"TCA-AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.3618390422647574, n_estimators=11, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter-KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lr()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Bruakfilter - KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lr()\n",
    "tca= TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"TCA-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter_NB\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"PeterFilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"TCA-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yr()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Bruakfilter-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lr()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tr()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6477c8e1-e08c-4828-8d59-1d24ccf69561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DSBF-Ridge\n",
      "roc_auc =  0.9555555555555555\n",
      "precision =  1.0\n",
      "recall =  0.9111111111111111\n",
      "f1 =  0.9534883720930233\n",
      "conf_matrix =  [[1023    0]\n",
      " [   8   82]]\n",
      "Number of correct predictions (%): 91.11111111111111\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DTB-KNN\n",
      "roc_auc =  0.5403370348723944\n",
      "precision =  0.09344262295081968\n",
      "recall =  0.3931034482758621\n",
      "f1 =  0.1509933774834437\n",
      "conf_matrix =  [[1217  553]\n",
      " [  88   57]]\n",
      "Number of correct predictions (%): 39.310344827586206\n",
      "Number of incorrect predictions (%): 381.37931034482756\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "TCA-AdaBoost\n",
      "roc_auc =  0.8931034482758621\n",
      "precision =  1.0\n",
      "recall =  0.7862068965517242\n",
      "f1 =  0.8803088803088803\n",
      "conf_matrix =  [[1770    0]\n",
      " [  31  114]]\n",
      "Number of correct predictions (%): 78.62068965517241\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "Bruakfilter - KNN\n",
      "roc_auc =  0.8784628872004676\n",
      "precision =  0.9734513274336283\n",
      "recall =  0.7586206896551724\n",
      "f1 =  0.8527131782945736\n",
      "conf_matrix =  [[1767    3]\n",
      " [  35  110]]\n",
      "Number of correct predictions (%): 75.86206896551724\n",
      "Number of incorrect predictions (%): 2.0689655172413794\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "TCA-Ridge\n",
      "roc_auc =  0.9997175141242938\n",
      "precision =  0.9931506849315068\n",
      "recall =  1.0\n",
      "f1 =  0.9965635738831615\n",
      "conf_matrix =  [[1769    1]\n",
      " [   0  145]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.6896551724137931\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "PeterFilter-Gaussian NB\n",
      "roc_auc =  0.6846288720046757\n",
      "precision =  0.6511627906976745\n",
      "recall =  0.38620689655172413\n",
      "f1 =  0.48484848484848475\n",
      "conf_matrix =  [[1740   30]\n",
      " [  89   56]]\n",
      "Number of correct predictions (%): 38.62068965517241\n",
      "Number of incorrect predictions (%): 20.689655172413794\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "TCA-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[1770    0]\n",
      " [ 145    0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "Bruakfilter-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  0.07571801566579635\n",
      "recall =  1.0\n",
      "f1 =  0.1407766990291262\n",
      "conf_matrix =  [[   0 1770]\n",
      " [   0  145]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 1220.689655172414\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.6818332359244106\n",
      "precision =  0.24149659863945577\n",
      "recall =  0.4896551724137931\n",
      "f1 =  0.32346241457858765\n",
      "conf_matrix =  [[1547  223]\n",
      " [  74   71]]\n",
      "Number of correct predictions (%): 48.96551724137931\n",
      "Number of incorrect predictions (%): 153.79310344827587\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (1915, 17)\n",
      "Y_target2 =  (1915,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.5941944282096241\n",
      "precision =  0.2535211267605634\n",
      "recall =  0.2482758620689655\n",
      "f1 =  0.25087108013937287\n",
      "conf_matrix =  [[1664  106]\n",
      " [ 109   36]]\n",
      "Number of correct predictions (%): 24.82758620689655\n",
      "Number of incorrect predictions (%): 73.10344827586206\n"
     ]
    }
   ],
   "source": [
    "# Non-ML Files\n",
    "\n",
    "# DSBF-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yr()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DSBF-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#DTB-KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA_AdaBoost\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"TCA-AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.3618390422647574, n_estimators=11, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter-KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lr()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Bruakfilter - KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lr()\n",
    "tca= TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"TCA-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter_NB\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"PeterFilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jr()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"TCA-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yr()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Bruakfilter-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lr()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_tr()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa5ee4-2d0d-4a21-a8dc-ce358d209534",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5878cc01-363d-4d60-976b-a0d9c8076449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_test_data1 = transformers_ml_full_data.copy()\n",
    "    transformers_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    transformers_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = transformers_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = transformers_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = transformers_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = transformers_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_lt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_test_data1 = transformers_ml_full_data.copy()\n",
    "    transformers_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    transformers_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = lightning_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = lightning_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = transformers_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = transformers_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_rt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_test_data1 = transformers_ml_full_data.copy()\n",
    "    transformers_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    transformers_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = ray_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = ray_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = transformers_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = transformers_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_yt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data1 = transformers_ml_full_data.copy()\n",
    "    transformers_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    transformers_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = transformers_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = transformers_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = transformers_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = transformers_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1d7861c9-cca4-4077-9235-54337566e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "TCA-CART\n",
      "roc_auc =  0.9640998870365933\n",
      "precision =  0.8936170212765957\n",
      "recall =  0.9618320610687023\n",
      "f1 =  0.9264705882352942\n",
      "conf_matrix =  [[431  15]\n",
      " [  5 126]]\n",
      "Number of correct predictions (%): 96.18320610687023\n",
      "Number of incorrect predictions (%): 11.450381679389313\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "TCA-Random FOrest\n",
      "roc_auc =  0.9029850746268657\n",
      "precision =  1.0\n",
      "recall =  0.8059701492537313\n",
      "f1 =  0.8925619834710743\n",
      "conf_matrix =  [[628   0]\n",
      " [ 13  54]]\n",
      "Number of correct predictions (%): 80.59701492537313\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Peterfilter-Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[1288    0]\n",
      " [   0  103]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Universal-Ridge\n",
      "roc_auc =  0.8670400410058494\n",
      "precision =  0.2361111111111111\n",
      "recall =  0.9902912621359223\n",
      "f1 =  0.38130841121495324\n",
      "conf_matrix =  [[958 330]\n",
      " [  1 102]]\n",
      "Number of correct predictions (%): 99.02912621359224\n",
      "Number of incorrect predictions (%): 320.3883495145631\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DSBF-Gaussian NB\n",
      "roc_auc =  0.9231638418079097\n",
      "precision =  0.31313131313131315\n",
      "recall =  1.0\n",
      "f1 =  0.47692307692307695\n",
      "conf_matrix =  [[749 136]\n",
      " [  0  62]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 219.3548387096774\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Bruakfilter - KNN\n",
      "roc_auc =  0.6194029850746269\n",
      "precision =  1.0\n",
      "recall =  0.23880597014925373\n",
      "f1 =  0.38554216867469876\n",
      "conf_matrix =  [[628   0]\n",
      " [ 51  16]]\n",
      "Number of correct predictions (%): 23.88059701492537\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.5582517349557943\n",
      "precision =  0.11386138613861387\n",
      "recall =  0.6865671641791045\n",
      "f1 =  0.19532908704883228\n",
      "conf_matrix =  [[270 358]\n",
      " [ 21  46]]\n",
      "Number of correct predictions (%): 68.65671641791045\n",
      "Number of incorrect predictions (%): 534.3283582089553\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "PeterFilter-Gaussian NB\n",
      "roc_auc =  0.617109516113699\n",
      "precision =  0.38\n",
      "recall =  0.2835820895522388\n",
      "f1 =  0.32478632478632474\n",
      "conf_matrix =  [[597  31]\n",
      " [ 48  19]]\n",
      "Number of correct predictions (%): 28.35820895522388\n",
      "Number of incorrect predictions (%): 46.26865671641791\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "TCA-Ridge\n",
      "roc_auc =  0.970873786407767\n",
      "precision =  1.0\n",
      "recall =  0.941747572815534\n",
      "f1 =  0.97\n",
      "conf_matrix =  [[1288    0]\n",
      " [   6   97]]\n",
      "Number of correct predictions (%): 94.1747572815534\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.5101364198117692\n",
      "precision =  0.10989010989010989\n",
      "recall =  0.14925373134328357\n",
      "f1 =  0.12658227848101264\n",
      "conf_matrix =  [[547  81]\n",
      " [ 57  10]]\n",
      "Number of correct predictions (%): 14.925373134328357\n",
      "Number of incorrect predictions (%): 120.89552238805969\n"
     ]
    }
   ],
   "source": [
    "# ML Files\n",
    "\n",
    "# TCA-CART\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lt()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"TCA-CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=7, max_features='sqrt', min_samples_split= 5, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#TCA-RandomForest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"TCA-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter-RandomForest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yt()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Peterfilter-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Universal_Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yt()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Universal-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yt()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DSBF-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter- KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Bruakfilter - KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"PeterFilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jt()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"TCA-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "86171157-d36a-4831-9ef6-5c866507231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (577, 17)\n",
      "Y_target1 =  (577,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "TCA-CART\n",
      "roc_auc =  0.980276134122288\n",
      "precision =  0.23076923076923078\n",
      "recall =  1.0\n",
      "f1 =  0.375\n",
      "conf_matrix =  [[487  20]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 333.33333333333337\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "TCA-Random FOrest\n",
      "roc_auc =  0.9921104536489153\n",
      "precision =  0.42857142857142855\n",
      "recall =  1.0\n",
      "f1 =  0.6\n",
      "conf_matrix =  [[499   8]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 133.33333333333331\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Peterfilter-Random FOrest\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Universal-Ridge\n",
      "roc_auc =  0.995069033530572\n",
      "precision =  0.5454545454545454\n",
      "recall =  1.0\n",
      "f1 =  0.7058823529411764\n",
      "conf_matrix =  [[502   5]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 83.33333333333334\n",
      "X_source =  (103, 17)\n",
      "Y_source =  (103,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DSBF-Gaussian NB\n",
      "roc_auc =  0.9771428571428572\n",
      "precision =  0.2\n",
      "recall =  1.0\n",
      "f1 =  0.33333333333333337\n",
      "conf_matrix =  [[167   8]\n",
      " [  0   2]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 400.0\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Bruakfilter - KNN\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.3510848126232742\n",
      "precision =  0.006211180124223602\n",
      "recall =  0.3333333333333333\n",
      "f1 =  0.012195121951219511\n",
      "conf_matrix =  [[187 320]\n",
      " [  4   2]]\n",
      "Number of correct predictions (%): 33.33333333333333\n",
      "Number of incorrect predictions (%): 5333.333333333334\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "PeterFilter-Gaussian NB\n",
      "roc_auc =  0.4294871794871795\n",
      "precision =  0.01002004008016032\n",
      "recall =  0.8333333333333334\n",
      "f1 =  0.019801980198019802\n",
      "conf_matrix =  [[ 13 494]\n",
      " [  1   5]]\n",
      "Number of correct predictions (%): 83.33333333333334\n",
      "Number of incorrect predictions (%): 8233.333333333332\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (1391, 17)\n",
      "Y_target1 =  (1391,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "TCA-Ridge\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (849, 17)\n",
      "Y_source =  (849,)\n",
      "X_target1 =  (695, 17)\n",
      "Y_target1 =  (695,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.46449704142011833\n",
      "precision =  0.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[471  36]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 600.0\n"
     ]
    }
   ],
   "source": [
    "# Non-ML Files\n",
    "\n",
    "# TCA-CART\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_lt()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"TCA-CART\")\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=7, max_features='sqrt', min_samples_split= 5, splitter='best', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "#TCA-RandomForest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"TCA-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter-RandomForest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yt()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Peterfilter-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Universal_Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yt()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Universal-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_yt()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DSBF-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter- KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Bruakfilter - KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB-MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter-Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"PeterFilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# TCA - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_jt()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"TCA-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_rt()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44f1a6-1962-4239-81d8-edde117013b5",
   "metadata": {},
   "source": [
    "## Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "162a3526-d43c-4652-9074-a9143451a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jy():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    yolov5_test_data1 = yolov5_ml_full_data.copy()\n",
    "    yolov5_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    yolov5_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    yolov5_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = yolov5_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = yolov5_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = yolov5_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = yolov5_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_ly():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    yolov5_test_data1 = yolov5_ml_full_data.copy()\n",
    "    yolov5_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    yolov5_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    yolov5_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = yolov5_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = yolov5_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = yolov5_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = yolov5_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "\n",
    "def data_loading_ry():\n",
    "    # Load your dataset (replace X and y with your features and labels)    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    yolov5_test_data1 = yolov5_ml_full_data.copy()\n",
    "    yolov5_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    yolov5_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    yolov5_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = yolov5_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = yolov5_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = yolov5_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = yolov5_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2\n",
    "\n",
    "def data_loading_ty():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    yolov5_test_data1 = yolov5_ml_full_data.copy()\n",
    "    yolov5_test_data1.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    yolov5_test_data2 =  transformers_non_ml_full_data.copy()\n",
    "    yolov5_test_data2.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "      #jax_test_data.shape\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    # For ML Files\n",
    "    X_target1 = yolov5_test_data1.drop(columns='Buggy')\n",
    "    Y_target1 = yolov5_test_data1['Buggy']\n",
    "    # For Non-ML Files\n",
    "    X_target2 = yolov5_test_data2.drop(columns='Buggy')\n",
    "    Y_target2 = yolov5_test_data2['Buggy']\n",
    "    \n",
    "    print(\"X_source = \", X_source.shape)\n",
    "    print(\"Y_source = \", Y_source.shape)\n",
    "    print(\"X_target1 = \", X_target1.shape)\n",
    "    print(\"Y_target1 = \", Y_target1.shape)\n",
    "    print(\"X_target2 = \", X_target2.shape)\n",
    "    print(\"Y_target2 = \", Y_target2.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target1 = X_target1.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target1 = Y_target1.to_numpy()\n",
    "    X_target2 = X_target2.to_numpy()\n",
    "    Y_target2 = Y_target2.to_numpy()\n",
    "    return X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e35880ba-a6c4-4cfd-88df-bc9983f639b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.4294117647058824\n",
      "precision =  0.5\n",
      "recall =  0.058823529411764705\n",
      "f1 =  0.10526315789473684\n",
      "conf_matrix =  [[ 8  2]\n",
      " [32  2]]\n",
      "Number of correct predictions (%): 5.88235294117647\n",
      "Number of incorrect predictions (%): 5.88235294117647\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DS-Gaussian NB\n",
      "roc_auc =  0.8705882352941177\n",
      "precision =  0.9411764705882353\n",
      "recall =  0.9411764705882353\n",
      "f1 =  0.9411764705882353\n",
      "conf_matrix =  [[ 8  2]\n",
      " [ 2 32]]\n",
      "Number of correct predictions (%): 94.11764705882352\n",
      "Number of incorrect predictions (%): 5.88235294117647\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Bruakfilter - KNN\n",
      "roc_auc =  0.9264705882352942\n",
      "precision =  1.0\n",
      "recall =  0.8529411764705882\n",
      "f1 =  0.9206349206349206\n",
      "conf_matrix =  [[10  0]\n",
      " [ 5 29]]\n",
      "Number of correct predictions (%): 85.29411764705883\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.6538461538461539\n",
      "precision =  1.0\n",
      "recall =  0.3076923076923077\n",
      "f1 =  0.47058823529411764\n",
      "conf_matrix =  [[ 9  0]\n",
      " [18  8]]\n",
      "Number of correct predictions (%): 30.76923076923077\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "PeterFilter-Gaussian NB\n",
      "roc_auc =  0.7352941176470589\n",
      "precision =  1.0\n",
      "recall =  0.47058823529411764\n",
      "f1 =  0.6399999999999999\n",
      "conf_matrix =  [[10  0]\n",
      " [18 16]]\n",
      "Number of correct predictions (%): 47.05882352941176\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DBSF-Ridge\n",
      "roc_auc =  0.9038461538461539\n",
      "precision =  1.0\n",
      "recall =  0.8076923076923077\n",
      "f1 =  0.8936170212765957\n",
      "conf_matrix =  [[ 9  0]\n",
      " [ 5 21]]\n",
      "Number of correct predictions (%): 80.76923076923077\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Universal-AdaBoost\n",
      "roc_auc =  0.8088235294117647\n",
      "precision =  1.0\n",
      "recall =  0.6176470588235294\n",
      "f1 =  0.7636363636363637\n",
      "conf_matrix =  [[10  0]\n",
      " [13 21]]\n",
      "Number of correct predictions (%): 61.76470588235294\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DS-Random FOrest\n",
      "roc_auc =  0.5588235294117647\n",
      "precision =  1.0\n",
      "recall =  0.11764705882352941\n",
      "f1 =  0.21052631578947367\n",
      "conf_matrix =  [[10  0]\n",
      " [30  4]]\n",
      "Number of correct predictions (%): 11.76470588235294\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-Gaussian NB\n",
      "roc_auc =  0.7970588235294118\n",
      "precision =  0.9310344827586207\n",
      "recall =  0.7941176470588235\n",
      "f1 =  0.8571428571428571\n",
      "conf_matrix =  [[ 8  2]\n",
      " [ 7 27]]\n",
      "Number of correct predictions (%): 79.41176470588235\n",
      "Number of incorrect predictions (%): 5.88235294117647\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Peterfilter-Ridge\n",
      "roc_auc =  0.7176470588235294\n",
      "precision =  0.8928571428571429\n",
      "recall =  0.7352941176470589\n",
      "f1 =  0.806451612903226\n",
      "conf_matrix =  [[ 7  3]\n",
      " [ 9 25]]\n",
      "Number of correct predictions (%): 73.52941176470588\n",
      "Number of incorrect predictions (%): 8.823529411764707\n"
     ]
    }
   ],
   "source": [
    "# ML Files\n",
    "\n",
    "\n",
    "# DTB-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Data Selection - Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ly()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target1, Y_target1, loc)\n",
    "print(\"DS-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter - KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Bruakfilter - KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ty()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter - NB\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2= data_loading_jy()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"PeterFilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ly()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DBSF-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Universal - AdaBoost\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Universal-AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.3618390422647574, n_estimators=11, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DS - Random Forest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ty()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target1, Y_target1, loc)\n",
    "print(\"DS-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"DTB-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ly()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target1, Y_target1)\n",
    "print(\"Peterfilter-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aa865246-ea06-499f-9151-a757969bc75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-Ridge\n",
      "roc_auc =  0.9230769230769231\n",
      "precision =  0.07142857142857142\n",
      "recall =  1.0\n",
      "f1 =  0.13333333333333333\n",
      "conf_matrix =  [[429  78]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 1300.0\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DS-Gaussian NB\n",
      "roc_auc =  0.6094674556213017\n",
      "precision =  0.03333333333333333\n",
      "recall =  0.3333333333333333\n",
      "f1 =  0.0606060606060606\n",
      "conf_matrix =  [[449  58]\n",
      " [  4   2]]\n",
      "Number of correct predictions (%): 33.33333333333333\n",
      "Number of incorrect predictions (%): 966.6666666666666\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Bruakfilter - KNN\n",
      "roc_auc =  0.9146942800788955\n",
      "precision =  0.7142857142857143\n",
      "recall =  0.8333333333333334\n",
      "f1 =  0.7692307692307692\n",
      "conf_matrix =  [[505   2]\n",
      " [  1   5]]\n",
      "Number of correct predictions (%): 83.33333333333334\n",
      "Number of incorrect predictions (%): 33.33333333333333\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-MLP\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[175   0]\n",
      " [  2   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (1266, 17)\n",
      "Y_source =  (1266,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "PeterFilter-Gaussian NB\n",
      "roc_auc =  0.6839250493096648\n",
      "precision =  0.02074688796680498\n",
      "recall =  0.8333333333333334\n",
      "f1 =  0.04048582995951417\n",
      "conf_matrix =  [[271 236]\n",
      " [  1   5]]\n",
      "Number of correct predictions (%): 83.33333333333334\n",
      "Number of incorrect predictions (%): 3933.3333333333335\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DBSF-Ridge\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[175   0]\n",
      " [  0   2]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Universal-AdaBoost\n",
      "roc_auc =  1.0\n",
      "precision =  1.0\n",
      "recall =  1.0\n",
      "f1 =  1.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (3839, 17)\n",
      "Y_source =  (3839,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DS-Random FOrest\n",
      "roc_auc =  0.5\n",
      "precision =  1.0\n",
      "recall =  0.0\n",
      "f1 =  0.0\n",
      "conf_matrix =  [[507   0]\n",
      " [  6   0]]\n",
      "Number of correct predictions (%): 0.0\n",
      "Number of incorrect predictions (%): 0.0\n",
      "X_source =  (6778, 17)\n",
      "Y_source =  (6778,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "DTB-Gaussian NB\n",
      "roc_auc =  0.9635108481262327\n",
      "precision =  0.13953488372093023\n",
      "recall =  1.0\n",
      "f1 =  0.24489795918367346\n",
      "conf_matrix =  [[470  37]\n",
      " [  0   6]]\n",
      "Number of correct predictions (%): 100.0\n",
      "Number of incorrect predictions (%): 616.6666666666667\n",
      "X_source =  (1820, 17)\n",
      "Y_source =  (1820,)\n",
      "X_target1 =  (44, 17)\n",
      "Y_target1 =  (44,)\n",
      "X_target2 =  (513, 17)\n",
      "Y_target2 =  (513,)\n",
      "Peterfilter-Ridge\n",
      "roc_auc =  0.7184418145956607\n",
      "precision =  0.08571428571428572\n",
      "recall =  0.5\n",
      "f1 =  0.14634146341463414\n",
      "conf_matrix =  [[475  32]\n",
      " [  3   3]]\n",
      "Number of correct predictions (%): 50.0\n",
      "Number of incorrect predictions (%): 533.3333333333333\n"
     ]
    }
   ],
   "source": [
    "# Non-ML Files\n",
    "\n",
    "\n",
    "# DTB-Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Data Selection - Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ly()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target2, Y_target2, loc)\n",
    "print(\"DS-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Bruakfilter - KNN\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Bruakfilter - KNN\")\n",
    "model = KNeighborsClassifier(algorithm='kd_tree', n_neighbors=5)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF - MLP\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ty()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-MLP\")\n",
    "model = MLPClassifier(activation='logistic', alpha=0.0062202779219760335, hidden_layer_sizes=(50,), learning_rate='invscaling', max_iter= 25, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter - NB\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2= data_loading_jy()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"PeterFilter-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DSBF - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ly()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DBSF-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Universal - AdaBoost\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Universal-AdaBoost\")\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate= 0.3618390422647574, n_estimators=11, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DS - Random Forest\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ty()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target2, Y_target2, loc)\n",
    "print(\"DS-Random FOrest\")\n",
    "model = RandomForestClassifier(criterion='gini', max_depth= 4, max_features='log2', min_samples_leaf=5, min_samples_split= 0.1794337157967658, n_estimators=6, random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# DTB - Naive Bayes\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ry()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"DTB-Gaussian NB\")\n",
    "model = GaussianNB(var_smoothing=1e-09)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n",
    "\n",
    "\n",
    "# Peterfilter - Ridge\n",
    "X_source, Y_source, X_target1, Y_target1, X_target2, Y_target2 = data_loading_ly()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target2, Y_target2)\n",
    "print(\"Peterfilter-Ridge\")\n",
    "model = RidgeClassifier(alpha=0.1986668460759633, max_iter=4107, solver='saga', random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target1)\n",
    "print(\"roc_auc = \", roc_auc_score(Y_target1, y_pred))\n",
    "print(\"precision = \", precision_score(Y_target1, y_pred, zero_division=1))\n",
    "print(\"recall = \", recall_score(Y_target1, y_pred))\n",
    "print(\"f1 = \", f1_score(Y_target1, y_pred))\n",
    "conf_mat = confusion_matrix(Y_target1, y_pred)\n",
    "print(\"conf_matrix = \", conf_mat)\n",
    "calculate_correct_incorrect(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e8c21-49f6-4fd9-bf95-705d12df0d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a14fa-14d7-4eb8-b125-98ad4de766d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd8613-5333-4b67-9c35-bce76b083004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3fe280-8564-4f18-83a4-2c95be02a452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
