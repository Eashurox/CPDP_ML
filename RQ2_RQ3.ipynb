{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ce836a8-191e-406c-810d-2746587aa2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd1009-48bb-4a40-b157-f13c27e19a77",
   "metadata": {},
   "source": [
    "# Domain Adaptation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11683916-ac28-4062-bbaa-a811eff6a434",
   "metadata": {},
   "source": [
    "## Bruakfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7855c323-959a-471b-acba-7bdf659eb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bruakfilter(object):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        Xsource = np.log(Xsource + 1)\n",
    "        Xtarget = np.log(Xtarget + 1)\n",
    "\n",
    "        if self.n_neighbors > Xsource.shape[0]:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        knn = NearestNeighbors()\n",
    "        knn.fit(Xsource)\n",
    "        data = []\n",
    "        ysel = []\n",
    "\n",
    "        for item in Xtarget:\n",
    "            tmp = knn.kneighbors(item.reshape(1, -1), self.n_neighbors, return_distance=False)\n",
    "            tmp = tmp[0]\n",
    "            for i in tmp:\n",
    "                if list(Xsource[i]) not in data:\n",
    "                    data.append(list(Xsource[i]))\n",
    "                    ysel.append(Ysource[i])\n",
    "        Xsource = np.asanyarray(data)\n",
    "        Ysource = np.asanyarray(ysel)\n",
    "\n",
    "        return Xsource, Ysource, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc76b09-78bc-46db-ac74-76cc694b877f",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa63824-0443-4733-ae69-b9ec775eec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSelection(object):\n",
    "    def __init__(self, topN=5, FSS=0.2):\n",
    "        self.topN = topN\n",
    "        self.FSS = FSS\n",
    "\n",
    "    def _sample(self, Xsource, Xtarget):\n",
    "        K = min(500, Xsource.shape[0], Xtarget.shape[0])\n",
    "        Ltrain = np.ones(K)\n",
    "        Ltest = np.ones(K) * -1\n",
    "\n",
    "        Train = random.sample(range(Xsource.shape[0]), Xsource.shape[0] - K)\n",
    "        Test = random.sample(range(Xtarget.shape[0]), Xtarget.shape[0] - K)\n",
    "        Train = np.delete(Xsource, Train, axis=0)\n",
    "        Test = np.delete(Xtarget, Test, axis=0)\n",
    "\n",
    "        data = np.concatenate((Train, Test), axis=0)\n",
    "        label = np.concatenate((Ltrain, Ltest), axis=0)\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def _calDistance(self, Xsource, Xtarget):\n",
    "        acc = np.zeros(10)\n",
    "        for i in range(10):\n",
    "            x, y = self._sample(Xsource, Xtarget)\n",
    "            lr = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "            acc[i] = np.mean(cross_val_score(lr, x, y, scoring='accuracy', cv=5))\n",
    "        return 2 * abs((np.mean(acc) - 0.5))\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget, loc):\n",
    "        self.topN = min(self.topN, len(loc))\n",
    "        dist = dict()\n",
    "\n",
    "        for i in range(len(loc)):\n",
    "            if i < len(loc) - 1:\n",
    "                train = Xsource[loc[i]:loc[i + 1]]\n",
    "                dist[i] = self._calDistance(train, Xtarget)\n",
    "            else:\n",
    "                train = Xsource[loc[i]:]\n",
    "                dist[i] = self._calDistance(train, Xtarget)\n",
    "\n",
    "        dist = sorted(dist.items(), key=lambda d: d[1])\n",
    "        i = dist[0][0]\n",
    "        if i != len(loc) - 1:\n",
    "            x = Xsource[loc[i]:loc[i + 1] ]\n",
    "            y = Ysource[loc[i]:loc[i + 1] ]\n",
    "        else:\n",
    "            x = Xsource[loc[i]:]\n",
    "            y = Ysource[loc[i]:]\n",
    "\n",
    "        for i in range(1, self.topN):\n",
    "            index = dist[i][0]\n",
    "            if index < len(loc) - 1:\n",
    "                tmp = Xsource[loc[index]:loc[index + 1] ]\n",
    "                temp = Ysource[loc[index]:loc[index + 1] ]\n",
    "            else:\n",
    "                tmp = Xsource[loc[index]:]\n",
    "                temp = Ysource[loc[index]:]\n",
    "            x = np.concatenate((x, tmp), axis=0)\n",
    "            y = np.concatenate((y, temp), axis=0)\n",
    "\n",
    "        fx, fy = self._sample(x, Xtarget)\n",
    "        lr = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "        lr.fit(fx, fy)\n",
    "        coef = dict()\n",
    "        for i in range(Xsource.shape[1]):\n",
    "            coef[i] = lr.coef_[0][i]\n",
    "        coef = sorted(coef.items(), key=lambda d: d[1], reverse=True)\n",
    "\n",
    "        dump = []\n",
    "        for i in range(int(Xsource.shape[1] * self.FSS)):\n",
    "            dump.append(coef[i][0])\n",
    "\n",
    "        x = np.delete(x, dump, axis=1)\n",
    "        Xtarget = np.delete(Xtarget, dump, axis=1)\n",
    "\n",
    "        return x, y, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650b796-0031-4b60-91c8-a04eb0145d49",
   "metadata": {},
   "source": [
    "## DSBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6375eb2-de2d-4614-87a9-41d810fd87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSBF\n",
    "class DSBF(object):\n",
    "    def __init__(self, topK=1, neighbors=10):\n",
    "        self.topK = int(topK)\n",
    "        self.neighbors = neighbors\n",
    "\n",
    "    def featureReduction(self, source, target):\n",
    "        d = pdist(target.T, metric='euclidean')\n",
    "        D = squareform(d)\n",
    "        dist = D.copy()\n",
    "        D = np.zeros(D.shape)\n",
    "\n",
    "        for i in range(target.shape[1]):\n",
    "            index = np.argsort(dist[i])\n",
    "            count = 0\n",
    "            for j in range(len(index)):\n",
    "                if count < self.topK and index[j] != i:\n",
    "                    D[i][index[j]] = 1\n",
    "                    count += 1\n",
    "\n",
    "        V = np.sum(D, axis=0)\n",
    "        V[V < 1e-6] = 0\n",
    "        index = np.where(V != 0)\n",
    "        target = np.delete(target, index, axis=1)\n",
    "        source = np.delete(source, index, axis=1)\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    def outlierRemove(self, target, ys):\n",
    "        d = pdist(target, metric='euclidean')\n",
    "        D = squareform(d)\n",
    "        dist = D.copy()\n",
    "        D = np.zeros(D.shape)\n",
    "        for i in range(target.shape[0]):\n",
    "            index = np.argsort(dist[i])\n",
    "            count = 0\n",
    "            for j in range(len(index)):\n",
    "                if count < self.topK and index[j] != i:\n",
    "                    D[i][index[j]] = 1\n",
    "                    count += 1\n",
    "        V = np.sum(D, axis=0)\n",
    "        V[V < 1e-6] = 0\n",
    "        index = np.where(V == 0)\n",
    "        target = np.delete(target, index, axis=0)\n",
    "        ys = np.delete(ys, index, axis=0)\n",
    "        return target, ys\n",
    "\n",
    "    def Bruakfilter(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        Xsource = np.log(Xsource + 1)\n",
    "        Xtarget = np.log(Xtarget + 1)\n",
    "\n",
    "        if self.neighbors > Xsource.shape[0]:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        knn = NearestNeighbors()\n",
    "        knn.fit(Xsource)\n",
    "        data = []\n",
    "        ysel = []\n",
    "\n",
    "        for item in Xtarget:\n",
    "            tmp = knn.kneighbors(item.reshape(1, -1), self.neighbors, return_distance=False)\n",
    "            tmp = tmp[0]\n",
    "            for i in tmp:\n",
    "                if list(Xsource[i]) not in data:\n",
    "                    data.append(list(Xsource[i]))\n",
    "                    ysel.append(Ysource[i])\n",
    "        Xsource = np.asanyarray(data)\n",
    "        Ysource = np.asanyarray(ysel)\n",
    "\n",
    "        return Xsource, Ysource, Xtarget, Ytarget\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        Xsource, Xtarget = self.featureReduction(Xsource, Xtarget)\n",
    "        if Xsource.shape[1] == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xsource, Ysource = self.outlierRemove(Xsource, Ysource)\n",
    "        if len(Xsource) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xtarget, Ytarget = self.outlierRemove(Xtarget, Ytarget)\n",
    "        if len(Xtarget) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xsource, Ysource, Xtarget, Ytarget = self.Bruakfilter(Xsource, Ysource, Xtarget, Ytarget)\n",
    "        if len(Xsource) == 0 or len(Xtarget) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        Xsource, Ysource = self.outlierRemove(Xsource, Ysource)\n",
    "        if len(Xsource) == 0 or len(Xtarget) == 0:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        return Xsource, Ysource, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc79271-e675-4e6a-85d0-6065797f3c1f",
   "metadata": {},
   "source": [
    "## DTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee452e8-7f86-4d81-b5c1-0f61ebdf6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTB(object):\n",
    "    def __init__(self, n_neighbors=10, iter=20):\n",
    "        self.n_neighbors = int(n_neighbors)\n",
    "        self.iter = iter\n",
    "\n",
    "    def _NNfilter(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        knn = NearestNeighbors()\n",
    "        knn.fit(Xsource)\n",
    "        data = []\n",
    "        ysel = []\n",
    "\n",
    "        for item in Xtarget:\n",
    "            tmp = knn.kneighbors(item.reshape(1, -1), self.n_neighbors, return_distance=False)\n",
    "            tmp = tmp[0]\n",
    "            for i in tmp:\n",
    "                if list(Xsource[i]) not in data:\n",
    "                    data.append(list(Xsource[i]))\n",
    "                    ysel.append(Ysource[i])\n",
    "        Xsource = np.asanyarray(data)\n",
    "        Ysource = np.asanyarray(ysel)\n",
    "        return Xsource, Ysource\n",
    "\n",
    "    # oversample for minor part\n",
    "    def _SMOTE(self, Xsource, Ysource):\n",
    "        smote = SMOTE()\n",
    "        Xsource, Ysource = smote.fit_resample(Xsource, Ysource)\n",
    "        return Xsource, Ysource\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "      Xsource, Ysource = self._NNfilter(Xsource, Ysource, Xtarget, Ytarget)\n",
    "      Xsource, Ysource = self._SMOTE(Xsource, Ysource)\n",
    "      return Xsource, Ysource, Xtarget, Ytarget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99fa752-0297-447a-b00e-7b080cf60040",
   "metadata": {},
   "source": [
    "## Peterfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aee02a8-7d6a-403a-b75a-8eded59fb9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Peterfilter(object):\n",
    "    def __init__(self, eachCluster=50):\n",
    "        self.eachCluster = eachCluster\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        self.Xsource = Xsource\n",
    "        self.Xtarget = Xtarget\n",
    "        self.Ysource = Ysource\n",
    "        self.Ytarget = Ytarget\n",
    "        data = np.concatenate((self.Xsource, self.Xtarget), axis=0)\n",
    "        if self.eachCluster == 0:\n",
    "            return 0,0,0,0\n",
    "        n_cluster = int(self.Xsource.shape[0] / self.eachCluster)\n",
    "        if n_cluster == 0:\n",
    "            return 0, 0, 0, 0\n",
    "        kmeans = KMeans(n_clusters=n_cluster)\n",
    "        kmeans.fit(data)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # remove the clusters where have no test instance\n",
    "        cluster = dict()\n",
    "        for i in range(n_cluster):\n",
    "            cluster[i] = []\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            cluster[labels[i]].append(i)\n",
    "\n",
    "        chosenCluster = []\n",
    "        for i in range(self.Xsource.shape[0], data.shape[0]):\n",
    "            for j in range(n_cluster):\n",
    "                if i in cluster[j] and (j not in chosenCluster):\n",
    "                    chosenCluster.append(j)\n",
    "\n",
    "        # choose train instance in each cluster\n",
    "        out = []\n",
    "        for i in range(len(chosenCluster)):\n",
    "            test = []\n",
    "            indexTest = []\n",
    "            train = []\n",
    "            indexTrain = []\n",
    "            for item in cluster[chosenCluster[i]]:\n",
    "                if item >= self.Xsource.shape[0] and item < data.shape[0]:\n",
    "                    test.append(list(data[item]))\n",
    "                    indexTest.append(item)\n",
    "                else:\n",
    "                    train.append(list(self.Xsource[item]))\n",
    "                    indexTrain.append(item)\n",
    "\n",
    "            if len(train) == 0:\n",
    "                break\n",
    "            Testfans = np.zeros((len(indexTest), len(indexTrain)))\n",
    "\n",
    "            neigh = NearestNeighbors(n_neighbors=1)\n",
    "            neigh.fit(np.asarray(test))\n",
    "            for item in train:\n",
    "                index = neigh.kneighbors(np.asarray(item).reshape(1, -1), return_distance=False)\n",
    "                Testfans[index[0][0], train.index(item)] += 1\n",
    "\n",
    "            for i in range(len(test)):\n",
    "                index = np.argmax(Testfans[i])\n",
    "                if indexTrain[index] not in out:\n",
    "                    out.append(indexTrain[index])\n",
    "\n",
    "        tmp = np.zeros((len(out), self.Xsource.shape[1]))\n",
    "        tmpl = np.zeros(len(out))\n",
    "        for i in range(len(out)):\n",
    "            tmp[i] = self.Xsource[out[i]]\n",
    "            tmpl[i] = self.Ysource[out[i]]\n",
    "\n",
    "        return tmp, tmpl, Xtarget, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5ee3b-d3e2-4bc7-b6f3-dc8127183344",
   "metadata": {},
   "source": [
    "## TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d37a9287-5f78-400c-a73b-e2ab5e455848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(ker, X, X2, gamma):\n",
    "    if not ker or ker == 'primal':\n",
    "        return X\n",
    "    elif ker == 'linear':\n",
    "        if not X2:\n",
    "            K = np.dot(X.T, X)\n",
    "        else:\n",
    "            K = np.dot(X.T, X2)\n",
    "    elif ker == 'rbf':\n",
    "        n1sq = np.sum(X ** 2, axis=0)\n",
    "        n1 = X.shape[1]\n",
    "        if not X2:\n",
    "            D = (np.ones((n1, 1)) * n1sq).T + np.ones((n1, 1)) * n1sq - 2 * np.dot(X.T, X)\n",
    "        else:\n",
    "            n2sq = np.sum(X2 ** 2, axis=0)\n",
    "            n2 = X2.shape[1]\n",
    "            D = (np.ones((n2, 1)) * n1sq).T + np.ones((n1, 1)) * n2sq - 2 * np.dot(X.T, X)\n",
    "        K = np.exp(-gamma * D)\n",
    "    elif ker == 'sam':\n",
    "        if not X2:\n",
    "            D = np.dot(X.T, X)\n",
    "        else:\n",
    "            D = np.dot(X.T, X2)\n",
    "        K = np.exp(-gamma * np.arccos(D) ** 2)\n",
    "        K[K != K] = 0\n",
    "    return K\n",
    "\n",
    "\n",
    "class TCA(object):\n",
    "    def __init__(self, kernel_type='primal', dim=5, lamb=1, gamma=1):\n",
    "        '''\n",
    "        Init func\n",
    "        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf' | 'sam'\n",
    "        :param dim: dimension after transfer\n",
    "        :param lamb: lambda value in equation\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.dim = dim\n",
    "        self.lamb = lamb\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _normalization(self, type):\n",
    "        ss = self.Xsource.shape\n",
    "        tt = self.Xtarget.shape\n",
    "\n",
    "        if type == 'N1':\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                minm = np.min(tmp)\n",
    "                maxm = np.max(tmp)\n",
    "                res[:, i] = (tmp - minm) / (maxm - minm)\n",
    "            self.Xsource = res\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                minm = np.min(tmp)\n",
    "                maxm = np.max(tmp)\n",
    "                res[:, i] = (tmp - minm) / (maxm - minm)\n",
    "            self.Xtarget = res\n",
    "\n",
    "        elif type == 'N2':\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xsource = res\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xtarget = res\n",
    "\n",
    "        elif type == 'N3':\n",
    "            Smean = []\n",
    "            Sstd = []\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                Smean.append(mean)\n",
    "                Sstd.append(std)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xsource = res\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                mean = Smean[i]\n",
    "                std = Sstd\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xtarget = res\n",
    "\n",
    "        elif type == 'N4':\n",
    "            Smean = []\n",
    "            Sstd = []\n",
    "\n",
    "            # normalization for target data\n",
    "            res = np.zeros((tt[0], tt[1]))\n",
    "            for i in range(tt[1]):\n",
    "                tmp = self.Xtarget[:, i]\n",
    "                mean = np.mean(tmp)\n",
    "                std = np.std(tmp)\n",
    "                Smean.append(mean)\n",
    "                Sstd.append(std)\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xtarget = res\n",
    "\n",
    "            # normalization for source data\n",
    "            res = np.zeros((ss[0], ss[1]))\n",
    "            for i in range(ss[1]):\n",
    "                tmp = self.Xsource[:, i]\n",
    "                mean = Smean[i]\n",
    "                std = Sstd\n",
    "                res[:, i] = (tmp - mean) / std\n",
    "            self.Xsource = res\n",
    "\n",
    "        elif type == 'N0':\n",
    "            return\n",
    "\n",
    "    def _computDCV(self):\n",
    "        ss = self.Xsource.shape\n",
    "        tt = self.Xtarget.shape\n",
    "        Sdist = []\n",
    "        Tdist = []\n",
    "        SDCV = []\n",
    "        TDCV = []\n",
    "\n",
    "        # compute DCV (dataset characteristic vector) of source dataset\n",
    "        for i in range(ss[0]):\n",
    "            for j in range(i + 1, ss[0]):\n",
    "                Sdist.append(dist.euclidean(self.Xsource[i], self.Xsource[j]))\n",
    "        SDCV.append(np.mean(np.asarray(Sdist)))\n",
    "        SDCV.append((np.median(np.asarray(Sdist))))\n",
    "        SDCV.append(np.min(np.asarray(Sdist)))\n",
    "        SDCV.append(np.max(np.asarray(Sdist)))\n",
    "        SDCV.append(np.std(np.asarray(Sdist)))\n",
    "        SDCV.append(ss[0])\n",
    "\n",
    "        # compute DCV (dataset characteristic vector) of target dataset\n",
    "        for i in range(tt[0]):\n",
    "            for j in range(i + 1, tt[0]):\n",
    "                Tdist.append(dist.euclidean(self.Xtarget[i], self.Xtarget[j]))\n",
    "        TDCV.append(np.mean(np.asarray(Tdist)))\n",
    "        TDCV.append((np.median(np.asarray(Tdist))))\n",
    "        TDCV.append(np.min(np.asarray(Tdist)))\n",
    "        TDCV.append(np.max(np.asarray(Tdist)))\n",
    "        TDCV.append(np.std(np.asarray(Tdist)))\n",
    "        TDCV.append(ss[0])\n",
    "\n",
    "        return np.asarray(SDCV), np.asarray(TDCV)\n",
    "\n",
    "    def _chooseNormalization(self):\n",
    "        SDCV, TDCV = self._computDCV()\n",
    "\n",
    "        nominal = []\n",
    "        for i in range(0, 6):\n",
    "            if SDCV[i] * 1.6 < TDCV[i]:\n",
    "                nominal.append('much-more')\n",
    "            elif TDCV[i] < SDCV[i] * 0.4:\n",
    "                nominal.append('much-less')\n",
    "            elif (SDCV[i] * 1.3 < TDCV[i]) and (TDCV[i] <= SDCV[i] * 1.6):\n",
    "                nominal.append('more')\n",
    "            elif (SDCV[i] * 1.1 < TDCV[i]) and (TDCV[i] <= SDCV[i] * 1.3):\n",
    "                nominal.append('slight-more')\n",
    "            elif (SDCV[i] * 0.9 <= TDCV[i]) and (TDCV[i] <= SDCV[i] * 1.1):\n",
    "                nominal.append('same')\n",
    "            elif (SDCV[i] * 0.7 <= TDCV[i]) and (TDCV[i] < SDCV[i] * 0.9):\n",
    "                nominal.append('slight-less')\n",
    "            elif (SDCV[i] * 0.4 <= TDCV[i]) and (TDCV[i] < SDCV[i] * 0.7):\n",
    "                nominal.append('less')\n",
    "\n",
    "        if (nominal[5] == nominal[2] == nominal[3] == 'much-less') or (\n",
    "                nominal[5] == nominal[2] == nominal[3] == 'much-more'):\n",
    "            self._normalization('N1')\n",
    "\n",
    "        elif ((nominal[4] == 'much-more') and ('less' in nominal[5])) or (\n",
    "                (nominal[4] == 'much-less') and ('more' in nominal[5])):\n",
    "            self._normalization('N3')\n",
    "\n",
    "        elif (nominal[4] == nominal[5] == 'much-more') or (nominal[4] == nominal[5] == 'much-less'):\n",
    "            self._normalization('N4')\n",
    "\n",
    "        elif nominal[0] == nominal[4] == 'same':\n",
    "            self._normalization('N0')\n",
    "\n",
    "        else:\n",
    "            self._normalization('N2')\n",
    "\n",
    "    def run(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Transform Xs and Xt\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :return: Xs_new and Xt_new after TCA\n",
    "        '''\n",
    "        self.Xsource = Xs\n",
    "        self.Xtarget = Xt\n",
    "        self._chooseNormalization()\n",
    "        Xs = self.Xsource\n",
    "        Xt = self.Xtarget\n",
    "\n",
    "        X = np.hstack((Xs.T, Xt.T))\n",
    "        X /= np.linalg.norm(X, axis=0)\n",
    "        m, n = X.shape\n",
    "        ns, nt = len(Xs), len(Xt)\n",
    "        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))\n",
    "        M = e * e.T\n",
    "        M = M / np.linalg.norm(M, 'fro')\n",
    "        H = np.eye(n) - 1 / n * np.ones((n, n))\n",
    "        K = kernel(self.kernel_type, X, None, gamma=self.gamma)\n",
    "        n_eye = m if self.kernel_type == 'primal' else n\n",
    "        a, b = np.linalg.multi_dot([K, M, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])\n",
    "        w, V = scipy.linalg.eig(a, b)\n",
    "        ind = np.argsort(w)\n",
    "        A = V[:, ind[:self.dim]]\n",
    "        Z = np.dot(A.T, K)\n",
    "        Z /= np.linalg.norm(Z, axis=0)\n",
    "        Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T\n",
    "        return Xs_new, Ys, Xt_new, Yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9ecca-9a72-497e-9888-44840465eddf",
   "metadata": {},
   "source": [
    "## Universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9749fc48-2244-49af-bb24-51ac26cd6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cliffsDelta(lst1, lst2, **dull):\n",
    "\n",
    "    \"\"\"Returns delta and true if there are more than 'dull' differences\"\"\"\n",
    "    if not dull:\n",
    "        dull = {'small': 0.147, 'medium': 0.33, 'large': 0.474} # effect sizes from (Hess and Kromrey, 2004)\n",
    "    m, n = len(lst1), len(lst2)\n",
    "    lst2 = sorted(lst2)\n",
    "    j = more = less = 0\n",
    "    for repeats, x in runs(sorted(lst1)):\n",
    "        while j <= (n - 1) and lst2[j] < x:\n",
    "            j += 1\n",
    "        more += j*repeats\n",
    "        while j <= (n - 1) and lst2[j] == x:\n",
    "            j += 1\n",
    "        less += (n - j)*repeats\n",
    "    d = (more - less) / (m*n)\n",
    "    size = lookup_size(d, dull)\n",
    "    return d, size\n",
    "\n",
    "def lookup_size(delta: float, dull: dict) -> str:\n",
    "    \"\"\"\n",
    "    :type delta: float\n",
    "    :type dull: dict, a dictionary of small, medium, large thresholds.\n",
    "    \"\"\"\n",
    "    delta = abs(delta)\n",
    "    if delta < dull['small']:\n",
    "        return 'negligible'\n",
    "    if dull['small'] <= delta < dull['medium']:\n",
    "        return 'small'\n",
    "    if dull['medium'] <= delta < dull['large']:\n",
    "        return 'medium'\n",
    "    if delta >= dull['large']:\n",
    "        return 'large'\n",
    "\n",
    "\n",
    "def runs(lst):\n",
    "    \"\"\"Iterator, chunks repeated values\"\"\"\n",
    "    for j, two in enumerate(lst):\n",
    "        if j == 0:\n",
    "            one, i = two, 0\n",
    "        if one != two:\n",
    "            yield j - i, one\n",
    "            i = j\n",
    "        one = two\n",
    "    yield j - i + 1, two\n",
    "\n",
    "\n",
    "def cohen(c0, c1):\n",
    "    cohens_d = (mean(c0) - mean(c1)) / (sqrt((stdev(c0) ** 2 + stdev(c1) ** 2) / 2))\n",
    "    t = abs(cohens_d)\n",
    "    if t <= 0.2:\n",
    "        res = 'negligible'\n",
    "    elif t <= 0.5:\n",
    "        res = 'small'\n",
    "    elif t <= 0.8:\n",
    "        res = 'medium'\n",
    "    else:\n",
    "        res = 'large'\n",
    "\n",
    "    return res\n",
    "    \n",
    "class Universal(object):\n",
    "    def __init__(self, pvalue=0.05, QuantifyType='cliff'):\n",
    "        self.p = pvalue\n",
    "        self.type = QuantifyType\n",
    "\n",
    "    def _compareMetricDistribution(self, x1, x2):\n",
    "        s, p = mannwhitneyu(x1, x2)\n",
    "        if p < self.p:\n",
    "            sig_diff = 1\n",
    "        else:\n",
    "            sig_diff = 0\n",
    "        return sig_diff\n",
    "\n",
    "    def _quantifyDifference(self, x1, x2):\n",
    "        if self.type == 'cliff':\n",
    "            d, res = cliffsDelta(x1, x2)\n",
    "        else:\n",
    "            res = cohen(x1, x2)\n",
    "        return res\n",
    "\n",
    "    def cluster(self, No_metric, numGroup, group):\n",
    "        indexOfCluster = 0\n",
    "        clusterOfGroup = np.zeros(numGroup)\n",
    "\n",
    "        for i in range(0, numGroup-1):\n",
    "            indexNewCluster = indexOfCluster + 1\n",
    "            for j in range(i+1, numGroup):\n",
    "                if self._compareMetricDistribution(group[i][:, No_metric], group[j][:, No_metric]) == 1:\n",
    "                    if self._quantifyDifference(group[i][:, No_metric], group[j][:, No_metric]) == 'large':\n",
    "                        clusterOfGroup[j] = indexNewCluster\n",
    "                        indexOfCluster = indexNewCluster\n",
    "\n",
    "        return clusterOfGroup\n",
    "\n",
    "    def rankTransform(self, xsource, xtarget):\n",
    "        #xsource = xsource.to_numpy()\n",
    "        #xtarget = xtarget.to_numpy()\n",
    "        group = [xsource, xtarget]\n",
    "        resGroup = group.copy()\n",
    "\n",
    "        for i in range(xsource.shape[1]):\n",
    "            clusterIndex = self.cluster(i, len(group), group)\n",
    "            cluster = np.unique(clusterIndex)\n",
    "            for item in cluster:\n",
    "                tmp = np.asarray(np.where(clusterIndex == item))[0]\n",
    "                tmp_data = np.asarray([])\n",
    "                for ncs in tmp:\n",
    "                    tmp_data = np.concatenate((tmp_data, group[int(ncs)][:, i]))\n",
    "\n",
    "                percentiles = np.percentile(sorted(tmp_data), [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "                for ncs in tmp:\n",
    "                    ncs = int(ncs)\n",
    "                    t = resGroup[ncs][:, i]\n",
    "                    for it in range(len(t)):\n",
    "                        if t[it] <= percentiles[0]:\n",
    "                            resGroup[ncs][:, i][it] = 1\n",
    "                        elif t[it] <= percentiles[1]:\n",
    "                            resGroup[ncs][:, i][it] = 2\n",
    "                        elif t[it] <= percentiles[2]:\n",
    "                            resGroup[ncs][:, i][it] = 3\n",
    "                        elif t[it] <= percentiles[3]:\n",
    "                            resGroup[ncs][:, i][it] = 4\n",
    "                        elif t[it] <= percentiles[4]:\n",
    "                            resGroup[ncs][:, i][it] = 5\n",
    "                        elif t[it] <= percentiles[5]:\n",
    "                            resGroup[ncs][:, i][it] = 6\n",
    "                        elif t[it] <= percentiles[6]:\n",
    "                            resGroup[ncs][:, i][it] = 7\n",
    "                        elif t[it] <= percentiles[7]:\n",
    "                            resGroup[ncs][:, i][it] = 8\n",
    "                        elif t[it] <= percentiles[8]:\n",
    "                            resGroup[ncs][:, i][it] = 9\n",
    "                        else:\n",
    "                            resGroup[ncs][:, i][it] = 10\n",
    "        return resGroup\n",
    "\n",
    "    def run(self, Xsource, Ysource, Xtarget, Ytarget):\n",
    "        res = self.rankTransform(Xsource, Xtarget)\n",
    "        source = np.asarray(res[0])\n",
    "        target = res[1]\n",
    "        source = pd.DataFrame(data=source)\n",
    "        target = pd.DataFrame(data=target)\n",
    "\n",
    "        return source, Ysource, target, Ytarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c89d4-f058-422f-9da1-3e08c471fc39",
   "metadata": {},
   "source": [
    "# Classifier's parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ca4e170-f994-4f78-aa5c-f67e0282f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for each classifier\n",
    "rf_space = {\n",
    "    'n_estimators': hp.randint('n_estimators', 1, 50),\n",
    "    'max_depth': hp.randint('max_depth',1,10),\n",
    "    'min_samples_split':hp.uniform('min_samples_split', 0, 1),\n",
    "    'min_samples_leaf':hp.randint('min_samples_leaf',1,10),\n",
    "    'criterion':hp.choice('criterion',['gini','entropy']),\n",
    "    'max_features':hp.choice('max_features',['sqrt','log2'])\n",
    "}\n",
    "\n",
    "ada_space = {\n",
    "    'n_estimators': hp.randint('n_estimators', 1, 50),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 1.0),\n",
    "    'algorithm': hp.choice('algorithm', ['SAMME', 'SAMME.R'])\n",
    "}\n",
    "\n",
    "nb_space = {\n",
    "    'var_smoothing': hp.choice('var_smoothing', [1e-09])\n",
    "}\n",
    "\n",
    "cart_space = {\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "    'max_features': hp.choice('max_features', [None, 'sqrt', 'log2']),\n",
    "    'splitter': hp.choice('splitter', ['best', 'random']),\n",
    "    'max_depth': hp.randint('max_depth',1,10),\n",
    "    'min_samples_split': hp.randint('min_samples_split', 2, 10)\n",
    "}\n",
    "\n",
    "knn_space = {\n",
    "    'n_neighbors': hp.randint('n_neighbors', 5, 17),\n",
    "    'algorithm': hp.choice('algorithm', ['ball_tree', 'kd_tree', 'brute'])\n",
    "}\n",
    "\n",
    "ridge_space = {\n",
    "    'alpha': hp.uniform('alpha', 0.1, 1.0),\n",
    "    'solver': hp.choice('solver', ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']),\n",
    "    'max_iter': hp.randint('max_iter', 1000,15000)\n",
    "}\n",
    "\n",
    "svm_space = {\n",
    "    'C': hp.lognormal('C', 0.1, 1.0),\n",
    "    # 'kernel': hp.choice('kernel', ['linear', 'rbf', 'poly', 'sigmoid']),\n",
    "    'kernel': hp.choice('kernel', ['linear']),\n",
    "    'degree': hp.randint('degree', 1,5),\n",
    "    #'gamma': hp.choice('gamma', ['scale', 'auto'])\n",
    "}\n",
    "\n",
    "mlp_space = {\n",
    "    'activation': hp.choice('activation', ['identity', 'logistic', 'tanh', 'relu']),\n",
    "    'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(50,), (100,), (50, 50)]),\n",
    "    'alpha': hp.uniform('alpha', 0.0001, 0.01),\n",
    "    'learning_rate': hp.choice('learning_rate', ['constant', 'invscaling', 'adaptive']),\n",
    "    'max_iter': hp.randint('max_iter', 10, 100)\n",
    "}\n",
    "\n",
    "\n",
    "algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9da308-e5a7-40ae-a55b-673765df8784",
   "metadata": {},
   "source": [
    "# Classifier's objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd781811-6c3a-45f1-a637-5d058db9e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for hyperparameter optimization\n",
    "def objective_rf(search_space):\n",
    "    model = RandomForestClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}\n",
    "\n",
    "def objective_ada(search_space):\n",
    "    model = AdaBoostClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}\n",
    "\n",
    "def objective_nb(search_space):\n",
    "    model = GaussianNB(**search_space)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}\n",
    "\n",
    "def objective_cart(search_space):\n",
    "    model = DecisionTreeClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}\n",
    "\n",
    "def objective_knn(search_space):\n",
    "    model = KNeighborsClassifier(**search_space)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}\n",
    "\n",
    "def objective_ridge(search_space):\n",
    "    model = RidgeClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}\n",
    "\n",
    "def objective_mlp(search_space):\n",
    "    model = MLPClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}\n",
    "\n",
    "def objective_svm(search_space):\n",
    "    model = SVC(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "    return {'loss': -roc_auc, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67839f1-0fba-4e20-828b-e6430cbd0cae",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26920601-678c-4e1d-97ba-590f1df028f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd6fe4-516c-4ae8-aaae-92fd939b5ec2",
   "metadata": {},
   "source": [
    "# Calling hyperopt for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "082fa43f-d40f-476d-af8d-4f0fbceb3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_classifier():\n",
    "    #implement Hyperopt on Random Forest\n",
    "    best_params_rf = fmin(\n",
    "        fn=objective_rf,\n",
    "        space=rf_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"Random Forest: \", space_eval(rf_space, best_params_rf))\n",
    "    \n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    \n",
    "    #implement Hyperopt on AdaBoost\n",
    "    best_params_ada = fmin(\n",
    "        fn=objective_ada,\n",
    "        space=ada_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"AdaBoost: \", space_eval(ada_space, best_params_ada))\n",
    "    \n",
    "    #implement Hyperopt on CART\n",
    "    best_params_cart = fmin(\n",
    "        fn=objective_cart,\n",
    "        space=cart_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"CART: \", space_eval(cart_space, best_params_cart))\n",
    "    \n",
    "    #implement Hyperopt on KNN\n",
    "    best_params_knn = fmin(\n",
    "        fn=objective_knn,\n",
    "        space=knn_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"KNN: \", space_eval(knn_space, best_params_knn))\n",
    "    \n",
    "    #implement Hyperopt on Ridge\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    \n",
    "    #implement Hyperopt on MLP\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    \n",
    "    #implement Hyperopt on SVM\n",
    "    best_params_svm = fmin(\n",
    "        fn=objective_svm,\n",
    "        space=svm_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"SVM: \", space_eval(svm_space, best_params_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409787b-2b1e-4777-ad41-f782bac870c9",
   "metadata": {},
   "source": [
    "# Running each Domain Adaptation for each classifier - per project pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5083b0-c484-4183-b3f6-a4e82d431d72",
   "metadata": {},
   "source": [
    "## Target: Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d540ad6-294b-4d10-85db-f5e478a00397",
   "metadata": {},
   "source": [
    "### S:Transformer -> T:Ray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b1cc719-353c-40ea-9fad-297bc1797aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.50trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.339516655969867, 'n_estimators': 1}\n",
      "100%|███████| 10/10 [00:00<00:00, 244.39trial/s, best loss: -0.7680452036630142]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 150.49trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.33803588607064866, 'n_estimators': 27}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 209.29trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': None, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.87trial/s, best loss: -0.5009615890932939]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.42trial/s, best loss: -0.7881746681410634]\n",
      "Ridge:  {'alpha': 0.19641169364362276, 'max_iter': 3002, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:01,  4.14trial/s, best loss: -0.5652304462922274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:01,  4.63trial/s, best loss: -0.5652304462922274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  3.41trial/s, best loss: -0.5652304462922274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:01,  2.62trial/s, best loss: -0.5652304462922274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:01,  1.72trial/s, best loss: -0.5652304462922274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:03<00:00,  2.13trial/s, best loss: -0.5652304462922274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  2.63trial/s, best loss: -0.5652304462922274]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0077680550613313405, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 48}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [15:21<00:00, 92.12s/trial, best loss: -0.8881947735508546]\n",
      "SVM:  {'C': 2.6193154449617193, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d6c2cbf-54c5-4706-a078-475de78beedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 10/10 [00:00<00:00, 15.45trial/s, best loss: -0.7382716049382716]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.03964762506431829, 'n_estimators': 34}\n",
      "100%|███████| 10/10 [00:00<00:00, 269.66trial/s, best loss: -0.6520269364621181]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:01<00:00,  7.83trial/s, best loss: -0.7530864197530864]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.983532855890369, 'n_estimators': 3}\n",
      "100%|███████| 10/10 [00:00<00:00, 122.94trial/s, best loss: -0.7891362572343572]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:01<00:00,  6.00trial/s, best loss: -0.704320987654321]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:00<00:00, 67.92trial/s, best loss: -0.6947530864197531]\n",
      "Ridge:  {'alpha': 0.5785811239538702, 'max_iter': 11856, 'solver': 'sag'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:04,  2.24trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:03,  2.10trial/s, best loss: -0.6811728395061728]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:02<00:05,  1.23trial/s, best loss: -0.7225308641975309]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (71) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:04,  1.41trial/s, best loss: -0.7225308641975309]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:03<00:03,  1.26trial/s, best loss: -0.7225308641975309]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:04<00:03,  1.33trial/s, best loss: -0.7225308641975309]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:07<00:00,  1.04trial/s, best loss: -0.7327160493827161]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:07<00:00,  1.28trial/s, best loss: -0.7327160493827161]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.003403471619032188, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 47}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 19.79trial/s, best loss: -0.7614197530864197]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 39.14trial/s, best loss: -0.7765432098765432]\n",
      "SVM:  {'C': 2.814805469705815, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48be287d-de3a-49dd-8a4a-273dba01a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 18.97trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 6, 'min_samples_split': 0.5804010250891207, 'n_estimators': 2}\n",
      "100%|███████| 10/10 [00:00<00:00, 234.22trial/s, best loss: -0.5694668236803431]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 115.15trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9860830765505643, 'n_estimators': 41}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 198.74trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.19trial/s, best loss: -0.5007320523315094]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:04<00:00,  2.20trial/s, best loss: -0.7774691358024691]\n",
      "Ridge:  {'alpha': 0.5442455026719245, 'max_iter': 2300, 'solver': 'cholesky'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:01<00:06,  1.16trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:03,  1.58trial/s, best loss: -0.6381970473769621]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:04<00:03,  1.32trial/s, best loss: -0.7942029401768319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:05<00:02,  1.37trial/s, best loss: -0.7942029401768319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:05<00:01,  1.51trial/s, best loss: -0.7942029401768319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:06<00:00,  1.49trial/s, best loss: -0.7942029401768319]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.003493362169483909, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 87}\n",
      "100%|███████| 10/10 [34:50<00:00, 209.03s/trial, best loss: -0.7335294807538572]\n",
      "SVM:  {'C': 6.024105565692674, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2680fd9d-46f9-46e2-992c-3711ccc75514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 29.00trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.5235601801386639, 'n_estimators': 37}\n",
      "100%|███████| 10/10 [00:00<00:00, 312.03trial/s, best loss: -0.9985370611183355]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 198.39trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8693735655303166, 'n_estimators': 31}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 253.71trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': None, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 12.86trial/s, best loss: -0.7671933085501859]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 56.47trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.7534379062636745, 'max_iter': 14776, 'solver': 'sag'}\n",
      " 10%|▉        | 1/10 [00:00<00:05,  1.72trial/s, best loss: -0.5139405204460966]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (81) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:03,  2.52trial/s, best loss: -0.7713754646840149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:01<00:02,  2.38trial/s, best loss: -0.7713754646840149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  3.04trial/s, best loss: -0.9883828996282528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:02<00:01,  2.81trial/s, best loss: -0.9883828996282528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:01,  2.25trial/s, best loss: -0.9883828996282528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:03<00:00,  3.15trial/s, best loss: -0.9883828996282528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  2.68trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.009438478814345352, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 75}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 100.73trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 6.481054183767967, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56add373-0587-4aeb-aec0-737c6b6b59e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 28.39trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.4417351176489127, 'n_estimators': 12}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 179.34trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 133.11trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.11338493185220115, 'n_estimators': 26}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 162.20trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:02<00:00,  3.92trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 36.70trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.1418348076018507, 'max_iter': 9233, 'solver': 'cholesky'}\n",
      " 70%|████████████████▊       | 7/10 [00:04<00:01,  1.93trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:05<00:01,  1.31trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:07<00:00,  1.31trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0061816954327692224, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 77}\n",
      " 50%|████████████            | 5/10 [00:00<00:00, 45.01trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 55.88trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.3037600849746624, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a56deb31-121e-454a-887e-06945c2e29c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.08trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.0828002800938965, 'n_estimators': 1}\n",
      "100%|███████| 10/10 [00:00<00:00, 236.68trial/s, best loss: -0.9948623497479644]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 128.51trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.6067221703742288, 'n_estimators': 24}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 195.72trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:01<00:00,  6.12trial/s, best loss: -0.662037037037037]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 9}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 14.92trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.3213680419772824, 'max_iter': 1720, 'solver': 'sparse_cg'}\n",
      " 20%|████▊                   | 2/10 [00:01<00:03,  2.11trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:02,  2.49trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:02<00:01,  2.98trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:02<00:01,  2.87trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:03<00:00,  2.43trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:04<00:00,  2.26trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.002764397909373785, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 95}\n",
      " 10%|██▍                     | 1/10 [00:00<00:01,  8.33trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:01<00:00,  8.34trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.4511514443818893, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bdd2f33-33cd-4a5e-8e30-c52946ae46f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 12.85trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.09672632218335542, 'n_estimators': 48}\n",
      "100%|███████| 10/10 [00:00<00:00, 213.65trial/s, best loss: -0.5523456311423224]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 73.23trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.0603899507532552, 'n_estimators': 9}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 153.13trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.39trial/s, best loss: -0.5561122839266823]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 13}\n",
      " 10%|▉        | 1/10 [00:01<00:09,  1.05s/trial, best loss: -0.5272399580658595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:05<00:02,  1.46trial/s, best loss: -0.851517599414071]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:11<00:00,  1.11s/trial, best loss: -0.851517599414071]\n",
      "Ridge:  {'alpha': 0.5079647572541218, 'max_iter': 12891, 'solver': 'svd'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:05<00:09,  1.42s/trial, best loss: -0.8314789683052577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:06<00:07,  1.31s/trial, best loss: -0.8314789683052577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:06<00:05,  1.04s/trial, best loss: -0.8314789683052577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:11<00:00,  1.05trial/s, best loss: -0.8314789683052577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:12<00:00,  1.22s/trial, best loss: -0.8314789683052577]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.007137772525797421, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 31}\n",
      "100%|███████| 10/10 [59:15<00:00, 355.52s/trial, best loss: -0.9300443037065759]\n",
      "SVM:  {'C': 1.8715001035182366, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374741f-f652-4ee3-81f4-3f7889ba9485",
   "metadata": {},
   "source": [
    "### S:Jax -> T:Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d91d889-591d-4df2-96bd-c97b5c95ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a4274a2-59ab-48ed-b698-ea50bd016aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 27.62trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.20085616428322395, 'n_estimators': 26}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 266.61trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 171.46trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.948901373886958, 'n_estimators': 24}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 224.59trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 6, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  7.01trial/s, best loss: -0.6444444444444444]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:00<00:00, 33.43trial/s, best loss: -0.7768518518518519]\n",
      "Ridge:  {'alpha': 0.24881003090187354, 'max_iter': 13246, 'solver': 'cholesky'}\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.18trial/s, best loss: -0.942283950617284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:02,  3.86trial/s, best loss: -0.942283950617284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:01,  3.56trial/s, best loss: -0.942283950617284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (94) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:01<00:01,  3.86trial/s, best loss: -0.942283950617284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:01<00:01,  3.92trial/s, best loss: -0.942283950617284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:01<00:00,  4.19trial/s, best loss: -0.942283950617284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:01<00:00,  3.19trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (85) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  3.39trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:02<00:00,  3.42trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:02<00:00,  3.58trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.002360840556520393, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 85}\n",
      " 30%|███████▏                | 3/10 [00:00<00:00, 22.27trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 33.64trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.4656732196268315, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a173f83f-1c3c-4d38-8455-7857251a4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 16.85trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.028308447456604435, 'n_estimators': 47}\n",
      "100%|███████| 10/10 [00:00<00:00, 258.75trial/s, best loss: -0.5394983939607179]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 160.83trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.12943004480362724, 'n_estimators': 47}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 217.18trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.93trial/s, best loss: -0.5003086419753087]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 9}\n",
      "100%|████████| 10/10 [00:03<00:00,  2.56trial/s, best loss: -0.5481481481481482]\n",
      "Ridge:  {'alpha': 0.27688305833565224, 'max_iter': 4917, 'solver': 'cholesky'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:03,  2.32trial/s, best loss: -0.5134398680702158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:01,  3.96trial/s, best loss: -0.5314814814814814]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:02,  2.28trial/s, best loss: -0.5314814814814814]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  2.78trial/s, best loss: -0.5499053370288991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:03<00:00,  2.75trial/s, best loss: -0.5499053370288991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (65) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  2.82trial/s, best loss: -0.5499053370288991]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.005281514698057529, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 60}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [36:35<00:00, 219.51s/trial, best loss: -0.8566432821602783]\n",
      "SVM:  {'C': 4.101850635752006, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de2345cf-9bd1-4552-bbf5-821cd88d96df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 34.97trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.270727726851296, 'n_estimators': 20}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 325.01trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 220.40trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.07556354687990662, 'n_estimators': 17}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 258.79trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 17.34trial/s, best loss: -0.5929368029739777]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:00<00:00, 65.84trial/s, best loss: -0.7713754646840149]\n",
      "Ridge:  {'alpha': 0.21925427349863574, 'max_iter': 7610, 'solver': 'saga'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:01,  4.95trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:01,  5.02trial/s, best loss: -0.7286245353159851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (65) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (83) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:00<00:00,  8.21trial/s, best loss: -0.7286245353159851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:00<00:00,  7.45trial/s, best loss: -0.7286245353159851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  7.74trial/s, best loss: -0.7286245353159851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  7.45trial/s, best loss: -0.7286245353159851]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.0058224856874815, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 65}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 105.77trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.195039138041681, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ac03b8e-7f69-46ee-9065-a8c3b2420b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 17.94trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.3923090946346195, 'n_estimators': 24}\n",
      "100%|████████| 10/10 [00:00<00:00, 253.61trial/s, best loss: -0.613829889085156]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 135.75trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.9395044971273746, 'n_estimators': 19}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 227.96trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  7.02trial/s, best loss: -0.5352359274098967]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 19}\n",
      " 10%|▉        | 1/10 [00:00<00:05,  1.51trial/s, best loss: -0.5093409973240657]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:01,  2.76trial/s, best loss: -0.7174823718639151]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.09trial/s, best loss: -0.7174823718639151]\n",
      "Ridge:  {'alpha': 0.27335216089805575, 'max_iter': 9500, 'solver': 'cholesky'}\n",
      " 10%|▉        | 1/10 [00:00<00:03,  2.35trial/s, best loss: -0.6121344525344784]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:01<00:05,  1.40trial/s, best loss: -0.6778547288402529]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:03,  1.76trial/s, best loss: -0.7008890660079752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (94) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:03<00:02,  1.59trial/s, best loss: -0.7206963652291299]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:03<00:01,  1.99trial/s, best loss: -0.7206963652291299]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:04<00:00,  2.37trial/s, best loss: -0.7206963652291299]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.88trial/s, best loss: -0.7206963652291299]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.007056393396354756, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 72}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (81) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [31:54<00:00, 191.49s/trial, best loss: -0.9389158157770022]\n",
      "SVM:  {'C': 0.6285278700752917, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "495951d4-b20f-48e4-bb28-a7c163101b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 28.73trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.37135189743888597, 'n_estimators': 37}\n",
      "100%|███████| 10/10 [00:00<00:00, 264.95trial/s, best loss: -0.6347228804350428]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 175.27trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6827795923106333, 'n_estimators': 5}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 221.92trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "100%|███████████████████████| 10/10 [00:01<00:00,  7.78trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 16}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.63trial/s, best loss: -0.5515610414602271]\n",
      "Ridge:  {'alpha': 0.8804308720984664, 'max_iter': 7795, 'solver': 'svd'}\n",
      " 20%|█▊       | 2/10 [00:00<00:01,  5.34trial/s, best loss: -0.5506419370126233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (89) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00,  9.10trial/s, best loss: -0.5506419370126233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  6.47trial/s, best loss: -0.5537996831004457]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  7.38trial/s, best loss: -0.5537996831004457]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.006216357422097386, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 99}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [26:52<00:00, 161.25s/trial, best loss: -0.9033739989181375]\n",
      "SVM:  {'C': 3.386702136156923, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db81b304-1980-4485-b88e-cda111f8f1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 10/10 [00:00<00:00, 35.93trial/s, best loss: -0.6604938271604939]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 0.06019461398660153, 'n_estimators': 18}\n",
      "100%|███████| 10/10 [00:00<00:00, 296.17trial/s, best loss: -0.6705243921703791]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 16.29trial/s, best loss: -0.7824074074074074]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.946699608910604, 'n_estimators': 42}\n",
      "100%|███████| 10/10 [00:00<00:00, 181.76trial/s, best loss: -0.8217041488949205]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': None, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  7.56trial/s, best loss: -0.7762345679012346]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|███████| 10/10 [00:00<00:00, 105.80trial/s, best loss: -0.7530864197530864]\n",
      "Ridge:  {'alpha': 0.11891349922174066, 'max_iter': 7757, 'solver': 'sparse_cg'}\n",
      " 20%|█▊       | 2/10 [00:00<00:01,  5.28trial/s, best loss: -0.5984567901234568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:02,  2.94trial/s, best loss: -0.7728395061728395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (89) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:02,  2.77trial/s, best loss: -0.7728395061728395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:02,  2.06trial/s, best loss: -0.7728395061728395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:02<00:01,  2.40trial/s, best loss: -0.7728395061728395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:01,  2.52trial/s, best loss: -0.8015432098765432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  2.71trial/s, best loss: -0.8015432098765432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:03<00:00,  2.96trial/s, best loss: -0.8015432098765432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  2.72trial/s, best loss: -0.8015432098765432]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.00478576105491579, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 42}\n",
      "100%|████████| 10/10 [00:00<00:00, 60.52trial/s, best loss: -0.9191358024691358]\n",
      "SVM:  {'C': 1.3184894814493433, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f402779-1972-4aba-a851-0e187871c8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 37.00trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.14231617943805608, 'n_estimators': 1}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 200.96trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 156.30trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.18158920261469136, 'n_estimators': 29}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 186.48trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.99trial/s, best loss: -0.9987654320987654]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 62.82trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.15109868474723065, 'max_iter': 6719, 'solver': 'sag'}\n",
      " 20%|████▊                   | 2/10 [00:01<00:06,  1.33trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:03,  1.81trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:02,  2.43trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:02<00:02,  2.45trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  3.77trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:03<00:00,  4.55trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  2.97trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.006913784063047745, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 73}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 86.19trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.31430675659916196, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea44b1-71fd-4240-8153-597d631acabb",
   "metadata": {},
   "source": [
    "### S:Lightning -> T:Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43d095fc-f03c-48d6-a13d-30526a5a7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53590edc-880c-4425-8682-c5ea3c8adcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.42trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.007536770014021976, 'n_estimators': 36}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 250.03trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 160.42trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.37261498567155205, 'n_estimators': 33}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 223.62trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.15trial/s, best loss: -0.9192684024337119]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:00<00:00, 10.50trial/s, best loss: -0.8135802469135802]\n",
      "Ridge:  {'alpha': 0.1326502057696592, 'max_iter': 2739, 'solver': 'svd'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  4.88trial/s, best loss: -0.9037037037037037]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:00<00:03,  2.41trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:03,  1.92trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:02,  2.26trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:02<00:02,  2.35trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:02<00:01,  2.11trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:03<00:00,  2.75trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  2.70trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.00512891816243958, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 58}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 38.80trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 3.467396739854255, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "937fe8c1-d76f-4a60-af00-f431eec2607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 10/10 [00:00<00:00, 18.12trial/s, best loss: -0.6180880473338791]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.010032975673458289, 'n_estimators': 31}\n",
      "100%|███████| 10/10 [00:00<00:00, 265.57trial/s, best loss: -0.6022089622257647]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 18.58trial/s, best loss: -0.6161925140857543]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.6950118894123529, 'n_estimators': 9}\n",
      "100%|███████| 10/10 [00:00<00:00, 193.22trial/s, best loss: -0.6161925140857543]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.40trial/s, best loss: -0.5952077319661655]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 17}\n",
      "100%|████████| 10/10 [00:05<00:00,  1.82trial/s, best loss: -0.6312371050124701]\n",
      "Ridge:  {'alpha': 0.845151122134745, 'max_iter': 2320, 'solver': 'sparse_cg'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|▉        | 1/10 [00:00<00:05,  1.76trial/s, best loss: -0.6350935140905414]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:01<00:04,  1.75trial/s, best loss: -0.6522854345880066]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:01<00:02,  2.36trial/s, best loss: -0.6522854345880066]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:01,  2.56trial/s, best loss: -0.6586458049105068]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:02<00:01,  2.27trial/s, best loss: -0.6586458049105068]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:03<00:01,  2.37trial/s, best loss: -0.6586458049105068]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.47trial/s, best loss: -0.6586458049105068]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.0017749669890132185, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 56}\n",
      "100%|███████| 10/10 [35:31<00:00, 213.11s/trial, best loss: -0.6256170446005007]\n",
      "SVM:  {'C': 0.5089918523370821, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "583cfc31-25dd-4b9c-b82c-f8b262be8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.23trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.28395485489073435, 'n_estimators': 37}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 325.72trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 212.57trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.24883308798651316, 'n_estimators': 49}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 254.92trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 1, 'max_features': None, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 21.74trial/s, best loss: -0.9442379182156133]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 118.42trial/s, best loss: -0.8113382899628252]\n",
      "Ridge:  {'alpha': 0.5862409864283266, 'max_iter': 6512, 'solver': 'svd'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  7.43trial/s, best loss: -0.8034386617100372]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:02,  3.82trial/s, best loss: -0.9995353159851301]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:01<00:00,  5.53trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (90) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:01<00:00,  5.76trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:01<00:00,  5.61trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.007177274176790471, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 90}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 100.97trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.26654728683191115, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6899408e-82f5-43f2-82b2-65b4e217b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 19.45trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.4650579010440258, 'n_estimators': 40}\n",
      "100%|███████| 10/10 [00:00<00:00, 249.36trial/s, best loss: -0.9873346689069838]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 138.16trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.5775573153470867, 'n_estimators': 45}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 202.81trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.60trial/s, best loss: -0.6193678524071441]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 12}\n",
      "100%|████████| 10/10 [00:02<00:00,  4.09trial/s, best loss: -0.6741957836083466]\n",
      "Ridge:  {'alpha': 0.23668721222055303, 'max_iter': 13689, 'solver': 'cholesky'}\n",
      " 10%|▉        | 1/10 [00:00<00:03,  2.77trial/s, best loss: -0.8030048013633382]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:03,  2.33trial/s, best loss: -0.8547500227382612]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:01<00:05,  1.38trial/s, best loss: -0.8890656489499711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:03,  1.59trial/s, best loss: -0.8890656489499711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:02,  1.93trial/s, best loss: -0.8890656489499711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:02<00:01,  2.44trial/s, best loss: -0.8890656489499711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.19trial/s, best loss: -0.8890656489499711]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.006699430476200976, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 88}\n",
      "100%|███████| 10/10 [24:18<00:00, 145.88s/trial, best loss: -0.9842592592592593]\n",
      "SVM:  {'C': 0.05646697600900133, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37552073-8a36-42ee-a516-8ada6fdec0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 24.73trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.06812206040688218, 'n_estimators': 16}\n",
      "100%|████████| 10/10 [00:00<00:00, 256.35trial/s, best loss: -0.979082714613282]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 165.15trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.15670930793228663, 'n_estimators': 43}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 226.31trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.67trial/s, best loss: -0.5979813211169034]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 11}\n",
      "100%|████████| 10/10 [00:06<00:00,  1.63trial/s, best loss: -0.6486221810540022]\n",
      "Ridge:  {'alpha': 0.9972017521318277, 'max_iter': 9661, 'solver': 'sparse_cg'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  7.09trial/s, best loss: -0.6249252030885739]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:01,  6.47trial/s, best loss: -0.6249252030885739]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:02,  3.48trial/s, best loss: -0.7468215501270948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:01,  3.75trial/s, best loss: -0.7468215501270948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:01,  2.43trial/s, best loss: -0.7651228584148321]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  2.98trial/s, best loss: -0.7651228584148321]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.16trial/s, best loss: -0.7651228584148321]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0003416018387475345, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 73}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [08:04<00:00, 48.43s/trial, best loss: -0.9947530864197531]\n",
      "SVM:  {'C': 0.14832080389674854, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "664947d8-7d20-41d4-8fa1-ad5db337a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 10/10 [00:00<00:00, 23.39trial/s, best loss: -0.9265779156434449]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.09454155483646354, 'n_estimators': 11}\n",
      "100%|███████| 10/10 [00:00<00:00, 289.25trial/s, best loss: -0.8404499303491161]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 13.12trial/s, best loss: -0.9711504124002508]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.9989119470019355, 'n_estimators': 44}\n",
      "100%|████████| 10/10 [00:00<00:00, 76.85trial/s, best loss: -0.9587914494564359]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': None, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.81trial/s, best loss: -0.9591691439403731]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 74.18trial/s, best loss: -0.9067901234567901]\n",
      "Ridge:  {'alpha': 0.27286791863018256, 'max_iter': 12142, 'solver': 'saga'}\n",
      " 10%|▉        | 1/10 [00:00<00:04,  2.14trial/s, best loss: -0.5015432098765432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:03,  2.04trial/s, best loss: -0.9906616355272164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:01<00:03,  1.99trial/s, best loss: -0.9938628236611952]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:03,  1.80trial/s, best loss: -0.9960946438230915]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:02,  2.18trial/s, best loss: -0.9960946438230915]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:03<00:02,  1.88trial/s, best loss: -0.9977782325429992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:03<00:01,  1.78trial/s, best loss: -0.9977782325429992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:04<00:01,  1.82trial/s, best loss: -0.9977782325429992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (83) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:04<00:00,  2.18trial/s, best loss: -0.9977782325429992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.93trial/s, best loss: -0.9977782325429992]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.009936154429367535, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 59}\n",
      " 10%|▉        | 1/10 [00:00<00:00,  9.65trial/s, best loss: -0.9949570127190651]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 15.23trial/s, best loss: -0.9951508863134816]\n",
      "SVM:  {'C': 2.0397443844121623, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74fdbdde-4cde-49a7-87f3-e039ef34a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 23.59trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 0.23653110806112088, 'n_estimators': 46}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 194.65trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 149.09trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.5326519969372806, 'n_estimators': 4}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 181.88trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:01<00:00,  6.31trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 8}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 48.78trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.9909970570595793, 'max_iter': 5540, 'solver': 'svd'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:03,  2.30trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:02,  2.75trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:02<00:00,  3.36trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  3.29trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  2.78trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.005557196969656327, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 31}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 102.01trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.0573218985223425, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacc4c5-0768-4979-91c3-b76c35010d97",
   "metadata": {},
   "source": [
    "### S:Yolov5 -> T:Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52f4706d-98dd-4aa8-bca4-88f31943b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0fef546-5c8d-4737-aaa0-15e2940bbbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 24.08trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.07376047445226186, 'n_estimators': 13}\n",
      "100%|████████| 10/10 [00:00<00:00, 280.84trial/s, best loss: -0.952888716556805]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 203.13trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.675405173359281, 'n_estimators': 2}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 247.85trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 4, 'max_features': None, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  8.40trial/s, best loss: -0.5951166592468131]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:00<00:00, 23.61trial/s, best loss: -0.8388861363625484]\n",
      "Ridge:  {'alpha': 0.9546735772841161, 'max_iter': 14917, 'solver': 'sag'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 12.47trial/s, best loss: -0.8358924647796304]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:00<00:00,  9.85trial/s, best loss: -0.8706392802263295]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (98) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 13.71trial/s, best loss: -0.8901125663598198]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.005216061090433218, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 80}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 78.75trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.436212841842739, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "733cc30f-936f-48ec-b929-c87bb23eec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 59.80trial/s, best loss: -0.5978919238483669]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.3269471824996413, 'n_estimators': 17}\n",
      "100%|███████| 10/10 [00:00<00:00, 277.91trial/s, best loss: -0.5600523458704925]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 20.08trial/s, best loss: -0.5980831645915011]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.2372652472446117, 'n_estimators': 9}\n",
      "100%|███████| 10/10 [00:00<00:00, 228.36trial/s, best loss: -0.5762573061623081]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:01<00:00,  8.13trial/s, best loss: -0.591004624244252]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 19}\n",
      "100%|████████| 10/10 [00:00<00:00, 39.79trial/s, best loss: -0.6421648739342936]\n",
      "Ridge:  {'alpha': 0.18461498040224278, 'max_iter': 10459, 'solver': 'svd'}\n",
      " 40%|███▌     | 4/10 [00:00<00:00, 29.43trial/s, best loss: -0.6092628495110077]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 33.38trial/s, best loss: -0.6092628495110077]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.009569994012479176, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 66}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [21:36<00:00, 129.68s/trial, best loss: -0.6261924422807194]\n",
      "SVM:  {'C': 0.11458534145542437, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a8d1b67-ff5d-4ca9-bcf3-4571a984f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 10/10 [00:00<00:00, 36.47trial/s, best loss: -0.7784460338101431]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.5931928033484348, 'n_estimators': 32}\n",
      "100%|███████| 10/10 [00:00<00:00, 334.89trial/s, best loss: -0.9609882964889467]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 229.10trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.14937698046612224, 'n_estimators': 4}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 265.59trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 4, 'max_features': None, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 19.06trial/s, best loss: -0.7291714001189205]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "100%|███████| 10/10 [00:00<00:00, 133.50trial/s, best loss: -0.9403687742010335]\n",
      "Ridge:  {'alpha': 0.9983970560082447, 'max_iter': 14853, 'solver': 'lsqr'}\n",
      " 70%|██████▎  | 7/10 [00:00<00:00, 28.27trial/s, best loss: -0.5434820966736118]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 27.64trial/s, best loss: -0.5434820966736118]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.0022884653310093037, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 30}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 121.40trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.5147814275281095, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9820f83-025e-47ef-8320-61eba7222bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 24.35trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.46720419975828165, 'n_estimators': 15}\n",
      "100%|████████| 10/10 [00:00<00:00, 272.45trial/s, best loss: -0.581928946524397]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 194.68trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.020251500441902257, 'n_estimators': 16}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 232.52trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': None, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  7.97trial/s, best loss: -0.5573125050861899]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 10}\n",
      "100%|████████| 10/10 [00:00<00:00, 10.95trial/s, best loss: -0.6495118454372687]\n",
      "Ridge:  {'alpha': 0.6845948439937027, 'max_iter': 4856, 'solver': 'cholesky'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 14.88trial/s, best loss: -0.5848578739007846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:00<00:00, 12.40trial/s, best loss: -0.589674316296392]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (83) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00, 16.68trial/s, best loss: -0.589674316296392]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:00<00:00, 12.38trial/s, best loss: -0.589674316296392]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.009672539807195764, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 83}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (89) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [08:26<00:00, 50.69s/trial, best loss: -0.9121950081139689]\n",
      "SVM:  {'C': 0.15254529418489657, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f6b389f-9558-409e-ac1a-3913df56f264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 28.67trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.12639265853965787, 'n_estimators': 14}\n",
      "100%|███████| 10/10 [00:00<00:00, 198.72trial/s, best loss: -0.5781694742435339]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 196.05trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8749131050149788, 'n_estimators': 47}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 235.33trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  8.31trial/s, best loss: -0.5492479619337575]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 26.08trial/s, best loss: -0.6220922551089283]\n",
      "Ridge:  {'alpha': 0.32571894406540725, 'max_iter': 2685, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 17.57trial/s, best loss: -0.5792348216123582]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:00<00:00, 24.39trial/s, best loss: -0.609788342691923]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.008261639782230414, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 52}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [04:00<00:00, 24.09s/trial, best loss: -0.8903608921057543]\n",
      "SVM:  {'C': 0.664255115095264, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf2d8c20-6061-40ea-9986-04c3f316d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 10/10 [00:00<00:00, 21.37trial/s, best loss: -0.6333850329585111]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 0.1121185354564268, 'n_estimators': 48}\n",
      "100%|███████| 10/10 [00:00<00:00, 304.57trial/s, best loss: -0.6886506158478499]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 27.13trial/s, best loss: -0.6698309948826946]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.7224048113917313, 'n_estimators': 15}\n",
      "100%|███████| 10/10 [00:00<00:00, 232.68trial/s, best loss: -0.6810798519858878]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': None, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:01<00:00,  8.44trial/s, best loss: -0.703118492668706]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 132.49trial/s, best loss: -0.6441731410873197]\n",
      "Ridge:  {'alpha': 0.8607505196036385, 'max_iter': 14834, 'solver': 'sparse_cg'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 18.55trial/s, best loss: -0.5180736863268852]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (83) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████▉ | 9/10 [00:00<00:00, 21.40trial/s, best loss: -0.62714242289336]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.35trial/s, best loss: -0.62714242289336]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.005921551856998165, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 52}\n",
      "100%|████████| 10/10 [00:00<00:00, 72.27trial/s, best loss: -0.6773780630831168]\n",
      "SVM:  {'C': 3.41991305855769, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (65) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92834dbc-7a67-42f3-8782-59898a62862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.88trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.30667782648088715, 'n_estimators': 35}\n",
      "100%|███████| 10/10 [00:00<00:00, 151.84trial/s, best loss: -0.8414113997673517]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 160.60trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9268882371862947, 'n_estimators': 18}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 183.16trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:01<00:00,  7.97trial/s, best loss: -0.7589106458144845]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 18}\n",
      "100%|████████| 10/10 [00:00<00:00, 59.70trial/s, best loss: -0.9329275152106998]\n",
      "Ridge:  {'alpha': 0.9372399373726743, 'max_iter': 9173, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 13.10trial/s, best loss: -0.8422838309422257]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (98) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00, 15.60trial/s, best loss: -0.8829003489724699]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 15.26trial/s, best loss: -0.8829003489724699]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0028515314818319936, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 98}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 80.38trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.6541770306619238, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998162a-c2cd-4965-af99-f874c1f797d7",
   "metadata": {},
   "source": [
    "## Target: Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894eb15-e32c-4d09-b98d-37404020c248",
   "metadata": {},
   "source": [
    "### S:Jax -> T:Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "437973ac-159c-49db-a0b3-17bfad5c02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b74edfb-a6af-45f7-8890-bea25cd77486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.75trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 0.21295228960938617, 'n_estimators': 48}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 308.50trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 181.92trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8563928018404351, 'n_estimators': 38}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 86.64trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 12.17trial/s, best loss: -0.5515873015873016]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 22.41trial/s, best loss: -0.5992063492063492]\n",
      "Ridge:  {'alpha': 0.4954794466398662, 'max_iter': 14442, 'solver': 'lsqr'}\n",
      " 20%|████▊                   | 2/10 [00:00<00:00, 10.29trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  3.73trial/s, best loss: -0.9166666666666667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:01,  3.25trial/s, best loss: -0.9166666666666667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:00,  3.22trial/s, best loss: -0.9166666666666667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  2.99trial/s, best loss: -0.9166666666666667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  3.62trial/s, best loss: -0.9166666666666667]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.001518885171833838, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 69}\n",
      " 20%|████▊                   | 2/10 [00:00<00:00, 18.01trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 27.42trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.8356695836148818, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41535803-1cfa-4fb3-9c13-4f760dafee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.24trial/s, best loss: -0.5]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.9524733290655395, 'n_estimators': 17}\n",
      "100%|███████| 10/10 [00:00<00:00, 326.37trial/s, best loss: -0.5717222908120595]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 13.56trial/s, best loss: -0.5056735964527991]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6778961084598619, 'n_estimators': 35}\n",
      "100%|███████| 10/10 [00:00<00:00, 195.17trial/s, best loss: -0.5375086843584195]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 12.20trial/s, best loss: -0.5119700328788702]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      " 10%|██▍                     | 1/10 [00:00<00:08,  1.03trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:01<00:07,  1.13trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:04<00:00,  2.28trial/s, best loss: -0.5]\n",
      "Ridge:  {'alpha': 0.6965296802868228, 'max_iter': 5092, 'solver': 'saga'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:01,  7.80trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:00<00:02,  2.73trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:01<00:01,  3.96trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:01<00:00,  4.19trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:02<00:00,  4.85trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:02<00:00,  4.57trial/s, best loss: -0.5]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.007595557008639653, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 12}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████| 10/10 [1:12:47<00:00, 436.73s/trial, best loss: -0.49891749748872694]\n",
      "SVM:  {'C': 0.09927812826054443, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d25a0968-24ec-4bdc-8b2a-7558313dac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 58.68trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.32985430189469145, 'n_estimators': 2}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 382.53trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 243.75trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.998127499829266, 'n_estimators': 18}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 284.36trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 3, 'max_features': None, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 32.30trial/s, best loss: -0.5451807228915663]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 144.63trial/s, best loss: -0.5903614457831325]\n",
      "Ridge:  {'alpha': 0.9807115674566894, 'max_iter': 3673, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:01,  7.45trial/s, best loss: -0.5301204819277109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (98) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00,  7.64trial/s, best loss: -0.5903614457831325]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  6.51trial/s, best loss: -0.5903614457831325]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (91) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  7.11trial/s, best loss: -0.5903614457831325]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.009233873838921295, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 99}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 106.90trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.3986487557218052, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50f65843-bedd-4cbe-a4b3-eadbb8ac1c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 23.04trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.5859534320826002, 'n_estimators': 21}\n",
      "100%|███████| 10/10 [00:00<00:00, 306.28trial/s, best loss: -0.7163472814086139]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 145.95trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8564188551874844, 'n_estimators': 45}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 194.81trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 12.32trial/s, best loss: -0.6355473469008457]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 9}\n",
      " 20%|█▊       | 2/10 [00:00<00:02,  2.95trial/s, best loss: -0.5987616215522543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  4.40trial/s, best loss: -0.6157082896349694]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  2.82trial/s, best loss: -0.6157082896349694]\n",
      "Ridge:  {'alpha': 0.33354884287577746, 'max_iter': 9377, 'solver': 'sparse_cg'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  6.96trial/s, best loss: -0.5418215469442121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:01,  4.53trial/s, best loss: -0.6743254963912896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:03,  1.94trial/s, best loss: -0.7269150946318497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:02<00:01,  3.13trial/s, best loss: -0.7269150946318497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  3.95trial/s, best loss: -0.7269150946318497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:02<00:00,  4.15trial/s, best loss: -0.7269150946318497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.10trial/s, best loss: -0.7269150946318497]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.00699067701949884, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 74}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [38:49<00:00, 232.94s/trial, best loss: -0.6640065978998234]\n",
      "SVM:  {'C': 1.947994507948272, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2bc2a43-f093-44b7-ab73-a77bcb380038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 33.02trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.24927722032183552, 'n_estimators': 1}\n",
      "100%|████████| 10/10 [00:00<00:00, 303.60trial/s, best loss: -0.645748978896456]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 189.01trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.7068881340209219, 'n_estimators': 39}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 247.68trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 12.31trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 18}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.30trial/s, best loss: -0.5038288617184631]\n",
      "Ridge:  {'alpha': 0.3118353101254123, 'max_iter': 9331, 'solver': 'lsqr'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:02,  3.31trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:00<00:01,  4.22trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:01<00:01,  4.75trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (90) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  8.07trial/s, best loss: -0.5321702930777367]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  6.22trial/s, best loss: -0.5321702930777367]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.007345620697360186, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 88}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [17:18<00:00, 103.89s/trial, best loss: -0.5653279479248254]\n",
      "SVM:  {'C': 0.27487079995043456, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd95abc7-a97b-458f-a7e0-bb1297285e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 10/10 [00:00<00:00, 17.53trial/s, best loss: -0.8605535421119476]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.32167585466379567, 'n_estimators': 34}\n",
      "100%|███████| 10/10 [00:00<00:00, 346.88trial/s, best loss: -0.8771146689323439]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 16.72trial/s, best loss: -0.9859717188613202]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9334919495169569, 'n_estimators': 26}\n",
      "100%|████████| 10/10 [00:00<00:00, 206.77trial/s, best loss: -0.941623963961572]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 2, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 12.30trial/s, best loss: -0.9146825396825398]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 8}\n",
      "100%|███████| 10/10 [00:00<00:00, 122.26trial/s, best loss: -0.9305555555555556]\n",
      "Ridge:  {'alpha': 0.18968231084943799, 'max_iter': 10491, 'solver': 'sag'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:03,  2.94trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:02,  3.70trial/s, best loss: -0.9384920634920635]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:02,  2.63trial/s, best loss: -0.996031746031746]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:01<00:01,  3.03trial/s, best loss: -0.996031746031746]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:01<00:01,  3.69trial/s, best loss: -0.996031746031746]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:02<00:00,  3.31trial/s, best loss: -0.996031746031746]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (98) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:02<00:00,  2.56trial/s, best loss: -0.996031746031746]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:03<00:00,  2.35trial/s, best loss: -0.996031746031746]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:04<00:00,  2.48trial/s, best loss: -0.998015873015873]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.008655976805567322, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 86}\n",
      "100%|████████| 10/10 [00:00<00:00, 64.07trial/s, best loss: -0.9920634920634921]\n",
      "SVM:  {'C': 2.906140998809424, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8dc96a19-a6af-4a4f-a155-34ad0ad130be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 24.53trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.20710333727094377, 'n_estimators': 24}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 228.74trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 166.42trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.17664736419438562, 'n_estimators': 42}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 201.09trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 10.46trial/s, best loss: -0.9900793650793651]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 50.36trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.5261502261726039, 'max_iter': 2077, 'solver': 'svd'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:02,  4.04trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:00<00:02,  3.27trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:01<00:01,  4.18trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:01<00:01,  3.27trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (81) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:02<00:00,  3.58trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.006136574531923883, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 49}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 78.58trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 5.03096035844064, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694e369-88fa-4d4d-9eac-0b57971a3542",
   "metadata": {},
   "source": [
    "### S:Lightning -> T:Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f50b8f58-5a33-44ad-b64b-07dd03d6eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a384703b-4c0f-4a37-8eb3-2570ab60c4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 27.71trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 6, 'min_samples_split': 0.08599217744460008, 'n_estimators': 41}\n",
      "100%|███████| 10/10 [00:00<00:00, 314.63trial/s, best loss: -0.9867577362698634]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 181.63trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.49166909649875296, 'n_estimators': 20}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 251.24trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 11.23trial/s, best loss: -0.6632886171846306]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|█████████| 10/10 [00:00<00:00, 17.12trial/s, best loss: -0.746031746031746]\n",
      "Ridge:  {'alpha': 0.16431082778581696, 'max_iter': 4883, 'solver': 'sparse_cg'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:04,  1.95trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:02,  3.41trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:01,  3.12trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:01<00:01,  3.91trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:01<00:00,  4.52trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  3.61trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (98) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:02<00:00,  3.56trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.003598663722423243, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 75}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 26.94trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.1843636836162013, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83bf979d-07df-4694-8f71-cb3a5a3196c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 23.05trial/s, best loss: -0.5]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.40336549730654636, 'n_estimators': 29}\n",
      "100%|████████| 10/10 [00:00<00:00, 319.47trial/s, best loss: -0.582112544859966]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.80trial/s, best loss: -0.6908036516344295]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.7691717099087089, 'n_estimators': 40}\n",
      "100%|████████| 10/10 [00:00<00:00, 163.15trial/s, best loss: -0.656076727689496]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 9, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 11.53trial/s, best loss: -0.4879060628990933]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 10}\n",
      " 40%|███▌     | 4/10 [00:00<00:01,  4.12trial/s, best loss: -0.7047688743743942]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:03<00:00,  2.14trial/s, best loss: -0.7249514339701124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.44trial/s, best loss: -0.7249514339701124]\n",
      "Ridge:  {'alpha': 0.6023265100287533, 'max_iter': 1214, 'solver': 'sparse_cg'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:01,  4.06trial/s, best loss: -0.6869570893128183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:00,  4.13trial/s, best loss: -0.6869570893128183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:01,  2.63trial/s, best loss: -0.6869570893128183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:03<00:01,  1.94trial/s, best loss: -0.6869570893128183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:03<00:00,  2.32trial/s, best loss: -0.705093016669543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:03<00:00,  2.77trial/s, best loss: -0.705093016669543]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0004149469553722137, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 38}\n",
      "100%|███████| 10/10 [37:43<00:00, 226.30s/trial, best loss: -0.5020499511020837]\n",
      "SVM:  {'C': 0.2227447796182637, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e54ed60-4b0e-4a1b-9e60-f66d0695480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 22.11trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.26682295114143806, 'n_estimators': 26}\n",
      "100%|███████| 10/10 [00:00<00:00, 374.38trial/s, best loss: -0.9898966165413533]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 232.93trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.07737934775082607, 'n_estimators': 34}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 91.01trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 28.73trial/s, best loss: -0.7078313253012049]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 106.64trial/s, best loss: -0.6985602183168765]\n",
      "Ridge:  {'alpha': 0.28334285759689987, 'max_iter': 5242, 'solver': 'saga'}\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.91trial/s, best loss: -0.786144578313253]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:00<00:00,  8.59trial/s, best loss: -0.786144578313253]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00,  7.96trial/s, best loss: -0.8431385315698886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  7.66trial/s, best loss: -0.8431385315698886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  6.83trial/s, best loss: -0.9937409412084427]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.008360452899720264, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 86}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 114.83trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.3145323368791784, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20a5d07a-cf56-45d0-96ec-ab3fd5581f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 20.75trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 0.06410573757304383, 'n_estimators': 28}\n",
      "100%|███████| 10/10 [00:00<00:00, 290.49trial/s, best loss: -0.7364789517702814]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 151.31trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.4733931579860306, 'n_estimators': 41}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 213.83trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 11.49trial/s, best loss: -0.4816666002894049]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 6}\n",
      " 60%|█████▍   | 6/10 [00:10<00:07,  1.90s/trial, best loss: -0.6154743097871059]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:11<00:00,  1.11s/trial, best loss: -0.6154743097871059]\n",
      "Ridge:  {'alpha': 0.8549415864713608, 'max_iter': 12117, 'solver': 'lsqr'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|▉        | 1/10 [00:00<00:04,  1.89trial/s, best loss: -0.7595627508507353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:01<00:04,  1.93trial/s, best loss: -0.7595627508507353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:03,  1.68trial/s, best loss: -0.7595627508507353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:02,  2.08trial/s, best loss: -0.7595627508507353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:02<00:01,  2.23trial/s, best loss: -0.7595627508507353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:04<00:00,  1.97trial/s, best loss: -0.7741546855709108]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (90) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.01trial/s, best loss: -0.7741546855709108]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.005792401684651191, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 90}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [28:35<00:00, 171.56s/trial, best loss: -0.6771686557719454]\n",
      "SVM:  {'C': 1.7051733885843372, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d681194a-f2cc-4fda-bed7-b5a07d0474bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 22.14trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 0.4288432732638512, 'n_estimators': 21}\n",
      "100%|███████| 10/10 [00:00<00:00, 294.49trial/s, best loss: -0.7925356556524664]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 184.61trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1854064220888524, 'n_estimators': 38}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 247.33trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': 'log2', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 12.58trial/s, best loss: -0.4772027294330054]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 11}\n",
      " 50%|████▌    | 5/10 [00:01<00:01,  3.57trial/s, best loss: -0.6939526995632377]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.49trial/s, best loss: -0.7127441023802886]\n",
      "Ridge:  {'alpha': 0.4366328140631299, 'max_iter': 4646, 'solver': 'sparse_cg'}\n",
      " 10%|▉        | 1/10 [00:00<00:02,  3.89trial/s, best loss: -0.6837538332868692]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00,  6.80trial/s, best loss: -0.7166061527296543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:00,  5.95trial/s, best loss: -0.7166061527296543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  6.21trial/s, best loss: -0.7166061527296543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  4.32trial/s, best loss: -0.7166061527296543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:01<00:00,  4.41trial/s, best loss: -0.7166061527296543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (71) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  4.77trial/s, best loss: -0.7166061527296543]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.004264119650486766, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 44}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [05:45<00:00, 34.58s/trial, best loss: -0.6939670813032954]\n",
      "SVM:  {'C': 1.3454146381617154, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9b0fc3-59c2-4fb2-a9bc-82283f655a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 10/10 [00:00<00:00, 20.26trial/s, best loss: -0.9421638323575875]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.40475452684008895, 'n_estimators': 35}\n",
      "100%|███████| 10/10 [00:00<00:00, 347.93trial/s, best loss: -0.9180014027727995]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 17.25trial/s, best loss: -0.9315257698656082]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8007005998644288, 'n_estimators': 49}\n",
      "100%|███████| 10/10 [00:00<00:00, 175.78trial/s, best loss: -0.9493143228855523]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 11.89trial/s, best loss: -0.8847817958146924]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 17}\n",
      "100%|████████| 10/10 [00:00<00:00, 54.05trial/s, best loss: -0.9662698412698413]\n",
      "Ridge:  {'alpha': 0.8393095193614204, 'max_iter': 11742, 'solver': 'lsqr'}\n",
      " 10%|▉        | 1/10 [00:00<00:03,  2.52trial/s, best loss: -0.9603174603174602]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:04,  1.95trial/s, best loss: -0.9603174603174602]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:01<00:04,  1.41trial/s, best loss: -0.9603174603174602]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:04,  1.45trial/s, best loss: -0.9603174603174602]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (71) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:03<00:03,  1.58trial/s, best loss: -0.9742063492063492]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:03<00:02,  1.69trial/s, best loss: -0.9742063492063492]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:03<00:01,  2.13trial/s, best loss: -0.9838808351144566]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:04<00:00,  2.01trial/s, best loss: -0.9838808351144566]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:05<00:00,  1.40trial/s, best loss: -0.9838808351144566]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:06<00:00,  1.62trial/s, best loss: -0.9933091720100363]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.007505577929805608, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 99}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 12.56trial/s, best loss: -0.9880952380952381]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 17.64trial/s, best loss: -0.9940802545346733]\n",
      "SVM:  {'C': 0.3644064142854401, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3916199-9ca4-40b8-bda9-bf2b477b5e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 32.44trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.00418597081822325, 'n_estimators': 2}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 219.69trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 161.70trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.17100472112110143, 'n_estimators': 33}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 191.97trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 7, 'max_features': None, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:01<00:00,  8.87trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|███████████████████████| 10/10 [00:01<00:00,  8.87trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.11668798253363516, 'max_iter': 7515, 'solver': 'saga'}\n",
      " 30%|███████▏                | 3/10 [00:01<00:02,  2.99trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:02,  2.93trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:02<00:02,  2.28trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:02<00:02,  1.95trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:02<00:01,  2.39trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:03<00:00,  2.74trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:04<00:00,  2.46trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.006840711486685004, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 91}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 110.98trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.102385873344408, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b1a100-c3f4-4536-8c4d-40f6a5701702",
   "metadata": {},
   "source": [
    "### S:Ray -> T:Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38d2fcc7-540a-4c9f-84fd-b27d42e5addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993feb57-be10-4f77-95aa-91f70fcd94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 18.99trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 0.2795800903037585, 'n_estimators': 25}\n",
      "100%|███████| 10/10 [00:00<00:00, 270.04trial/s, best loss: -0.9701700585447449]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 127.08trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.3530885509236029, 'n_estimators': 32}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 180.10trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  9.74trial/s, best loss: -0.8749258787243176]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 10.47trial/s, best loss: -0.9700987029883043]\n",
      "Ridge:  {'alpha': 0.8294819274547098, 'max_iter': 10240, 'solver': 'lsqr'}\n",
      " 20%|████▊                   | 2/10 [00:03<00:16,  2.05s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:04<00:09,  1.42s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:05<00:08,  1.36s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:06<00:05,  1.15s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (65) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:09<00:03,  1.22s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:10<00:00,  1.06s/trial, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.001188121574914473, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 87}\n",
      " 20%|████▊                   | 2/10 [00:00<00:00, 17.20trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 20.29trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.033735369413415, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9cdd08c-337d-44d8-b8e0-0bd95b41ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 12.20trial/s, best loss: -0.5]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.9770802199450715, 'n_estimators': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 250.91trial/s, best loss: -0.6655288497705559]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|█████████| 10/10 [00:01<00:00,  6.55trial/s, best loss: -0.605876710873923]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.7334513245026323, 'n_estimators': 35}\n",
      "100%|████████| 10/10 [00:00<00:00, 91.33trial/s, best loss: -0.6564052951354318]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  9.49trial/s, best loss: -0.5576143569592135]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 9}\n",
      " 20%|█▊       | 2/10 [00:01<00:06,  1.20trial/s, best loss: -0.6395830844186016]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.71trial/s, best loss: -0.7106084139817064]\n",
      "Ridge:  {'alpha': 0.18864458651726973, 'max_iter': 4525, 'solver': 'lsqr'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:08,  1.28s/trial, best loss: -0.516009642403565]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:05<00:05,  1.03s/trial, best loss: -0.5319954996216496]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:08<00:02,  1.02s/trial, best loss: -0.6601760767498153]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:13<00:00,  1.40s/trial, best loss: -0.6768694049499737]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.005250855615603801, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 68}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███| 10/10 [3:16:32<00:00, 1179.21s/trial, best loss: -0.49577176842300896]\n",
      "SVM:  {'C': 1.0579240592930232, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53d48e38-16b6-4a79-b17d-0753981e031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.69trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.03407876966347079, 'n_estimators': 32}\n",
      "100%|███████| 10/10 [00:00<00:00, 347.79trial/s, best loss: -0.9917763157894737]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 207.26trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9035814329697326, 'n_estimators': 31}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 245.97trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 29.21trial/s, best loss: -0.8097710390433916]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 122.69trial/s, best loss: -0.9728915662650602]\n",
      "Ridge:  {'alpha': 0.9109213563578831, 'max_iter': 13096, 'solver': 'svd'}\n",
      " 20%|████▊                   | 2/10 [00:00<00:02,  3.35trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:00<00:01,  3.73trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:02<00:02,  2.09trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:02<00:01,  2.42trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  3.57trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:03<00:00,  2.85trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  2.72trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.00999368763382883, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 62}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 94.61trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 5.204816187372024, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4d40459-02a7-4d4a-a812-835788b3564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 20.10trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.4741299142768455, 'n_estimators': 49}\n",
      "100%|███████| 10/10 [00:00<00:00, 231.56trial/s, best loss: -0.7040392776383855]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 79.09trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.0659765675385719, 'n_estimators': 44}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 159.96trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  9.76trial/s, best loss: -0.5545455148884199]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 10}\n",
      "100%|████████| 10/10 [00:05<00:00,  1.76trial/s, best loss: -0.6981411047831455]\n",
      "Ridge:  {'alpha': 0.40881000992058436, 'max_iter': 10604, 'solver': 'saga'}\n",
      " 20%|█▊       | 2/10 [00:01<00:05,  1.48trial/s, best loss: -0.8145070824538346]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:03<00:09,  1.42s/trial, best loss: -0.8606580862992906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (65) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:06<00:11,  1.91s/trial, best loss: -0.8606580862992906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:08<00:09,  1.91s/trial, best loss: -0.8606580862992906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:08<00:05,  1.47s/trial, best loss: -0.8606580862992906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:10<00:03,  1.33s/trial, best loss: -0.8606580862992906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:10<00:02,  1.22s/trial, best loss: -0.8606580862992906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:11<00:01,  1.06s/trial, best loss: -0.8606580862992906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:12<00:00,  1.23s/trial, best loss: -0.8606580862992906]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0017651146805771928, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 65}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [26:56<00:00, 161.62s/trial, best loss: -0.8809108951637526]\n",
      "SVM:  {'C': 0.2699771541097176, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da1e0f91-4f37-4884-8047-fbc75b382cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 33.65trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 0.035601909361236195, 'n_estimators': 20}\n",
      "100%|███████| 10/10 [00:00<00:00, 307.03trial/s, best loss: -0.8310239577663608]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 199.15trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8207456103239493, 'n_estimators': 23}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 261.60trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 12.59trial/s, best loss: -0.46099727410711516]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 19}\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.87trial/s, best loss: -0.792779038945752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:01<00:01,  4.46trial/s, best loss: -0.792779038945752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:02<00:00,  4.98trial/s, best loss: -0.792918431195543]\n",
      "Ridge:  {'alpha': 0.3461862636779112, 'max_iter': 2069, 'solver': 'lsqr'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 10.83trial/s, best loss: -0.6295650961806525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:00<00:00,  7.46trial/s, best loss: -0.7360884322133276]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00,  8.77trial/s, best loss: -0.7360884322133276]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:00<00:00, 10.01trial/s, best loss: -0.7360884322133276]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  9.04trial/s, best loss: -0.7360884322133276]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0018510769693431122, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 87}\n",
      "100%|████████| 10/10 [08:40<00:00, 52.03s/trial, best loss: -0.7607603072824706]\n",
      "SVM:  {'C': 0.560948543600836, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c5f1d5b-504c-4211-b439-69f800619658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 10/10 [00:00<00:00, 16.11trial/s, best loss: -0.9506551435740173]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.3624826801037896, 'n_estimators': 28}\n",
      "100%|████████| 10/10 [00:00<00:00, 287.03trial/s, best loss: -0.924668445577283]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:02<00:00,  5.00trial/s, best loss: -0.9866924652957549]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8021180782111869, 'n_estimators': 34}\n",
      "100%|███████| 10/10 [00:00<00:00, 138.88trial/s, best loss: -0.9066602944495333]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:01<00:00,  9.15trial/s, best loss: -0.9837414428646657]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 6}\n",
      "100%|████████| 10/10 [00:00<00:00, 57.36trial/s, best loss: -0.9676963992548046]\n",
      "Ridge:  {'alpha': 0.575118406138218, 'max_iter': 2603, 'solver': 'svd'}\n",
      " 10%|▉        | 1/10 [00:01<00:09,  1.08s/trial, best loss: -0.9977697240033454]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:02<00:09,  1.16s/trial, best loss: -0.9980485085029273]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:03<00:06,  1.01trial/s, best loss: -0.9980485085029273]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:04<00:06,  1.13s/trial, best loss: -0.9988848620016727]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:06<00:07,  1.47s/trial, best loss: -0.9988848620016727]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:10<00:08,  2.19s/trial, best loss: -0.9988848620016727]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (94) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:10<00:05,  1.76s/trial, best loss: -0.9988848620016727]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (71) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:14<00:04,  2.20s/trial, best loss: -0.9988848620016727]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:15<00:02,  2.01s/trial, best loss: -0.9988848620016727]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:17<00:00,  1.70s/trial, best loss: -0.9988848620016727]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.004407426453599633, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 58}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  6.11trial/s, best loss: -0.9994424310008363]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 11.52trial/s, best loss: -0.9994424310008363]\n",
      "SVM:  {'C': 0.38589512369170786, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de39dd1f-445d-45da-b921-944685a580a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 19.86trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 6, 'min_samples_split': 0.2696969835197459, 'n_estimators': 48}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 191.06trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 130.48trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6719928532241233, 'n_estimators': 33}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 174.89trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:01<00:00,  5.42trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 10}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.65trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.38209350817374843, 'max_iter': 3436, 'solver': 'sparse_cg'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:06,  1.35trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:05<00:04,  1.14trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:11<00:00,  1.12s/trial, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.0029878617510035116, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 20}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 52.99trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.466584799176326, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71aac15-12a5-4cf4-ab10-5e4530fe5266",
   "metadata": {},
   "source": [
    "### S:Yolov5 -> T:Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3103c836-1d3a-47c5-9918-a12db50e836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3050fce5-490f-4434-8b8e-9b4a1a89adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 37.48trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 0.15786813345381856, 'n_estimators': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 342.23trial/s, best loss: -0.8666016169500976]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 231.55trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.1623509922396968, 'n_estimators': 42}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 272.19trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 15.07trial/s, best loss: -0.6689638730689749]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "100%|████████| 10/10 [00:00<00:00, 64.31trial/s, best loss: -0.8388979604480022]\n",
      "Ridge:  {'alpha': 0.9815995167984221, 'max_iter': 1163, 'solver': 'svd'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 19.34trial/s, best loss: -0.8717264947053069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 20.80trial/s, best loss: -0.8717264947053069]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.009436384906538113, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 77}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 92.39trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.9993331199016982, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce2a7b48-3e15-4506-8369-8e0620552f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 10/10 [00:00<00:00, 30.06trial/s, best loss: -0.6605616180121338]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.48335988310626965, 'n_estimators': 10}\n",
      "100%|███████| 10/10 [00:00<00:00, 342.38trial/s, best loss: -0.7382208017488195]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 22.54trial/s, best loss: -0.7114547240697227]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.5513465158653922, 'n_estimators': 25}\n",
      "100%|███████| 10/10 [00:00<00:00, 262.56trial/s, best loss: -0.6887575725392843]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 8, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.95trial/s, best loss: -0.6115342661551193]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 32.45trial/s, best loss: -0.6800975524490998]\n",
      "Ridge:  {'alpha': 0.5889932596275529, 'max_iter': 12329, 'solver': 'svd'}\n",
      " 40%|███▌     | 4/10 [00:00<00:00, 25.30trial/s, best loss: -0.6787091613896744]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (94) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 24.03trial/s, best loss: -0.6787091613896744]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.003433992011932142, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 71}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [07:11<00:00, 43.12s/trial, best loss: -0.6887990583279124]\n",
      "SVM:  {'C': 0.5625409628875736, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a126438-901d-433a-9373-c2ab8c292e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 10/10 [00:00<00:00, 28.94trial/s, best loss: -0.9175281954887218]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.06626855537552767, 'n_estimators': 25}\n",
      "100%|███████| 10/10 [00:00<00:00, 381.15trial/s, best loss: -0.9344454887218044]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 249.10trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.7119757111159172, 'n_estimators': 31}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 283.09trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:00<00:00, 43.03trial/s, best loss: -0.717589342331733]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 8}\n",
      "100%|████████| 10/10 [00:00<00:00, 104.15trial/s, best loss: -0.602667247939125]\n",
      "Ridge:  {'alpha': 0.9894459382981142, 'max_iter': 4641, 'solver': 'saga'}\n",
      " 60%|█████▍   | 6/10 [00:00<00:00, 30.28trial/s, best loss: -0.9597336715282181]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 28.43trial/s, best loss: -0.9597336715282181]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.005497428824018738, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 64}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 218.30trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.9622804017091562, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16096d92-4d8a-4f03-b4c4-e945d7de04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 35.56trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.3093174431751191, 'n_estimators': 14}\n",
      "100%|███████| 10/10 [00:00<00:00, 328.86trial/s, best loss: -0.7539394904881384]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 224.94trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.5265163580836104, 'n_estimators': 7}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 266.63trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.59trial/s, best loss: -0.7033279346493733]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 18}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 11.42trial/s, best loss: -0.7376986339559519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 23.70trial/s, best loss: -0.7376986339559519]\n",
      "Ridge:  {'alpha': 0.45485374269977885, 'max_iter': 2098, 'solver': 'sag'}\n",
      " 60%|█████▍   | 6/10 [00:00<00:00, 16.31trial/s, best loss: -0.7192335860094433]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 18.40trial/s, best loss: -0.7192335860094433]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.009049191790117884, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 74}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [07:05<00:00, 42.55s/trial, best loss: -0.7422576455542722]\n",
      "SVM:  {'C': 0.15499894162952976, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "057b4d9b-2caf-4a42-af4d-22bbdecf0d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 26.33trial/s, best loss: -0.9442431000836353]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.2785243804953783, 'n_estimators': 19}\n",
      "100%|███████| 10/10 [00:00<00:00, 321.29trial/s, best loss: -0.7509231970829405]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 221.24trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.5921011933268309, 'n_estimators': 41}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 265.04trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.52trial/s, best loss: -0.5614006266013514]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      " 40%|███▌     | 4/10 [00:00<00:00, 12.57trial/s, best loss: -0.6121543404091494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 15.87trial/s, best loss: -0.6121543404091494]\n",
      "Ridge:  {'alpha': 0.577983370046019, 'max_iter': 4971, 'solver': 'cholesky'}\n",
      " 50%|████▌    | 5/10 [00:00<00:00, 17.57trial/s, best loss: -0.5785934436965939]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 17.14trial/s, best loss: -0.6376863541625181]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.008987253855026378, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 51}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [11:01<00:00, 66.12s/trial, best loss: -0.7347216137639889]\n",
      "SVM:  {'C': 0.5637115031984578, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56a9ec00-d165-4000-a614-cfef24e7cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 10/10 [00:00<00:00, 35.33trial/s, best loss: -0.7518817953721773]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 0.20036108528840202, 'n_estimators': 1}\n",
      "100%|███████| 10/10 [00:00<00:00, 369.28trial/s, best loss: -0.6962642877056036]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 21.22trial/s, best loss: -0.5034848062447728]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.3827975061681017, 'n_estimators': 14}\n",
      "100%|███████| 10/10 [00:00<00:00, 272.70trial/s, best loss: -0.6468541603055125]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 6, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.70trial/s, best loss: -0.6996097017005855]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 18}\n",
      "100%|███████| 10/10 [00:00<00:00, 143.63trial/s, best loss: -0.6792584332311123]\n",
      "Ridge:  {'alpha': 0.6332836884142595, 'max_iter': 5651, 'solver': 'saga'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 18.94trial/s, best loss: -0.6661555617507666]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:00<00:00, 18.88trial/s, best loss: -0.689294675216058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:00<00:00, 19.20trial/s, best loss: -0.689294675216058]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.004047715817641411, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 48}\n",
      "100%|████████| 10/10 [00:00<00:00, 94.75trial/s, best loss: -0.7387789238918316]\n",
      "SVM:  {'C': 0.43339979974148224, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd49ccb0-f8da-4b65-aa36-8d505697ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 26.35trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.3528821027455473, 'n_estimators': 13}\n",
      "100%|███████| 10/10 [00:00<00:00, 233.52trial/s, best loss: -0.8118204627822693]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 178.69trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.707087470547724, 'n_estimators': 7}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 204.10trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.28trial/s, best loss: -0.8163075656803005]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 8}\n",
      "100%|████████| 10/10 [00:00<00:00, 20.76trial/s, best loss: -0.9469004031312368]\n",
      "Ridge:  {'alpha': 0.8919128391622346, 'max_iter': 9553, 'solver': 'saga'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 29.53trial/s, best loss: -0.6469194312796209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (65) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:00<00:00, 18.40trial/s, best loss: -0.9965151937552272]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 17.04trial/s, best loss: -0.9965151937552272]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.009201977784945187, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 82}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 111.97trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.7017207183619735, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330156a9-92dd-4176-8be4-463f1378c5f9",
   "metadata": {},
   "source": [
    "## Target: Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9b31a-ec03-4086-9a95-1d6e83bc5bef",
   "metadata": {},
   "source": [
    "### S:Jax -> T:Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8609fc40-8988-4fee-b3de-d025ed43fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3eb9e44e-06fa-4848-b724-7104cdde69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 23.30trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.0010231640658663332, 'n_estimators': 20}\n",
      "100%|███████| 10/10 [00:00<00:00, 378.35trial/s, best loss: -0.9988104678826328]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 205.30trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8259858227837247, 'n_estimators': 37}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 277.63trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 25.23trial/s, best loss: -0.6610017889087656]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "100%|████████| 10/10 [00:00<00:00, 23.67trial/s, best loss: -0.8193202146690519]\n",
      "Ridge:  {'alpha': 0.26166709451009984, 'max_iter': 4726, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 15.27trial/s, best loss: -0.5268336314847942]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00,  9.17trial/s, best loss: -0.7093023255813954]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  6.84trial/s, best loss: -0.9543828264758497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  5.97trial/s, best loss: -0.9543828264758497]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.001738264196093273, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 59}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (81) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 54.66trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.001010192595377, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eacfc3cc-5807-467d-bd93-468033ad5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 10/10 [00:00<00:00, 24.24trial/s, best loss: -0.9892665474060822]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.2649350718887751, 'n_estimators': 48}\n",
      "100%|███████| 10/10 [00:00<00:00, 376.98trial/s, best loss: -0.5802058167198422]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 196.35trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.43252352931162413, 'n_estimators': 30}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 276.18trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': None, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 25.44trial/s, best loss: -0.5023882854139388]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:02<00:00,  4.26trial/s, best loss: -0.5974955277280859]\n",
      "Ridge:  {'alpha': 0.7381560660426815, 'max_iter': 9538, 'solver': 'svd'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|██▍                     | 1/10 [00:00<00:02,  3.43trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:01<00:05,  1.45trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:04,  1.71trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (81) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:02,  2.26trial/s, best loss: -0.6625970529111262]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:00,  3.20trial/s, best loss: -0.6625970529111262]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.05trial/s, best loss: -0.7218523504785791]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.008689851952169168, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 38}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [38:00<00:00, 228.07s/trial, best loss: -0.9235748667539605]\n",
      "SVM:  {'C': 6.671082706068476, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36b6f049-4331-4286-b695-21492a553800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 10/10 [00:00<00:00, 26.02trial/s, best loss: -0.5352112676056338]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 6, 'min_samples_split': 0.15111283926308694, 'n_estimators': 47}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 406.05trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 249.09trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9547300304435994, 'n_estimators': 46}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 287.84trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 62.08trial/s, best loss: -0.6408450704225352]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 213.95trial/s, best loss: -0.8154929577464789]\n",
      "Ridge:  {'alpha': 0.35273299239255584, 'max_iter': 11726, 'solver': 'lsqr'}\n",
      " 20%|████▊                   | 2/10 [00:00<00:00, 15.00trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00,  9.86trial/s, best loss: -0.5028169014084507]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00,  7.21trial/s, best loss: -0.5661971830985916]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (91) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:01<00:00,  6.67trial/s, best loss: -0.5661971830985916]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  7.25trial/s, best loss: -0.5661971830985916]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.00455269788585599, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 91}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 96.76trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 4.793260662692282, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06e0f593-9d74-4c94-bef8-8647fbd53381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 22.52trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 0.005347035322147753, 'n_estimators': 35}\n",
      "100%|███████| 10/10 [00:00<00:00, 361.74trial/s, best loss: -0.7293030632757317]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 160.56trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8462154739266967, 'n_estimators': 18}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 250.00trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:00<00:00, 24.91trial/s, best loss: -0.544888700367003]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.61trial/s, best loss: -0.8551076111613154]\n",
      "Ridge:  {'alpha': 0.5550523057456344, 'max_iter': 9693, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:01,  5.41trial/s, best loss: -0.8052763587407558]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:01,  3.91trial/s, best loss: -0.8052763587407558]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:00,  4.18trial/s, best loss: -0.8052763587407558]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  4.09trial/s, best loss: -0.8494273647714069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  3.34trial/s, best loss: -0.8494273647714069]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.006873174494584188, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 83}\n",
      "100%|███████| 10/10 [34:08<00:00, 204.82s/trial, best loss: -0.9810320343765563]\n",
      "SVM:  {'C': 0.41650524095691766, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4b483b4-4f74-4a6a-805c-2e137f0171ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 37.94trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 0.30513607978552804, 'n_estimators': 25}\n",
      "100%|███████| 10/10 [00:00<00:00, 359.25trial/s, best loss: -0.7315991368976265]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 209.42trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.693488619196436, 'n_estimators': 2}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 276.30trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 26.05trial/s, best loss: -0.5009958873540749]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 9}\n",
      " 30%|██▋      | 3/10 [00:01<00:02,  2.88trial/s, best loss: -0.5084558213304318]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  3.49trial/s, best loss: -0.5953101082566439]\n",
      "Ridge:  {'alpha': 0.4570623580498323, 'max_iter': 3947, 'solver': 'svd'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 15.31trial/s, best loss: -0.6062925326890802]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:00<00:00, 10.45trial/s, best loss: -0.6062925326890802]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 12.29trial/s, best loss: -0.6062925326890802]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.008876794945841286, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 45}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [08:18<00:00, 49.81s/trial, best loss: -0.9509248842742011]\n",
      "SVM:  {'C': 0.26297601845667756, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01612949-50c2-454d-b2d2-ab3b854f532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|█████████| 10/10 [00:00<00:00, 25.03trial/s, best loss: -0.595033472880512]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 0.302822337403053, 'n_estimators': 33}\n",
      "100%|███████| 10/10 [00:00<00:00, 388.63trial/s, best loss: -0.6260996256201243]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 13.86trial/s, best loss: -0.7066189624329159]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8043943981645643, 'n_estimators': 36}\n",
      "100%|███████| 10/10 [00:00<00:00, 240.96trial/s, best loss: -0.7233369603304871]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 25.12trial/s, best loss: -0.6493738819320215]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 226.20trial/s, best loss: -0.6288014311270125]\n",
      "Ridge:  {'alpha': 0.20974727051170328, 'max_iter': 4584, 'solver': 'lsqr'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:01,  7.84trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:00,  7.06trial/s, best loss: -0.6162790697674418]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  3.56trial/s, best loss: -0.7164579606440071]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:01,  3.43trial/s, best loss: -0.7164579606440071]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  4.89trial/s, best loss: -0.7164579606440071]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:02<00:00,  2.80trial/s, best loss: -0.7200357781753131]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:03<00:00,  2.97trial/s, best loss: -0.721824686940966]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.0023933238150534576, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 80}\n",
      "100%|████████| 10/10 [00:00<00:00, 82.42trial/s, best loss: -0.7280858676207513]\n",
      "SVM:  {'C': 3.310807030467598, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db074bca-78a2-4230-ab8f-fd5df7ff24de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.55trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 0.35192405388795944, 'n_estimators': 14}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 253.48trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 181.61trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.021249910780745708, 'n_estimators': 32}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 212.05trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 17.51trial/s, best loss: -0.9847942754919499]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 6}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 38.90trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.9863363758238284, 'max_iter': 8238, 'solver': 'sag'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:00<00:03,  2.24trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:01,  3.37trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:02<00:01,  2.71trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:02<00:01,  2.90trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:02<00:00,  3.80trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  3.24trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0011765764711063878, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 77}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 105.66trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.4933444557066719, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68e5b5f-1f7c-4a6b-8d1c-fa7ebef96273",
   "metadata": {},
   "source": [
    "### S:Ray -> T:Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc9e3669-71b1-4c9a-8296-234e583d89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "\n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6521457c-f4a8-4c38-b69e-eb3faa1ce0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 17.23trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 0.2263682677963036, 'n_estimators': 35}\n",
      "100%|███████| 10/10 [00:00<00:00, 290.97trial/s, best loss: -0.9992069785884219]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 123.41trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.5807511051619009, 'n_estimators': 47}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 200.66trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 15.40trial/s, best loss: -0.9879755823174667]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:02<00:00,  3.87trial/s, best loss: -0.9749552772808587]\n",
      "Ridge:  {'alpha': 0.13844183597029144, 'max_iter': 8461, 'solver': 'lsqr'}\n",
      " 20%|████▊                   | 2/10 [00:01<00:07,  1.14trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:02<00:05,  1.21trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:02<00:03,  1.63trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:03<00:03,  1.48trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:06<00:05,  1.37s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:08<00:02,  1.17s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:10<00:00,  1.09s/trial, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0026376796819370086, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 74}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 14.57trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.0610834986851088, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee3236cd-87be-48c6-8653-993dbbadf14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 10/10 [00:00<00:00, 20.28trial/s, best loss: -0.9973166368515205]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.0437738107607315, 'n_estimators': 4}\n",
      "100%|███████| 10/10 [00:00<00:00, 284.81trial/s, best loss: -0.9789849325931801]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 110.36trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.3469280611041682, 'n_estimators': 46}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 197.18trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 16.19trial/s, best loss: -0.5899526031388894]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      " 40%|███▌     | 4/10 [00:00<00:00, 36.84trial/s, best loss: -0.7182468694096601]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.82trial/s, best loss: -0.7182468694096601]\n",
      "Ridge:  {'alpha': 0.6095952182119357, 'max_iter': 5949, 'solver': 'svd'}\n",
      " 10%|▉        | 1/10 [00:02<00:18,  2.04s/trial, best loss: -0.9740608228980322]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:05<00:23,  2.94s/trial, best loss: -0.9808199472548549]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:08<00:21,  3.14s/trial, best loss: -0.991654832820021]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:09<00:13,  2.23s/trial, best loss: -0.991654832820021]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:15<00:03,  1.56s/trial, best loss: -0.991654832820021]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:02,  2.05s/trial, best loss: -0.991654832820021]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:19<00:00,  1.94s/trial, best loss: -0.991654832820021]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.005546402013775788, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 84}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [39:33<00:00, 237.30s/trial, best loss: -0.9973166368515205]\n",
      "SVM:  {'C': 0.27691367352268526, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5eae407e-6366-46d3-81e2-4b89dde305bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.81trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.2618506737801548, 'n_estimators': 5}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 375.29trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 208.85trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.10607484789840231, 'n_estimators': 4}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 273.19trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "100%|█████████| 10/10 [00:00<00:00, 43.19trial/s, best loss: -0.995774647887324]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "100%|███████| 10/10 [00:00<00:00, 106.22trial/s, best loss: -0.9605633802816902]\n",
      "Ridge:  {'alpha': 0.8419093794830931, 'max_iter': 2421, 'solver': 'sag'}\n",
      " 20%|████▊                   | 2/10 [00:01<00:04,  1.75trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (71) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:03,  2.00trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:02,  2.53trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:02<00:02,  2.35trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:02<00:01,  2.47trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:04<00:01,  1.73trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:04<00:00,  2.12trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.0053528676839364455, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 86}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 85.68trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.4033963598741121, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9782c54-0009-421d-b8a1-27399ac21442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 13.21trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.46742218206974584, 'n_estimators': 31}\n",
      "100%|███████| 10/10 [00:00<00:00, 254.12trial/s, best loss: -0.9694686756542427]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 79.61trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.3211395137626808, 'n_estimators': 6}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 75.22trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 16.36trial/s, best loss: -0.5883112332405068]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      " 60%|█████▍   | 6/10 [00:22<00:15,  3.89s/trial, best loss: -0.8772937683270936]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:32<00:00,  3.23s/trial, best loss: -0.8772937683270936]\n",
      "Ridge:  {'alpha': 0.8191042520874076, 'max_iter': 2533, 'solver': 'lsqr'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|▉        | 1/10 [00:01<00:10,  1.17s/trial, best loss: -0.8720561385389964]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:05<00:13,  1.99s/trial, best loss: -0.9892665474060822]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:09<00:10,  2.19s/trial, best loss: -0.9892665474060822]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:09<00:06,  1.57s/trial, best loss: -0.9892665474060822]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:12<00:02,  1.31s/trial, best loss: -0.9892665474060822]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:14<00:00,  1.43s/trial, best loss: -0.9892665474060822]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.001617747489795298, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 78}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [24:12<00:00, 145.23s/trial, best loss: -0.999603489294211]\n",
      "SVM:  {'C': 0.6271413751351366, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd7b2320-0fa5-4b10-b8a2-6387d41f2182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 27.65trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 0.09096014677560615, 'n_estimators': 29}\n",
      "100%|███████| 10/10 [00:00<00:00, 343.98trial/s, best loss: -0.9599524187153052]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 190.98trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.13292451964706212, 'n_estimators': 9}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 258.04trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 22.37trial/s, best loss: -0.5809527322353982]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 11}\n",
      " 40%|███▌     | 4/10 [00:03<00:04,  1.42trial/s, best loss: -0.7563118971654095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  2.87trial/s, best loss: -0.7567084078711985]\n",
      "Ridge:  {'alpha': 0.751969338967894, 'max_iter': 10516, 'solver': 'sparse_cg'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  8.70trial/s, best loss: -0.5368109473839515]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:03,  2.35trial/s, best loss: -0.8648636187595671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  5.89trial/s, best loss: -0.8648636187595671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  6.28trial/s, best loss: -0.8648636187595671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:02<00:00,  4.79trial/s, best loss: -0.8648636187595671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  4.16trial/s, best loss: -0.8648636187595671]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.009918318100571675, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 97}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [14:45<00:00, 88.50s/trial, best loss: -0.9969201261457314]\n",
      "SVM:  {'C': 0.29764540151529745, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52b238f0-a35e-4372-880b-e083011ac80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 10/10 [00:00<00:00, 14.92trial/s, best loss: -0.7321892923667079]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.426018248905652, 'n_estimators': 7}\n",
      "100%|███████| 10/10 [00:00<00:00, 315.00trial/s, best loss: -0.6824779152758055]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.92trial/s, best loss: -0.8023440237537577]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.7885815684558997, 'n_estimators': 32}\n",
      "100%|████████| 10/10 [00:00<00:00, 97.05trial/s, best loss: -0.8493720376961805]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:00<00:00, 19.41trial/s, best loss: -0.809582649429209]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 78.57trial/s, best loss: -0.7119856887298748]\n",
      "Ridge:  {'alpha': 0.13053913258627559, 'max_iter': 7716, 'solver': 'svd'}\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.85trial/s, best loss: -0.773407963410361]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:07,  1.11trial/s, best loss: -0.822206443760028]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:02<00:05,  1.26trial/s, best loss: -0.822206443760028]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:08,  1.47s/trial, best loss: -0.822206443760028]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:05<00:06,  1.23s/trial, best loss: -0.822206443760028]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:07<00:05,  1.29s/trial, best loss: -0.822206443760028]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:07<00:03,  1.18s/trial, best loss: -0.8311509875882928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:09<00:02,  1.16s/trial, best loss: -0.8311509875882928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:09<00:00,  1.10trial/s, best loss: -0.8311509875882928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:10<00:00,  1.08s/trial, best loss: -0.8311509875882928]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0038088282282226597, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 28}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 14.59trial/s, best loss: -0.8343322944138096]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (65) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 14.47trial/s, best loss: -0.8365177138852516]\n",
      "SVM:  {'C': 3.1674110574827994, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb2a8ca8-ef64-4cb6-a56c-3f47d9d5a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 18.31trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.055797094649934875, 'n_estimators': 23}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 199.73trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 134.70trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.3657882091704065, 'n_estimators': 5}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 169.59trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 12.08trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 13}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 28.72trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.37550661357853155, 'max_iter': 4969, 'solver': 'lsqr'}\n",
      " 30%|███████▏                | 3/10 [00:02<00:06,  1.12trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:06<00:04,  1.05s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/trial, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.007325775350802649, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 54}\n",
      " 30%|███████▏                | 3/10 [00:00<00:00, 27.11trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 37.29trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.394480993815964, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629b8da-ee18-41e7-8e92-d1272c1894ce",
   "metadata": {},
   "source": [
    "### S:Transformers -> T:Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b655ba81-8105-4326-b139-e9087798dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "      \n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "   \n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ab999ed-3d2f-422f-a188-ee3c3163d695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 18.73trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.24177089812452635, 'n_estimators': 33}\n",
      "100%|████████| 10/10 [00:00<00:00, 347.55trial/s, best loss: -0.992862807295797]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 163.74trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.4589371209035216, 'n_estimators': 14}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 250.35trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 19.04trial/s, best loss: -0.6949910554561718]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 11.56trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.35298591653265177, 'max_iter': 2185, 'solver': 'sparse_cg'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:05,  1.53trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:02,  2.34trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:02<00:04,  1.29trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:03<00:04,  1.25trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (89) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:04<00:01,  1.61trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:05<00:01,  1.84trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:06<00:00,  1.43trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:06<00:00,  1.54trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.004295170624436081, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 95}\n",
      " 10%|██▍                     | 1/10 [00:00<00:01,  7.13trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 11.16trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.654616499139688, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97d596d5-840f-4f1a-a237-c690cb80fe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.69trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 0.5546660950740367, 'n_estimators': 1}\n",
      "100%|███████| 10/10 [00:00<00:00, 323.38trial/s, best loss: -0.6266344540139793]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 138.56trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.441809557744831, 'n_estimators': 1}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 226.57trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 18.29trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 12}\n",
      " 20%|█▊       | 2/10 [00:03<00:12,  1.60s/trial, best loss: -0.5062611806797853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:16<00:00,  1.63s/trial, best loss: -0.8211091234347048]\n",
      "Ridge:  {'alpha': 0.9506835215105244, 'max_iter': 13838, 'solver': 'cholesky'}\n",
      " 40%|███▌     | 4/10 [00:02<00:03,  1.80trial/s, best loss: -0.6783007210962138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:03<00:01,  1.99trial/s, best loss: -0.6783007210962138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:04<00:00,  2.19trial/s, best loss: -0.6788908765652952]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.86trial/s, best loss: -0.6788908765652952]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0017489385609617749, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 77}\n",
      "100%|███████| 10/10 [36:40<00:00, 220.02s/trial, best loss: -0.8111779134315698]\n",
      "SVM:  {'C': 0.48457823069896844, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03136094-700b-46c0-b09e-d728f9ce44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 33.36trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.12010315097607493, 'n_estimators': 40}\n",
      "100%|███████| 10/10 [00:00<00:00, 396.93trial/s, best loss: -0.9965986394557823]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 232.16trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.336320003520127, 'n_estimators': 30}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 274.08trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': None, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 44.80trial/s, best loss: -0.7140845070422535]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 7}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 206.46trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.7010567362574954, 'max_iter': 13852, 'solver': 'lsqr'}\n",
      " 10%|▉        | 1/10 [00:00<00:02,  4.17trial/s, best loss: -0.6197183098591549]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:01,  3.94trial/s, best loss: -0.6676056338028169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (83) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:01,  3.76trial/s, best loss: -0.6676056338028169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  3.60trial/s, best loss: -0.7008239915684583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:01,  2.94trial/s, best loss: -0.7008239915684583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:00,  3.20trial/s, best loss: -0.8042253521126761]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:02<00:00,  3.98trial/s, best loss: -0.8042253521126761]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.17trial/s, best loss: -0.8873239436619718]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.007110417123685092, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 98}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 109.75trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.7557197068210375, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (98) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8182f3-1102-45d5-9d3a-871b0cecb1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 16.03trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.3743038990957539, 'n_estimators': 15}\n",
      "100%|███████| 10/10 [00:00<00:00, 288.86trial/s, best loss: -0.6974254467661325]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 86.91trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.036353354353834674, 'n_estimators': 18}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 168.70trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 18.52trial/s, best loss: -0.5353078951736349]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      " 50%|████▌    | 5/10 [00:08<00:08,  1.72s/trial, best loss: -0.9969201261457314]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:10<00:04,  1.42s/trial, best loss: -0.9969201261457314]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:22<00:00,  2.26s/trial, best loss: -0.9969201261457314]\n",
      "Ridge:  {'alpha': 0.5168513377635835, 'max_iter': 8226, 'solver': 'svd'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:01<00:06,  1.29trial/s, best loss: -0.8767497187540343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:03<00:09,  1.31s/trial, best loss: -0.8767497187540343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:03<00:05,  1.09trial/s, best loss: -0.8767497187540343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:04<00:02,  1.42trial/s, best loss: -0.8767497187540343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:08<00:02,  1.49s/trial, best loss: -0.8767497187540343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:12<00:00,  1.21s/trial, best loss: -0.8767497187540343]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0035667485493636806, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 66}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edee9f45-a6c0-49f9-af8e-178047a57f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 20.73trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 0.1503718602896601, 'n_estimators': 45}\n",
      "100%|███████| 10/10 [00:00<00:00, 341.32trial/s, best loss: -0.8025837744130719]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 193.90trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.5291878875945015, 'n_estimators': 14}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 254.82trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 5, 'max_features': None, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 22.61trial/s, best loss: -0.5010973203253232]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      " 80%|███████▏ | 8/10 [00:00<00:00, 11.71trial/s, best loss: -0.8202146690518783]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  4.97trial/s, best loss: -0.8202146690518783]\n",
      "Ridge:  {'alpha': 0.281236640744133, 'max_iter': 13951, 'solver': 'svd'}\n",
      " 30%|██▋      | 3/10 [00:00<00:01,  6.24trial/s, best loss: -0.6357173155303101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:00<00:00,  8.23trial/s, best loss: -0.6357173155303101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:01<00:00,  6.71trial/s, best loss: -0.6357173155303101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  6.74trial/s, best loss: -0.6472806742526235]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.0008676742787577667, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 49}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [14:38<00:00, 87.81s/trial, best loss: -0.9712852479575088]\n",
      "SVM:  {'C': 1.0409770808676877, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77f4a531-aa85-4870-86eb-1e42288cf700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 10/10 [00:00<00:00, 15.80trial/s, best loss: -0.6475849731663685]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.01694525375568956, 'n_estimators': 47}\n",
      "100%|███████| 10/10 [00:00<00:00, 348.72trial/s, best loss: -0.6074636224480388]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 11.67trial/s, best loss: -0.6771019677996422]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.5415509495460703, 'n_estimators': 37}\n",
      "100%|███████| 10/10 [00:00<00:00, 184.67trial/s, best loss: -0.7310827508621802]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 21.01trial/s, best loss: -0.6234347048300537]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "100%|████████| 10/10 [00:00<00:00, 87.41trial/s, best loss: -0.6305903398926654]\n",
      "Ridge:  {'alpha': 0.19211524581817768, 'max_iter': 12554, 'solver': 'saga'}\n",
      " 30%|██▋      | 3/10 [00:02<00:04,  1.46trial/s, best loss: -0.6502683363148479]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:03,  1.58trial/s, best loss: -0.6502683363148479]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:05<00:01,  1.62trial/s, best loss: -0.6502683363148479]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:05<00:01,  1.95trial/s, best loss: -0.6502683363148479]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:05<00:00,  1.97trial/s, best loss: -0.6502683363148479]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:08<00:00,  1.21trial/s, best loss: -0.6502683363148479]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.00033152287013095866, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 60}\n",
      "100%|████████| 10/10 [00:00<00:00, 58.61trial/s, best loss: -0.7110912343470484]\n",
      "SVM:  {'C': 6.060642260431502, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da7b980-1e4f-4bc4-bbae-cc13c41d21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.99trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.09137105349764274, 'n_estimators': 42}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 220.10trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 153.99trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.26066402801018285, 'n_estimators': 36}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 193.25trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 14.70trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 12}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 40.84trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.10334189171724575, 'max_iter': 13851, 'solver': 'saga'}\n",
      " 40%|█████████▌              | 4/10 [00:04<00:07,  1.30s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:08<00:00,  1.23trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.008496448080081128, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 61}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 69.95trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.3482009916572386, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc18c0-9cb8-4a34-852c-1381483dc85a",
   "metadata": {},
   "source": [
    "### S:Yolov5 -> T:Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab4ae7cf-f086-46f4-bc7c-0efed99dfcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598f8cd2-e68c-4e2c-a754-95dbbf5aaa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 45.41trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.10630966476538983, 'n_estimators': 2}\n",
      "100%|████████| 10/10 [00:00<00:00, 389.57trial/s, best loss: -0.964710547184774]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 245.81trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.544031184617449, 'n_estimators': 43}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 284.78trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 28.09trial/s, best loss: -0.6000682367261125]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|█████████| 10/10 [00:00<00:00, 30.69trial/s, best loss: -0.862678199288125]\n",
      "Ridge:  {'alpha': 0.6317281456614577, 'max_iter': 10088, 'solver': 'cholesky'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 27.95trial/s, best loss: -0.8883591833723697]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (71) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:00<00:00, 23.81trial/s, best loss: -0.8883591833723697]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 20.54trial/s, best loss: -0.8883591833723697]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.00875656317936526, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 71}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 113.58trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.44977267302176543, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b8c141-966d-4e4c-bf27-538e37ac475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|█████████| 10/10 [00:00<00:00, 30.48trial/s, best loss: -0.964221824686941]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.27318017685601115, 'n_estimators': 38}\n",
      "100%|████████| 10/10 [00:00<00:00, 399.77trial/s, best loss: -0.614213525625657]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 244.71trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9299525033017547, 'n_estimators': 34}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 284.60trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 28.71trial/s, best loss: -0.5803441344079081]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 15}\n",
      "100%|████████| 10/10 [00:00<00:00, 57.00trial/s, best loss: -0.6929900595688178]\n",
      "Ridge:  {'alpha': 0.23567397522325279, 'max_iter': 10685, 'solver': 'cholesky'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 29.59trial/s, best loss: -0.6020139055382402]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 30.37trial/s, best loss: -0.6209910923408886]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.006242287984168215, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 55}\n",
      "100%|████████| 10/10 [14:47<00:00, 88.73s/trial, best loss: -0.9544473747302805]\n",
      "SVM:  {'C': 0.2828665284504838, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f0ba37-867f-4e9a-b5ae-a5a8c4662288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 45.06trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.328673641472053, 'n_estimators': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 414.19trial/s, best loss: -0.9605442176870748]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 261.66trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.011343409631655362, 'n_estimators': 9}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 300.74trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 66.48trial/s, best loss: -0.6622017821212993]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 8}\n",
      "100%|███████| 10/10 [00:00<00:00, 223.27trial/s, best loss: -0.9645875251509055]\n",
      "Ridge:  {'alpha': 0.45693718861344435, 'max_iter': 10046, 'solver': 'sparse_cg'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 11.76trial/s, best loss: -0.9958225543738622]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (83) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 24.73trial/s, best loss: -0.9958225543738622]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.003423833194219599, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 84}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 240.27trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 13.282564871069997, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f6bd94-8dc7-45f3-aeb6-e75e99b1a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 38.26trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.556781782949546, 'n_estimators': 18}\n",
      "100%|███████| 10/10 [00:00<00:00, 350.61trial/s, best loss: -0.6465060951994541]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 240.05trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6993073037370626, 'n_estimators': 28}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 288.83trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 26.88trial/s, best loss: -0.5501355513343046]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 9}\n",
      " 70%|██████▎  | 7/10 [00:01<00:00,  6.09trial/s, best loss: -0.6733581690426571]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  9.42trial/s, best loss: -0.6733581690426571]\n",
      "Ridge:  {'alpha': 0.27845269105250925, 'max_iter': 1066, 'solver': 'cholesky'}\n",
      " 60%|█████▍   | 6/10 [00:00<00:00, 26.03trial/s, best loss: -0.5818103019014073]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 24.91trial/s, best loss: -0.5818103019014073]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.001227961713798087, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 80}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [06:52<00:00, 41.27s/trial, best loss: -0.8989635394574259]\n",
      "SVM:  {'C': 0.3923422445081089, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c959782e-7eed-41ef-a683-8ee1e1f6f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 32.08trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.601341957887429, 'n_estimators': 2}\n",
      "100%|███████| 10/10 [00:00<00:00, 365.70trial/s, best loss: -0.6308854176272062]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 238.35trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.4444452831875309, 'n_estimators': 43}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 279.14trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 28.64trial/s, best loss: -0.5461888866348229]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "100%|████████| 10/10 [00:00<00:00, 18.72trial/s, best loss: -0.6512550024897183]\n",
      "Ridge:  {'alpha': 0.36644414845476614, 'max_iter': 12510, 'solver': 'svd'}\n",
      " 40%|███▌     | 4/10 [00:00<00:00, 19.22trial/s, best loss: -0.6031757741179942]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 23.61trial/s, best loss: -0.6031757741179942]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.005645372473174076, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 66}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [08:04<00:00, 48.40s/trial, best loss: -0.9302602216771482]\n",
      "SVM:  {'C': 0.14821836950452108, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adddea50-3fdc-4d3f-987a-53a707d429ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|█████████| 10/10 [00:00<00:00, 25.43trial/s, best loss: -0.532753628534017]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.6309204836240538, 'n_estimators': 9}\n",
      "100%|███████| 10/10 [00:00<00:00, 400.88trial/s, best loss: -0.6699739962746436]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 38.18trial/s, best loss: -0.6517990520627778]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.3620447969362864, 'n_estimators': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 288.17trial/s, best loss: -0.6147299116611032]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 9, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 28.64trial/s, best loss: -0.6492079007063423]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 12}\n",
      "100%|███████| 10/10 [00:00<00:00, 249.14trial/s, best loss: -0.6266344540139793]\n",
      "Ridge:  {'alpha': 0.5403949211696994, 'max_iter': 8735, 'solver': 'cholesky'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 28.03trial/s, best loss: -0.6352839201077033]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:00<00:00, 21.26trial/s, best loss: -0.6352839201077033]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 21.07trial/s, best loss: -0.6352839201077033]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.008115345551296069, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 73}\n",
      "100%|███████| 10/10 [00:00<00:00, 123.49trial/s, best loss: -0.6490880253766852]\n",
      "SVM:  {'C': 4.977428226714868, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6685a7ad-6568-412c-ad40-c1e0038c28d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 33.74trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.32823278544413004, 'n_estimators': 12}\n",
      "100%|███████| 10/10 [00:00<00:00, 266.05trial/s, best loss: -0.8667724028548771]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 193.90trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.7192177017216449, 'n_estimators': 14}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 217.05trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 27.11trial/s, best loss: -0.9211865813400216]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 8}\n",
      "100%|████████| 10/10 [00:00<00:00, 37.15trial/s, best loss: -0.9992069785884219]\n",
      "Ridge:  {'alpha': 0.8599502999490178, 'max_iter': 14571, 'solver': 'sparse_cg'}\n",
      " 40%|█████████▌              | 4/10 [00:00<00:00, 18.03trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.47trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0014536590895164873, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 67}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 114.48trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 3.2591152351211856, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abe122-80a8-4bfa-895a-661a3119c9d5",
   "metadata": {},
   "source": [
    "## Target: Yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe9d93-7fbe-49b5-a180-04d35db188a0",
   "metadata": {},
   "source": [
    "### S:Jax -> T:Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8293fe4f-076a-4903-9ade-d538eb2f9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbf325c7-cfcb-4b80-813f-b693eac0301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 26.57trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.22730425385750497, 'n_estimators': 16}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 433.74trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 250.91trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.09149800770642137, 'n_estimators': 39}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 301.03trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 1, 'max_features': 'log2', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 168.25trial/s, best loss: -0.8108108108108107]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 43.04trial/s, best loss: -0.8716216216216216]\n",
      "Ridge:  {'alpha': 0.4751801608098557, 'max_iter': 4073, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00,  9.05trial/s, best loss: -0.8648648648648649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:00,  8.93trial/s, best loss: -0.8648648648648649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:00<00:00,  6.08trial/s, best loss: -0.8783783783783784]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (98) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (89) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  9.34trial/s, best loss: -0.8783783783783784]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  7.53trial/s, best loss: -0.8783783783783784]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.008897727330154573, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 89}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (89) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 69.07trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.8123071670971431, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a015f5f-f479-4334-9c7f-5477f1ca3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 28.63trial/s, best loss: -0.8108108108108107]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.14189275103267873, 'n_estimators': 43}\n",
      "100%|███████| 10/10 [00:00<00:00, 426.58trial/s, best loss: -0.6621621621621622]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 211.22trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.11580519226571856, 'n_estimators': 11}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 288.32trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 129.75trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      " 80%|███████▏ | 8/10 [00:00<00:00, 12.27trial/s, best loss: -0.6689189189189189]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  5.51trial/s, best loss: -0.6689189189189189]\n",
      "Ridge:  {'alpha': 0.8391450127970801, 'max_iter': 3420, 'solver': 'svd'}\n",
      " 30%|██▋      | 3/10 [00:00<00:01,  6.97trial/s, best loss: -0.8327120223671948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  4.32trial/s, best loss: -0.8327120223671948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:00,  4.72trial/s, best loss: -0.8327120223671948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  4.03trial/s, best loss: -0.8327120223671948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  3.89trial/s, best loss: -0.8327120223671948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:02<00:00,  4.10trial/s, best loss: -0.8327120223671948]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  4.05trial/s, best loss: -0.8327120223671948]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0015784699274648116, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 21}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [50:12<00:00, 301.24s/trial, best loss: -0.8310810810810811]\n",
      "SVM:  {'C': 0.592746767618406, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03d503cf-fa3f-4892-80e3-9753f646102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 28.85trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 0.48357647472807863, 'n_estimators': 32}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 449.47trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 269.74trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6150883822895927, 'n_estimators': 17}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 311.19trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 241.48trial/s, best loss: -0.8]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 252.15trial/s, best loss: -0.8818181818181818]\n",
      "Ridge:  {'alpha': 0.15350801354641852, 'max_iter': 4301, 'solver': 'svd'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 17.37trial/s, best loss: -0.6363636363636364]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (81) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 24.60trial/s, best loss: -0.6363636363636364]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.007698232779771741, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 51}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 117.93trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.1819242974651498, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1f8bbc6-427a-404e-bdfd-b4eedb4d63da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 33.43trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.22643194079129758, 'n_estimators': 1}\n",
      "100%|███████| 10/10 [00:00<00:00, 431.24trial/s, best loss: -0.8296831314072692]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 205.15trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.35763878905468793, 'n_estimators': 25}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 288.28trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 162.38trial/s, best loss: -0.7087604846225535]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      " 30%|██▋      | 3/10 [00:01<00:02,  3.26trial/s, best loss: -0.8678937558247903]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  4.66trial/s, best loss: -0.8678937558247903]\n",
      "Ridge:  {'alpha': 0.14330158860814804, 'max_iter': 7175, 'solver': 'cholesky'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 15.60trial/s, best loss: -0.7360205032618825]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00,  8.74trial/s, best loss: -0.787744641192917]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00,  7.84trial/s, best loss: -0.7914725069897484]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:01<00:00,  7.12trial/s, best loss: -0.7914725069897484]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  7.89trial/s, best loss: -0.7914725069897484]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.005860135982933575, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 72}\n",
      "100%|████████| 10/10 [14:56<00:00, 89.60s/trial, best loss: -0.8867660764212489]\n",
      "SVM:  {'C': 1.365326756897423, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "886d8203-4638-478a-9c63-eed48005a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 36.12trial/s, best loss: -0.8040540540540541]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.49277899246475554, 'n_estimators': 11}\n",
      "100%|███████| 10/10 [00:00<00:00, 270.05trial/s, best loss: -0.8445945945945945]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 260.74trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.21236962138513077, 'n_estimators': 23}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 307.97trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 202.03trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 10}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 42.33trial/s, best loss: -0.75]\n",
      "Ridge:  {'alpha': 0.5065091039245277, 'max_iter': 2102, 'solver': 'svd'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (89) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 52.43trial/s, best loss: -0.5608108108108109]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0006251871466842754, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 11}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [25:13<00:00, 151.36s/trial, best loss: -0.9121621621621622]\n",
      "SVM:  {'C': 0.4338810767913887, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60782691-c9da-40c1-8339-42607986722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 27.73trial/s, best loss: -0.6621621621621622]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 9, 'min_samples_split': 0.07076418584150257, 'n_estimators': 44}\n",
      "100%|███████| 10/10 [00:00<00:00, 404.66trial/s, best loss: -0.6756756756756757]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.44trial/s, best loss: -0.6891891891891893]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8052986547557551, 'n_estimators': 39}\n",
      "100%|███████| 10/10 [00:00<00:00, 250.68trial/s, best loss: -0.6486486486486487]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 161.19trial/s, best loss: -0.6148648648648649]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 199.72trial/s, best loss: -0.6148648648648649]\n",
      "Ridge:  {'alpha': 0.7620112825980053, 'max_iter': 11483, 'solver': 'saga'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:04,  1.94trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:01<00:04,  1.77trial/s, best loss: -0.6959459459459459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (81) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:02<00:05,  1.28trial/s, best loss: -0.6959459459459459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:03<00:02,  1.81trial/s, best loss: -0.6959459459459459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:03<00:01,  2.61trial/s, best loss: -0.6959459459459459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:03<00:00,  2.79trial/s, best loss: -0.6959459459459459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:04<00:00,  3.06trial/s, best loss: -0.6959459459459459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.10trial/s, best loss: -0.6959459459459459]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.00957721951247579, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 81}\n",
      "100%|███████| 10/10 [00:00<00:00, 103.11trial/s, best loss: -0.7027027027027027]\n",
      "SVM:  {'C': 2.69537375994563, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f6cb0f3-8bfd-4a4a-84fb-686d0d5550fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 33.35trial/s, best loss: -0.8243243243243243]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.03666303753148836, 'n_estimators': 44}\n",
      "100%|███████| 10/10 [00:00<00:00, 224.29trial/s, best loss: -0.8243243243243243]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████| 10/10 [00:00<00:00, 184.29trial/s, best loss: -0.8243243243243243]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.5753964400628175, 'n_estimators': 46}\n",
      "100%|████████| 10/10 [00:00<00:00, 84.10trial/s, best loss: -0.8881640260950606]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 9, 'splitter': 'random'}\n",
      "100%|███████| 10/10 [00:00<00:00, 117.04trial/s, best loss: -0.8108108108108107]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 9}\n",
      "100%|████████| 10/10 [00:00<00:00, 43.87trial/s, best loss: -0.8243243243243243]\n",
      "Ridge:  {'alpha': 0.8022614711478244, 'max_iter': 5023, 'solver': 'sag'}\n",
      " 20%|█▊       | 2/10 [00:01<00:03,  2.18trial/s, best loss: -0.7837837837837838]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:02,  2.70trial/s, best loss: -0.7837837837837838]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:00,  3.91trial/s, best loss: -0.7837837837837838]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.11trial/s, best loss: -0.7837837837837838]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.005210132031269053, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 86}\n",
      "100%|███████| 10/10 [00:00<00:00, 156.28trial/s, best loss: -0.8243243243243243]\n",
      "SVM:  {'C': 0.5625207671924385, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (14) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e21e7d-9316-4641-b5f1-495eb54840d6",
   "metadata": {},
   "source": [
    "### S:Lightning -> T:Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e15d0e9-d728-4c76-8fec-f20eafcecfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bf93289-0a53-4dd9-b97b-73d7ce990899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 34.69trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.6605415011049879, 'n_estimators': 49}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 461.41trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 244.80trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.19630047584556665, 'n_estimators': 20}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 304.92trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 164.43trial/s, best loss: -0.8986486486486487]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      "100%|████████| 10/10 [00:00<00:00, 34.79trial/s, best loss: -0.8783783783783784]\n",
      "Ridge:  {'alpha': 0.4229675742700174, 'max_iter': 14730, 'solver': 'lsqr'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 13.76trial/s, best loss: -0.9594594594594594]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:00<00:00, 17.85trial/s, best loss: -0.9594594594594594]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 16.52trial/s, best loss: -0.9594594594594594]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.007247872565513732, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 53}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 109.25trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 3.080506403592277, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b989a68a-5c74-4595-9086-048820330f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 31.09trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.25862088197686206, 'n_estimators': 32}\n",
      "100%|███████| 10/10 [00:00<00:00, 401.73trial/s, best loss: -0.9347623485554521]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 196.36trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.7202266789381194, 'n_estimators': 41}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 278.15trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 154.19trial/s, best loss: -0.5931966449207828]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 13}\n",
      " 30%|██▋      | 3/10 [00:00<00:01,  6.41trial/s, best loss: -0.7327586206896551]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:03,  1.67trial/s, best loss: -0.7327586206896551]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.22trial/s, best loss: -0.7327586206896551]\n",
      "Ridge:  {'alpha': 0.5804672388621298, 'max_iter': 11804, 'solver': 'lsqr'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:01,  4.85trial/s, best loss: -0.5060577819198508]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:02,  2.22trial/s, best loss: -0.8350419384902144]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  2.66trial/s, best loss: -0.8350419384902144]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  4.06trial/s, best loss: -0.8350419384902144]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.16trial/s, best loss: -0.8350419384902144]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.004906931917445395, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 97}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [16:24<00:00, 98.42s/trial, best loss: -0.9256756756756757]\n",
      "SVM:  {'C': 1.2575296685866124, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab54868a-df67-4032-a67f-0c600904cc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 41.38trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.5467959150052346, 'n_estimators': 45}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 450.59trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 268.82trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.7363453522996518, 'n_estimators': 20}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 309.20trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 262.13trial/s, best loss: -0.8636363636363636]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 8}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 148.62trial/s, best loss: -0.9]\n",
      "Ridge:  {'alpha': 0.37133988117883876, 'max_iter': 13210, 'solver': 'lsqr'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 17.39trial/s, best loss: -0.6242424242424243]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00, 12.91trial/s, best loss: -0.9090909090909092]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:00<00:00, 16.64trial/s, best loss: -0.990909090909091]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.008955070869515743, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 93}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 180.09trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.243369272772435, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b34742d-93e0-4538-9e4d-4780d6d9b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 29.55trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 9, 'min_samples_split': 0.2171729800784491, 'n_estimators': 32}\n",
      "100%|███████| 10/10 [00:00<00:00, 439.52trial/s, best loss: -0.9391891891891893]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 227.16trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.13202791888282772, 'n_estimators': 44}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 294.50trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': None, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 177.17trial/s, best loss: -0.6022833178005592]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 15}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 14.62trial/s, best loss: -0.6742777260018639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 12.15trial/s, best loss: -0.6742777260018639]\n",
      "Ridge:  {'alpha': 0.44648772746784615, 'max_iter': 14235, 'solver': 'svd'}\n",
      " 20%|██        | 2/10 [00:00<00:00,  8.96trial/s, best loss: -0.787744641192917]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00, 10.06trial/s, best loss: -0.787744641192917]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00,  7.52trial/s, best loss: -0.787744641192917]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  7.31trial/s, best loss: -0.8087138863000932]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.002176171448740656, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 46}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [17:54<00:00, 107.42s/trial, best loss: -0.8851351351351351]\n",
      "SVM:  {'C': 0.36337628783232573, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2a09a88-ce17-49f0-9b1e-261e9b3688fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 35.71trial/s, best loss: -0.9932432432432432]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.5345529398858861, 'n_estimators': 12}\n",
      "100%|████████| 10/10 [00:00<00:00, 443.87trial/s, best loss: -0.896551724137931]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 269.08trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.3805397861079691, 'n_estimators': 41}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 306.13trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 205.83trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 12}\n",
      "100%|████████| 10/10 [00:00<00:00, 129.21trial/s, best loss: -0.841798695246971]\n",
      "Ridge:  {'alpha': 0.3464192440596723, 'max_iter': 11795, 'solver': 'lsqr'}\n",
      "100%|████████| 10/10 [00:00<00:00, 42.01trial/s, best loss: -0.7353215284249767]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.00871850581258245, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 97}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [00:00<00:00, 331.34trial/s, best loss: -0.7075955265610437]\n",
      "SVM:  {'C': 2.87819921717081, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42ed8f23-c3a7-4fd1-82e9-1c5b0043f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 20.37trial/s, best loss: -0.6891891891891893]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'min_samples_leaf': 9, 'min_samples_split': 0.03791223959566292, 'n_estimators': 12}\n",
      "100%|███████| 10/10 [00:00<00:00, 404.64trial/s, best loss: -0.6756756756756757]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 13.06trial/s, best loss: -0.7364864864864865]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.07941254376727862, 'n_estimators': 28}\n",
      "100%|███████| 10/10 [00:00<00:00, 182.33trial/s, best loss: -0.7432432432432432]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_split': 8, 'splitter': 'random'}\n",
      "100%|███████| 10/10 [00:00<00:00, 160.39trial/s, best loss: -0.7297297297297297]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 193.80trial/s, best loss: -0.6824324324324325]\n",
      "Ridge:  {'alpha': 0.30124411605543533, 'max_iter': 14090, 'solver': 'cholesky'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  5.34trial/s, best loss: -0.7094594594594594]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:03,  2.29trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (85) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:01<00:02,  2.43trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:04,  1.42trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:02,  1.71trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (99) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:04<00:01,  1.73trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:04<00:01,  1.91trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:04<00:00,  2.08trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.82trial/s, best loss: -0.7567567567567568]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.001986258225812804, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 85}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 26.96trial/s, best loss: -0.7567567567567568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 37.05trial/s, best loss: -0.7567567567567568]\n",
      "SVM:  {'C': 2.5396020698581037, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9cd6d24-2321-40d3-a288-1e568db12a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.99trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 9, 'min_samples_split': 0.09373686713537088, 'n_estimators': 12}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 265.35trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 182.08trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.057316318169970695, 'n_estimators': 33}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 215.58trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 119.60trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 14}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 23.47trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.5632426274287508, 'max_iter': 10230, 'solver': 'sag'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:06,  1.44trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:02,  2.51trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:01,  3.09trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:02<00:00,  3.01trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  3.44trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:04<00:00,  2.47trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0044423332424045146, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 93}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 129.84trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 5.1508438783788, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcad46-f538-4039-8fad-379a7d558978",
   "metadata": {},
   "source": [
    "### S:Ray -> T:Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66606c7f-9711-4960-83ff-d81b8723bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27a667a1-88df-4274-ae9c-54981f9c3da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 24.47trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.5977806332780713, 'n_estimators': 37}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 445.63trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 227.89trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8577691470449591, 'n_estimators': 10}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 299.35trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 180.88trial/s, best loss: -0.9256756756756757]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 14}\n",
      "100%|████████| 10/10 [00:00<00:00, 59.22trial/s, best loss: -0.7900745573159367]\n",
      "Ridge:  {'alpha': 0.8499561740821431, 'max_iter': 8629, 'solver': 'sparse_cg'}\n",
      " 20%|████▊                   | 2/10 [00:00<00:01,  5.34trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:00<00:01,  4.97trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:01<00:00,  8.47trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:01<00:00,  6.52trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.0010418105536834346, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 92}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 110.68trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.24952913742684096, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b41e528f-23ad-46af-b865-1f8b822d77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 14.96trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 0.11798266608544883, 'n_estimators': 45}\n",
      "100%|███████| 10/10 [00:00<00:00, 305.04trial/s, best loss: -0.9107642124883504]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 114.74trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.021325757779333883, 'n_estimators': 8}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 218.24trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 92.67trial/s, best loss: -0.5803821062441752]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:10<00:00,  1.06s/trial, best loss: -0.8040540540540541]\n",
      "Ridge:  {'alpha': 0.7565959448714329, 'max_iter': 6041, 'solver': 'lsqr'}\n",
      " 20%|█▊       | 2/10 [00:02<00:10,  1.29s/trial, best loss: -0.8851351351351351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:05<00:12,  1.72s/trial, best loss: -0.8918918918918919]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:11<00:07,  1.88s/trial, best loss: -0.8918918918918919]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:12<00:04,  1.48s/trial, best loss: -0.8918918918918919]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:12<00:02,  1.15s/trial, best loss: -0.8918918918918919]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:16<00:01,  1.98s/trial, best loss: -0.9384902143522834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:17<00:00,  1.76s/trial, best loss: -0.9384902143522834]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0027600073761627156, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 72}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (42) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████| 10/10 [1:06:41<00:00, 400.11s/trial, best loss: -0.9324324324324325]\n",
      "SVM:  {'C': 1.2838642035992582, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0af18f9-3cc2-4d33-ab05-8dc62f40bdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 32.88trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.19352441366220585, 'n_estimators': 45}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 441.00trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 256.95trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.881058465122201, 'n_estimators': 47}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 307.34trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'splitter': 'random'}\n",
      "100%|███████| 10/10 [00:00<00:00, 204.99trial/s, best loss: -0.8878787878787879]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 194.63trial/s, best loss: -0.8696969696969697]\n",
      "Ridge:  {'alpha': 0.37865715615441886, 'max_iter': 14839, 'solver': 'lsqr'}\n",
      " 20%|██        | 2/10 [00:00<00:00, 10.01trial/s, best loss: -0.990909090909091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (62) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 11.59trial/s, best loss: -0.990909090909091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00,  7.40trial/s, best loss: -0.990909090909091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:01<00:00,  7.25trial/s, best loss: -0.990909090909091]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:01<00:00,  7.76trial/s, best loss: -0.990909090909091]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.006957287116914084, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 62}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 132.22trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.4238985416753507, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a412ab0e-dc84-4341-ad88-1dd7ecc81604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 26.69trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 0.6037795085444015, 'n_estimators': 41}\n",
      "100%|███████| 10/10 [00:00<00:00, 429.57trial/s, best loss: -0.8634669151910531]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 213.09trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.19596183112925913, 'n_estimators': 28}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 283.90trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 164.88trial/s, best loss: -0.6773066169617894]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 13}\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  5.06trial/s, best loss: -0.798928238583411]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:02<00:00,  3.88trial/s, best loss: -0.798928238583411]\n",
      "Ridge:  {'alpha': 0.6652150192149621, 'max_iter': 6945, 'solver': 'sparse_cg'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███▎       | 3/10 [00:00<00:01,  4.59trial/s, best loss: -0.81547064305685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:00,  6.61trial/s, best loss: -0.8161696178937557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  4.61trial/s, best loss: -0.8161696178937557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  5.04trial/s, best loss: -0.8161696178937557]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0074654176454279535, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 54}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [28:22<00:00, 170.25s/trial, best loss: -0.9391891891891893]\n",
      "SVM:  {'C': 1.08548370421866, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef64707d-2538-44c2-9f0c-0f5e4487b1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 34.42trial/s, best loss: -0.5]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.14337937413921753, 'n_estimators': 45}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 307.31trial/s, best loss: -0.5]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 7, 'splitter': 'random'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 13\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m peterfilter \u001b[38;5;241m=\u001b[39m Peterfilter()\n\u001b[1;32m      4\u001b[0m X_source, Y_source, X_target, Y_target \u001b[38;5;241m=\u001b[39m peterfilter\u001b[38;5;241m.\u001b[39mrun(X_source, Y_source, X_target, Y_target)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mhyperopt_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [61], line 39\u001b[0m, in \u001b[0;36mhyperopt_classifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCART: \u001b[39m\u001b[38;5;124m\"\u001b[39m, space_eval(cart_space, best_params_cart))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#implement Hyperopt on KNN\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m best_params_knn \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective_knn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknn_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN: \u001b[39m\u001b[38;5;124m\"\u001b[39m, space_eval(knn_space, best_params_knn))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#implement Hyperopt on Ridge\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn [10], line 37\u001b[0m, in \u001b[0;36mobjective_knn\u001b[0;34m(search_space)\u001b[0m\n\u001b[1;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msearch_space)\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_source, Y_source)\n\u001b[0;32m---> 37\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(Y_target, y_pred)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39mroc_auc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m:STATUS_OK}\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:266\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:808\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_neighbors <= n_samples, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but n_samples = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, n_neighbors = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    813\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    814\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 13"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f279523-d718-4709-a2fc-e3b74d8f2331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 13.22trial/s, best loss: -0.6621621621621622]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 0.07914607951075137, 'n_estimators': 40}\n",
      "100%|███████| 10/10 [00:00<00:00, 327.84trial/s, best loss: -0.6891891891891893]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.66trial/s, best loss: -0.7162162162162162]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6831787514868233, 'n_estimators': 49}\n",
      "100%|████████| 10/10 [00:00<00:00, 96.33trial/s, best loss: -0.7364864864864865]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 119.02trial/s, best loss: -0.722972972972973]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:00<00:00, 52.05trial/s, best loss: -0.6486486486486487]\n",
      "Ridge:  {'alpha': 0.21102163838609728, 'max_iter': 1173, 'solver': 'sag'}\n",
      " 10%|▉        | 1/10 [00:01<00:09,  1.08s/trial, best loss: -0.7364864864864865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:03<00:12,  1.60s/trial, best loss: -0.7364864864864865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:05<00:13,  1.96s/trial, best loss: -0.7364864864864865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (48) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:06<00:09,  1.51s/trial, best loss: -0.7364864864864865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:07<00:06,  1.35s/trial, best loss: -0.7432432432432432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:07<00:02,  1.41trial/s, best loss: -0.7432432432432432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:08<00:01,  1.18trial/s, best loss: -0.7432432432432432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:12<00:01,  1.79s/trial, best loss: -0.7432432432432432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:13<00:00,  1.32s/trial, best loss: -0.7432432432432432]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0015845977115890308, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 74}\n",
      " 10%|▉        | 1/10 [00:00<00:00,  9.06trial/s, best loss: -0.7364864864864865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (18) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 20.21trial/s, best loss: -0.75]\n",
      "SVM:  {'C': 4.338174335885853, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d0ba968-e8a1-47b7-b9ec-a397fc2d18f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 25.04trial/s, best loss: -0.8716216216216216]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.5106771781620997, 'n_estimators': 43}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 213.24trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████| 10/10 [00:00<00:00, 137.63trial/s, best loss: -0.8716216216216216]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.3978434749589512, 'n_estimators': 28}\n",
      "100%|███████| 10/10 [00:00<00:00, 191.54trial/s, best loss: -0.8716216216216216]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 57.77trial/s, best loss: -0.8648648648648649]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      "100%|████████| 10/10 [00:00<00:00, 25.17trial/s, best loss: -0.8513513513513513]\n",
      "Ridge:  {'alpha': 0.43740376265707837, 'max_iter': 12131, 'solver': 'saga'}\n",
      " 60%|█████▍   | 6/10 [00:06<00:04,  1.04s/trial, best loss: -0.8581081081081081]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:08<00:01,  1.01trial/s, best loss: -0.8581081081081081]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:10<00:00,  1.04s/trial, best loss: -0.8581081081081081]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.008443998844650418, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 51}\n",
      "100%|████████| 10/10 [00:00<00:00, 50.13trial/s, best loss: -0.8716216216216216]\n",
      "SVM:  {'C': 5.815974819729837, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624c576-ceee-45c2-a8ce-b27696d1894c",
   "metadata": {},
   "source": [
    "### S:Transformers -> T:Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea3d8624-30e8-414c-8144-730e0ef13b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b38cc43-ca35-4e67-94c5-a6f23ab17d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 26.79trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.19945104058903707, 'n_estimators': 17}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 440.11trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 232.20trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.7556627854755213, 'n_estimators': 19}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 307.92trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 170.40trial/s, best loss: -0.8175675675675675]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 76.01trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.27337443926047944, 'max_iter': 1267, 'solver': 'lsqr'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  8.56trial/s, best loss: -0.8310810810810811]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (85) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00,  8.45trial/s, best loss: -0.8445945945945945]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (37) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (35) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:00<00:00,  7.69trial/s, best loss: -0.8986486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (90) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:01<00:00,  7.42trial/s, best loss: -0.8986486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  6.74trial/s, best loss: -0.8986486486486487]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.000978535452599318, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 88}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 78.12trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.9794065292497414, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "faf93fef-f92e-4e58-9d5f-4de6436e965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 24.24trial/s, best loss: -0.8716216216216216]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.3143453563031734, 'n_estimators': 25}\n",
      "100%|███████| 10/10 [00:00<00:00, 347.18trial/s, best loss: -0.7837837837837838]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 137.96trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.7634552793671858, 'n_estimators': 6}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 211.36trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 117.23trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 15}\n",
      " 40%|███▌     | 4/10 [00:05<00:07,  1.23s/trial, best loss: -0.8716216216216216]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:05<00:01,  1.56trial/s, best loss: -0.8716216216216216]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:09<00:00,  1.08trial/s, best loss: -0.8716216216216216]\n",
      "Ridge:  {'alpha': 0.6519291068293467, 'max_iter': 2050, 'solver': 'svd'}\n",
      " 40%|███▌     | 4/10 [00:01<00:02,  2.92trial/s, best loss: -0.8236253494874185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:03<00:00,  2.23trial/s, best loss: -0.8236253494874185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:04<00:00,  2.17trial/s, best loss: -0.8236253494874185]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.007946100123124474, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 20}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [24:44<00:00, 148.46s/trial, best loss: -0.7432432432432432]\n",
      "SVM:  {'C': 1.321834323523943, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9de8df77-bba4-42a6-add8-a2a277fe95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 55.19trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 0.5911396153597731, 'n_estimators': 1}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 443.80trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 263.64trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.4977766881831266, 'n_estimators': 31}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 311.08trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 239.74trial/s, best loss: -0.8818181818181818]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 7}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 241.31trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.9390501915588442, 'max_iter': 13163, 'solver': 'lsqr'}\n",
      " 40%|███▌     | 4/10 [00:00<00:00, 16.42trial/s, best loss: -0.9272727272727272]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:00<00:00, 14.37trial/s, best loss: -0.9272727272727272]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (91) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (43) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 16.85trial/s, best loss: -0.9272727272727272]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.003242469578996133, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 76}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 165.47trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.0489930223798927, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (90) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23852734-dc1c-4ce7-97fa-e08823be4d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 27.47trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.580700675061076, 'n_estimators': 20}\n",
      "100%|███████| 10/10 [00:00<00:00, 417.32trial/s, best loss: -0.6959459459459459]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 176.44trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.6429668187792251, 'n_estimators': 38}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 245.17trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': None, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 155.54trial/s, best loss: -0.6209226467847156]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 13}\n",
      " 50%|████▌    | 5/10 [00:01<00:01,  2.81trial/s, best loss: -0.8918918918918919]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:04<00:01,  1.55trial/s, best loss: -0.8918918918918919]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.78trial/s, best loss: -0.8918918918918919]\n",
      "Ridge:  {'alpha': 0.4232043189828121, 'max_iter': 2828, 'solver': 'cholesky'}\n",
      " 30%|██▋      | 3/10 [00:00<00:01,  4.32trial/s, best loss: -0.6787045666356012]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:01,  3.83trial/s, best loss: -0.7523299161230196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:02<00:00,  3.80trial/s, best loss: -0.7532618825722274]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.004417445593841909, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 59}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1614a805-1861-40ac-80a6-85ff17411fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 40.70trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.3517233674303837, 'n_estimators': 15}\n",
      "100%|███████| 10/10 [00:00<00:00, 398.44trial/s, best loss: -0.6148648648648649]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 251.16trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.46661931840418724, 'n_estimators': 40}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 297.99trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 205.74trial/s, best loss: -0.5]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 11}\n",
      " 50%|████████████            | 5/10 [00:00<00:00, 18.25trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.15trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.6321586467320347, 'max_iter': 12385, 'solver': 'svd'}\n",
      " 50%|████████████            | 5/10 [00:00<00:00, 48.14trial/s, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (38) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 35.39trial/s, best loss: -0.5]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0015310385654893465, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 38}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [04:41<00:00, 28.19s/trial, best loss: -0.5097856477166821]\n",
      "SVM:  {'C': 0.33207058029764264, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45613434-c34c-4a0f-a0f2-ce92f0a1b7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 17.81trial/s, best loss: -0.6418918918918919]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.022036040142707325, 'n_estimators': 35}\n",
      "100%|███████| 10/10 [00:00<00:00, 352.58trial/s, best loss: -0.6486486486486487]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:01<00:00,  8.76trial/s, best loss: -0.6756756756756757]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.8247461272993816, 'n_estimators': 23}\n",
      "100%|███████| 10/10 [00:00<00:00, 150.04trial/s, best loss: -0.6621621621621622]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 33.83trial/s, best loss: -0.6216216216216216]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|███████| 10/10 [00:00<00:00, 129.14trial/s, best loss: -0.6013513513513513]\n",
      "Ridge:  {'alpha': 0.7261437048642986, 'max_iter': 1136, 'solver': 'sparse_cg'}\n",
      " 20%|█▊       | 2/10 [00:01<00:07,  1.07trial/s, best loss: -0.6486486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:02<00:06,  1.12trial/s, best loss: -0.6486486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:03<00:03,  1.52trial/s, best loss: -0.6486486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:03<00:03,  1.38trial/s, best loss: -0.6486486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (85) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:04<00:03,  1.29trial/s, best loss: -0.6486486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (95) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:05<00:01,  1.62trial/s, best loss: -0.6486486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:05<00:01,  1.65trial/s, best loss: -0.6486486486486487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:07<00:00,  1.42trial/s, best loss: -0.6486486486486487]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0024105512888939265, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 74}\n",
      "100%|████████| 10/10 [00:00<00:00, 67.12trial/s, best loss: -0.6891891891891893]\n",
      "SVM:  {'C': 9.170812297124504, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71be632f-f27a-4a51-bd66-f2012ed4a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 10/10 [00:00<00:00, 27.90trial/s, best loss: -0.8243243243243243]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 6, 'min_samples_split': 0.08004381930103932, 'n_estimators': 38}\n",
      "100%|███████| 10/10 [00:00<00:00, 235.36trial/s, best loss: -0.8243243243243243]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████| 10/10 [00:00<00:00, 159.64trial/s, best loss: -0.8243243243243243]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.7910485722775137, 'n_estimators': 23}\n",
      "100%|███████| 10/10 [00:00<00:00, 200.25trial/s, best loss: -0.8243243243243243]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 90.52trial/s, best loss: -0.7972972972972974]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:00<00:00, 37.58trial/s, best loss: -0.8243243243243243]\n",
      "Ridge:  {'alpha': 0.37442714557289536, 'max_iter': 13256, 'solver': 'sag'}\n",
      " 80%|████████  | 8/10 [00:04<00:00,  2.03trial/s, best loss: -0.777027027027027]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:05<00:00,  1.55trial/s, best loss: -0.777027027027027]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:05<00:00,  1.69trial/s, best loss: -0.777027027027027]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.009199529513614751, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 68}\n",
      "100%|████████| 10/10 [00:00<00:00, 93.34trial/s, best loss: -0.8243243243243243]\n",
      "SVM:  {'C': 0.2822467987203296, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b749f-cb74-4587-b622-d440fcd33a44",
   "metadata": {},
   "source": [
    "## Target: Jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba1725-e650-4c09-b66f-6b6c1b9c4037",
   "metadata": {},
   "source": [
    "### S:Lightning -> T:Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a75fc99f-4978-4980-b89b-833afda1f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1507d54d-6c7c-4c75-a6d0-e4b8317136ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 32.63trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 0.11883963792898833, 'n_estimators': 46}\n",
      "100%|████████| 10/10 [00:00<00:00, 364.72trial/s, best loss: -0.967741935483871]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 195.47trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8299475752408366, 'n_estimators': 1}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 259.75trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 32.00trial/s, best loss: -0.7556818181818181]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 9}\n",
      "100%|████████| 10/10 [00:00<00:00, 92.99trial/s, best loss: -0.8295454545454546]\n",
      "Ridge:  {'alpha': 0.21559480115526192, 'max_iter': 10802, 'solver': 'svd'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:01,  6.66trial/s, best loss: -0.9829545454545454]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███████▏                | 3/10 [00:01<00:02,  2.45trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:02,  2.73trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:01<00:01,  3.07trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (87) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:02<00:01,  2.89trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (79) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  2.68trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  2.79trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.0056743397490398055, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 96}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 22.01trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.738950555314686, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1481c024-4833-495e-a74b-ae5450bda5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 23.51trial/s, best loss: -0.5334445902145393]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 0.22664059858290397, 'n_estimators': 8}\n",
      "100%|███████| 10/10 [00:00<00:00, 353.82trial/s, best loss: -0.5617379225189072]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 14.52trial/s, best loss: -0.5991472449452075]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6630101847962837, 'n_estimators': 42}\n",
      "100%|████████| 10/10 [00:00<00:00, 180.17trial/s, best loss: -0.606382157740392]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 29.41trial/s, best loss: -0.48316676956320415]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:01<00:00,  5.82trial/s, best loss: -0.6105398209600248]\n",
      "Ridge:  {'alpha': 0.5456883126306239, 'max_iter': 6534, 'solver': 'sag'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|▉        | 1/10 [00:00<00:04,  2.20trial/s, best loss: -0.5332516592066676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:02,  2.98trial/s, best loss: -0.6237652415496219]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  3.75trial/s, best loss: -0.6373958172557493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:01<00:01,  3.41trial/s, best loss: -0.6373958172557493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:00,  3.51trial/s, best loss: -0.6373958172557493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  3.17trial/s, best loss: -0.6373958172557493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:03<00:00,  2.15trial/s, best loss: -0.6373958172557493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  2.76trial/s, best loss: -0.6373958172557493]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.0023290319998282615, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 78}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [50:54<00:00, 305.45s/trial, best loss: -0.5428499768482791]\n",
      "SVM:  {'C': 0.4625041148052726, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61b7aa9b-112a-4d16-9626-4a4c1f61e62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 35.09trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 0.41581487459800626, 'n_estimators': 14}\n",
      "100%|███████| 10/10 [00:00<00:00, 414.91trial/s, best loss: -0.9653225806451613]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 247.71trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.6406575127329324, 'n_estimators': 13}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 298.74trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 8, 'max_features': None, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 95.10trial/s, best loss: -0.7765957446808511]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 9}\n",
      "100%|███████| 10/10 [00:00<00:00, 224.53trial/s, best loss: -0.7446808510638298]\n",
      "Ridge:  {'alpha': 0.27404687627707874, 'max_iter': 8732, 'solver': 'sag'}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 14.26trial/s, best loss: -0.7446808510638298]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:00<00:00,  9.71trial/s, best loss: -0.7659574468085106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00, 11.65trial/s, best loss: -0.7659574468085106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:00<00:00,  9.58trial/s, best loss: -0.7659574468085106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  8.63trial/s, best loss: -0.7659574468085106]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0042406858538636535, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 63}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 145.76trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.847913050741563, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adafc7cd-5585-4ac0-8f19-d871f386322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 23.50trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 0.3763469553047254, 'n_estimators': 19}\n",
      "100%|███████| 10/10 [00:00<00:00, 367.44trial/s, best loss: -0.8799969131038741]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 174.19trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9198585307305244, 'n_estimators': 32}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 243.44trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|███████| 10/10 [00:00<00:00, 31.76trial/s, best loss: -0.48996758759067754]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 9}\n",
      " 50%|████▌    | 5/10 [00:03<00:03,  1.55trial/s, best loss: -0.6624672017286618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:10<00:00,  1.05s/trial, best loss: -0.6624672017286618]\n",
      "Ridge:  {'alpha': 0.7872027665240117, 'max_iter': 9149, 'solver': 'sag'}\n",
      " 20%|█▊       | 2/10 [00:00<00:01,  4.75trial/s, best loss: -0.7282952616144467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:01,  4.42trial/s, best loss: -0.7282952616144467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  3.95trial/s, best loss: -0.7282952616144467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (54) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:02<00:01,  2.78trial/s, best loss: -0.7955703040592684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:03<00:00,  3.20trial/s, best loss: -0.7955703040592684]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0039248408176727305, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 78}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (74) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 10/10 [26:25<00:00, 158.55s/trial, best loss: -0.8319956783454235]\n",
      "SVM:  {'C': 0.35098102042246415, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3e2b5ff-2b2d-4a2a-8ef0-b3dc5bc9d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 33.79trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.1861587649174652, 'n_estimators': 9}\n",
      "100%|███████| 10/10 [00:00<00:00, 380.51trial/s, best loss: -0.8752122241086587]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 225.13trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.09273689051649235, 'n_estimators': 32}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 273.30trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 36.23trial/s, best loss: -0.6219516900756289]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 10}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 11.43trial/s, best loss: -0.6653418737459484]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  5.21trial/s, best loss: -0.6734063898749807]\n",
      "Ridge:  {'alpha': 0.5600321627038474, 'max_iter': 12562, 'solver': 'saga'}\n",
      " 10%|▉        | 1/10 [00:00<00:00,  9.66trial/s, best loss: -0.4988906467047384]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:00<00:00, 12.21trial/s, best loss: -0.7034939805525543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00,  6.95trial/s, best loss: -0.7034939805525543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (90) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  8.60trial/s, best loss: -0.7034939805525543]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.00421555558696089, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 40}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [03:00<00:00, 18.09s/trial, best loss: -0.9431818181818181]\n",
      "SVM:  {'C': 0.11462182917480836, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7af1fa82-1a9a-4baf-ae84-dcb1f4fc07ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 26.21trial/s, best loss: -0.8923734372588362]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 0.5231486300628357, 'n_estimators': 37}\n",
      "100%|███████| 10/10 [00:00<00:00, 384.07trial/s, best loss: -0.8766013273653341]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 11.17trial/s, best loss: -0.8782123012810621]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.49078948177934084, 'n_estimators': 24}\n",
      "100%|███████| 10/10 [00:00<00:00, 243.58trial/s, best loss: -0.8449992282759686]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "100%|█████████| 10/10 [00:00<00:00, 31.39trial/s, best loss: -0.792898209600247]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 12}\n",
      "100%|███████| 10/10 [00:00<00:00, 210.71trial/s, best loss: -0.8698101558882544]\n",
      "Ridge:  {'alpha': 0.31931371267985875, 'max_iter': 5324, 'solver': 'saga'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  5.86trial/s, best loss: -0.9310078715851211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:01,  4.32trial/s, best loss: -0.9310078715851211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:02,  3.40trial/s, best loss: -0.9310078715851211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:01<00:01,  3.55trial/s, best loss: -0.9310078715851211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:01<00:01,  2.79trial/s, best loss: -0.9310078715851211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:01<00:00,  3.96trial/s, best loss: -0.9327056644543911]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:02<00:00,  3.67trial/s, best loss: -0.9327056644543911]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:03<00:00,  2.37trial/s, best loss: -0.9327056644543911]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (78) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [00:03<00:00,  2.74trial/s, best loss: -0.941194628800741]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.006174721770611445, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 93}\n",
      " 20%|█▊       | 2/10 [00:00<00:00, 19.33trial/s, best loss: -0.9010360395122704]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 27.34trial/s, best loss: -0.9301589751504862]\n",
      "SVM:  {'C': 0.24665430090913532, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b26bf0bc-31f5-4625-9605-26516dfb370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 22.80trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.03306522641353815, 'n_estimators': 41}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 250.41trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 172.94trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.025280845614934128, 'n_estimators': 28}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 207.32trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 24.68trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 51.39trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.908885503510659, 'max_iter': 10955, 'solver': 'cholesky'}\n",
      " 20%|████▊                   | 2/10 [00:00<00:01,  4.75trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (26) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:01,  3.57trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:01<00:01,  2.98trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:02<00:00,  3.26trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  3.15trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.0066153172041213655, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 26}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 118.97trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.4813722669589513, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dce2e3-25e8-46ce-9f90-5355ac703d56",
   "metadata": {},
   "source": [
    "### S:Ray -> T:Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98c3f2f2-8720-4133-8df0-9917aed946f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da33f762-f4aa-4e76-80c2-452292194013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 21.33trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 0.21344017506641488, 'n_estimators': 35}\n",
      "100%|███████| 10/10 [00:00<00:00, 337.99trial/s, best loss: -0.9651952461799661]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 147.61trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.2469846641499082, 'n_estimators': 22}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 220.78trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 26.02trial/s, best loss: -0.9034090909090908]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:02<00:00,  3.53trial/s, best loss: -0.8579545454545454]\n",
      "Ridge:  {'alpha': 0.15698497760330732, 'max_iter': 3980, 'solver': 'saga'}\n",
      " 10%|▉        | 1/10 [00:00<00:07,  1.19trial/s, best loss: -0.9886363636363636]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:01<00:07,  1.14trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (57) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:03<00:04,  1.39trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:03<00:03,  1.49trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:04<00:02,  1.59trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:06<00:00,  1.32trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:07<00:00,  1.26trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.00523074030611946, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 57}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 16.13trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.5168376711451144, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59ec97b1-8daa-4275-b369-fb9a39e735e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 15.42trial/s, best loss: -0.5190712301281063]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.04356008344876483, 'n_estimators': 27}\n",
      "100%|███████| 10/10 [00:00<00:00, 279.86trial/s, best loss: -0.5863559191233215]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:02<00:00,  4.68trial/s, best loss: -0.5737382312085199]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.640805353436923, 'n_estimators': 15}\n",
      "100%|████████| 10/10 [00:00<00:00, 74.07trial/s, best loss: -0.5897418583114679]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 24.69trial/s, best loss: -0.5645354221330452]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      " 20%|█▊       | 2/10 [00:01<00:07,  1.06trial/s, best loss: -0.5773942738076863]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:14<00:00,  1.46s/trial, best loss: -0.5773942738076863]\n",
      "Ridge:  {'alpha': 0.8721884966464274, 'max_iter': 10617, 'solver': 'lsqr'}\n",
      " 10%|▉        | 1/10 [00:00<00:05,  1.80trial/s, best loss: -0.5136498688069147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:05<00:13,  1.98s/trial, best loss: -0.5299139527704892]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (55) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:12<00:05,  1.92s/trial, best loss: -0.6420647476462417]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (53) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:13<00:03,  1.59s/trial, best loss: -0.6420647476462417]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:15<00:00,  1.51s/trial, best loss: -0.6420647476462417]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.007222135192016054, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 74}\n",
      "100%|████| 10/10 [3:27:19<00:00, 1243.99s/trial, best loss: -0.5787737305139682]\n",
      "SVM:  {'C': 10.372733187960261, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6c2746d-f239-416e-a40c-71e4bd70a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 41.35trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 0.2964126068351466, 'n_estimators': 17}\n",
      "100%|████████| 10/10 [00:00<00:00, 379.36trial/s, best loss: -0.967741935483871]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 227.11trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.7247507730769208, 'n_estimators': 43}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 257.95trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 7, 'max_features': None, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|█████████| 10/10 [00:00<00:00, 68.21trial/s, best loss: -0.851063829787234]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 13}\n",
      "100%|███████| 10/10 [00:00<00:00, 201.80trial/s, best loss: -0.7553191489361701]\n",
      "Ridge:  {'alpha': 0.4643807993511052, 'max_iter': 9927, 'solver': 'sparse_cg'}\n",
      " 10%|█         | 1/10 [00:00<00:02,  4.05trial/s, best loss: -0.851063829787234]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (67) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:00<00:02,  3.26trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▌              | 4/10 [00:01<00:01,  3.82trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:01<00:01,  4.12trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:01<00:01,  3.44trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  4.13trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:02<00:00,  3.87trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.0004278045362554682, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 46}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (94) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 117.71trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.625009184848561, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40a40e0f-e2fc-4062-a533-e2e1f07d2798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 15.39trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 0.3070034138219079, 'n_estimators': 33}\n",
      "100%|███████| 10/10 [00:00<00:00, 305.93trial/s, best loss: -0.8506135206050316]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 107.19trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.04397442296891781, 'n_estimators': 33}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 216.29trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 28.33trial/s, best loss: -0.5597796727890106]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:08<00:00,  1.18trial/s, best loss: -0.6756829757678654]\n",
      "Ridge:  {'alpha': 0.9193861336233005, 'max_iter': 8060, 'solver': 'svd'}\n",
      " 10%|▉        | 1/10 [00:00<00:08,  1.01trial/s, best loss: -0.7294721407624631]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:02<00:06,  1.11trial/s, best loss: -0.8562953387868497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:03<00:05,  1.15trial/s, best loss: -0.8562953387868497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:05<00:05,  1.10s/trial, best loss: -0.8623726655348047]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:08<00:00,  1.23trial/s, best loss: -0.8623726655348047]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.00892917406390933, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 93}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [29:07<00:00, 174.71s/trial, best loss: -0.915949606420744]\n",
      "SVM:  {'C': 2.0271158112558267, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc88373e-117f-45e5-86ae-068afaa4db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 39.19trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 0.05272904179947502, 'n_estimators': 16}\n",
      "100%|███████| 10/10 [00:00<00:00, 387.93trial/s, best loss: -0.8578098471986417]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 230.44trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.5763442894843321, 'n_estimators': 33}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 285.48trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 34.27trial/s, best loss: -0.5035692236456244]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|████████| 10/10 [00:01<00:00,  7.58trial/s, best loss: -0.6514508411791943]\n",
      "Ridge:  {'alpha': 0.2161848022529982, 'max_iter': 1362, 'solver': 'cholesky'}\n",
      " 40%|███▌     | 4/10 [00:00<00:00,  7.26trial/s, best loss: -0.6195593455780214]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00,  9.38trial/s, best loss: -0.6309905077944128]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (17) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  9.89trial/s, best loss: -0.6309905077944128]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0046700565779890565, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 28}\n",
      "100%|████████| 10/10 [04:10<00:00, 25.03s/trial, best loss: -0.8782701805834233]\n",
      "SVM:  {'C': 2.849678685964366, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23f7e55-496f-4c48-b1a1-3131c3329c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:01<00:00,  9.57trial/s, best loss: -0.8871546534959098]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.021323735594438897, 'n_estimators': 10}\n",
      "100%|███████| 10/10 [00:00<00:00, 312.63trial/s, best loss: -0.8420859700571076]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:01<00:00,  6.18trial/s, best loss: -0.9440693008180274]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.9200056919417959, 'n_estimators': 45}\n",
      "100%|████████| 10/10 [00:00<00:00, 87.34trial/s, best loss: -0.9060329526161445]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': None, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 24.97trial/s, best loss: -0.9804078561506404]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 14}\n",
      "100%|████████| 10/10 [00:00<00:00, 66.41trial/s, best loss: -0.9545454545454546]\n",
      "Ridge:  {'alpha': 0.27033327673303476, 'max_iter': 2841, 'solver': 'sparse_cg'}\n",
      " 10%|▉        | 1/10 [00:01<00:17,  1.94s/trial, best loss: -0.9987266553480476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:05<00:11,  1.64s/trial, best loss: -0.9987266553480476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (56) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:11<00:07,  1.82s/trial, best loss: -0.9987266553480476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:13<00:05,  1.85s/trial, best loss: -0.9987266553480476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:14<00:03,  1.57s/trial, best loss: -0.9987266553480476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:15<00:01,  1.66s/trial, best loss: -0.9987266553480476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:18<00:00,  1.83s/trial, best loss: -0.9987266553480476]\n",
      "MLP:  {'activation': 'logistic', 'alpha': 0.005421390174416767, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 77}\n",
      "100%|█████████| 10/10 [00:00<00:00, 18.92trial/s, best loss: -0.993469285383547]\n",
      "SVM:  {'C': 0.22290078200559532, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8df8e236-e0ec-4cbb-99c4-aefdd950b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 27.76trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.24169079412775873, 'n_estimators': 15}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 199.60trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 135.22trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.7918338550062306, 'n_estimators': 40}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 175.44trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 14.84trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 10}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 17.55trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.42698790965849165, 'max_iter': 6199, 'solver': 'sag'}\n",
      " 10%|██▍                     | 1/10 [00:00<00:07,  1.15trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▊                   | 2/10 [00:01<00:06,  1.25trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:05<00:01,  1.63trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:07<00:00,  1.28trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.004710241591952054, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 19}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 68.82trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.14887056019952064, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3ce0f-a6cf-401c-9ff4-df1ffffca72c",
   "metadata": {},
   "source": [
    "### S:Transformers -> T:Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "973a9698-2163-40d5-8de1-500c8cafa8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9688d27a-e921-44d2-98e4-b67d942f3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 25.34trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 0.16143313074952936, 'n_estimators': 38}\n",
      "100%|███████| 10/10 [00:00<00:00, 354.17trial/s, best loss: -0.9702886247877759]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 161.04trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.6186245510752796, 'n_estimators': 2}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 254.78trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 28.58trial/s, best loss: -0.7045454545454546]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 7}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 13.98trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.629694091553613, 'max_iter': 9665, 'solver': 'sag'}\n",
      " 10%|▉        | 1/10 [00:00<00:03,  2.85trial/s, best loss: -0.8068181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (44) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:00<00:02,  3.75trial/s, best loss: -0.8068181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:01<00:03,  2.17trial/s, best loss: -0.9943181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:02<00:03,  1.57trial/s, best loss: -0.9943181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:02<00:02,  1.97trial/s, best loss: -0.9943181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:03<00:02,  1.76trial/s, best loss: -0.9943181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:03<00:00,  2.57trial/s, best loss: -0.9943181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (52) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:03<00:00,  3.30trial/s, best loss: -0.9943181818181819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:04<00:00,  2.18trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.006659733637931966, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 94}\n",
      " 40%|█████████▌              | 4/10 [00:00<00:00, 35.32trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (94) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 32.98trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.4016875537261773, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88671a48-e46c-4d87-83d4-b938a96ab1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 22.60trial/s, best loss: -0.8465909090909092]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.16129955688974418, 'n_estimators': 44}\n",
      "100%|███████| 10/10 [00:00<00:00, 336.18trial/s, best loss: -0.6499556258681896]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 140.42trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME.R', 'learning_rate': 0.17474996554085093, 'n_estimators': 20}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 256.64trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': 'log2', 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 27.81trial/s, best loss: -0.5054213613211915]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "100%|██████████████████████| 10/10 [00:06<00:00,  1.61trial/s, best loss: -0.75]\n",
      "Ridge:  {'alpha': 0.6576238833969889, 'max_iter': 4107, 'solver': 'svd'}\n",
      " 20%|█▊       | 2/10 [00:00<00:02,  3.67trial/s, best loss: -0.5222063590060194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:02<00:02,  2.46trial/s, best loss: -0.570960024695169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:02<00:01,  2.88trial/s, best loss: -0.570960024695169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (21) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:03<00:02,  1.41trial/s, best loss: -0.570960024695169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:05<00:00,  1.83trial/s, best loss: -0.6619462880074085]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.004333147294213654, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 56}\n",
      "100%|███████| 10/10 [41:29<00:00, 248.94s/trial, best loss: -0.6636633739774656]\n",
      "SVM:  {'C': 2.07385713938116, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15d0445e-5acb-4e33-b424-d7326ed99ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 35.47trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.3486089498855218, 'n_estimators': 4}\n",
      "100%|███████| 10/10 [00:00<00:00, 404.01trial/s, best loss: -0.9766129032258065]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 237.13trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.1849987928143459, 'n_estimators': 31}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 283.73trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 71.01trial/s, best loss: -0.8297872340425532]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 209.73trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.22212861556355368, 'max_iter': 3803, 'solver': 'cholesky'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  6.47trial/s, best loss: -0.7978723404255319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (31) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:01,  4.33trial/s, best loss: -0.851063829787234]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:01,  4.06trial/s, best loss: -0.8829787234042553]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:01<00:01,  4.24trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (86) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████████████▍         | 6/10 [00:01<00:01,  3.19trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:01<00:00,  3.35trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████▏    | 8/10 [00:02<00:00,  2.38trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:02<00:00,  2.70trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (76) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:03<00:00,  3.15trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.005354447666448392, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 86}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 128.04trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 2.7536107693348333, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21967906-95b6-428b-99e2-200e5ca34698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 14.83trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.173089266297195, 'n_estimators': 29}\n",
      "100%|███████| 10/10 [00:00<00:00, 301.03trial/s, best loss: -0.6272283531409168]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 90.99trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.9387246936571053, 'n_estimators': 44}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 201.18trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': None, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 29.21trial/s, best loss: -0.6178615527087514]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      " 10%|▉        | 1/10 [00:01<00:10,  1.22s/trial, best loss: -0.5817738076863714]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:10<00:00,  1.01s/trial, best loss: -0.7798464269177343]\n",
      "Ridge:  {'alpha': 0.9996177473032422, 'max_iter': 2479, 'solver': 'svd'}\n",
      " 10%|▉        | 1/10 [00:00<00:01,  5.35trial/s, best loss: -0.5444513042136132]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▊       | 2/10 [00:01<00:09,  1.14s/trial, best loss: -0.6420551010958482]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▌     | 4/10 [00:04<00:07,  1.20s/trial, best loss: -0.7344979935175182]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▍   | 6/10 [00:05<00:03,  1.08trial/s, best loss: -0.7344979935175182]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▏ | 8/10 [00:07<00:01,  1.22trial/s, best loss: -0.7344979935175182]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (29) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:08<00:00,  1.19trial/s, best loss: -0.7344979935175182]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.004200581542146908, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 91}\n",
      "100%|███████| 10/10 [56:01<00:00, 336.17s/trial, best loss: -0.7427554406544219]\n",
      "SVM:  {'C': 0.5410932984797815, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d858bd7-b497-43b2-8e8a-d08206458ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 43.39trial/s, best loss: -0.9592529711375213]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.36901268532768605, 'n_estimators': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 385.16trial/s, best loss: -0.8841256366723259]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 222.38trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.2551641297230794, 'n_estimators': 27}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 280.60trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 36.33trial/s, best loss: -0.6139064670473839]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "100%|████████| 10/10 [00:00<00:00, 11.22trial/s, best loss: -0.9352812934094767]\n",
      "Ridge:  {'alpha': 0.25674508215536, 'max_iter': 9320, 'solver': 'svd'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▋      | 3/10 [00:00<00:00,  7.06trial/s, best loss: -0.5071191541904615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▎  | 7/10 [00:00<00:00, 10.85trial/s, best loss: -0.6026103565365025]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:01<00:00,  8.72trial/s, best loss: -0.6026103565365025]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (84) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:01<00:00,  8.09trial/s, best loss: -0.6026103565365025]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.007049957922605321, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 34}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (92) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 10/10 [03:19<00:00, 19.95s/trial, best loss: -0.870070612748881]\n",
      "SVM:  {'C': 0.11305225669413291, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ada6c83-1309-4ba5-b0b1-90b77c2ed1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 12.68trial/s, best loss: -0.8011363636363636]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 0.17602365042058843, 'n_estimators': 46}\n",
      "100%|███████| 10/10 [00:00<00:00, 357.24trial/s, best loss: -0.7312567525852754]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████████████████| 10/10 [00:00<00:00, 10.07trial/s, best loss: -0.8125]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.6399855982509144, 'n_estimators': 27}\n",
      "100%|███████| 10/10 [00:00<00:00, 185.23trial/s, best loss: -0.8339539280753202]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 30.35trial/s, best loss: -0.7272727272727273]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      "100%|████████| 10/10 [00:00<00:00, 84.20trial/s, best loss: -0.7954545454545454]\n",
      "Ridge:  {'alpha': 0.36766497501748097, 'max_iter': 3408, 'solver': 'cholesky'}\n",
      " 10%|██▎                    | 1/10 [00:00<00:07,  1.13trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|████▌                  | 2/10 [00:01<00:06,  1.24trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (73) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██████▉                | 3/10 [00:01<00:03,  1.81trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|█████████▏             | 4/10 [00:02<00:03,  1.82trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (36) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|███████████▌           | 5/10 [00:02<00:02,  1.99trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████████████▊         | 6/10 [00:03<00:02,  1.53trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████       | 7/10 [00:04<00:01,  1.92trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (24) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████▍    | 8/10 [00:04<00:00,  2.21trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████▋  | 9/10 [00:05<00:00,  1.48trial/s, best loss: -0.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:05<00:00,  1.67trial/s, best loss: -0.75]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.004660999033381398, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 80}\n",
      "100%|████████| 10/10 [00:00<00:00, 63.55trial/s, best loss: -0.9829545454545454]\n",
      "SVM:  {'C': 2.723829659054652, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (46) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4de5594-4583-459b-b2fb-6ce00b440b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 26.78trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.2818815060225537, 'n_estimators': 40}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 227.42trial/s, best loss: -1.0]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 147.68trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8745980057168294, 'n_estimators': 40}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 196.24trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 8, 'splitter': 'best'}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 18.17trial/s, best loss: -1.0]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 16}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 54.30trial/s, best loss: -1.0]\n",
      "Ridge:  {'alpha': 0.31603162145949326, 'max_iter': 6206, 'solver': 'cholesky'}\n",
      " 30%|███████▏                | 3/10 [00:01<00:03,  1.83trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████████████            | 5/10 [00:03<00:03,  1.28trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 7/10 [00:04<00:01,  1.79trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████▌  | 9/10 [00:05<00:00,  2.08trial/s, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:05<00:00,  1.76trial/s, best loss: -1.0]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.008521218105800563, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 94}\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 69.72trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.22574411880674047, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed0682-826e-4e9e-b8e5-90b4ebd2bce1",
   "metadata": {},
   "source": [
    "### S:Yolov5 -> T:Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c88dc6d9-dc86-4291-a4fc-23271aa1e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea5aa3c3-f25a-4a4d-a6ef-a40e8e52b8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 29.37trial/s, best loss: -0.9176570458404074]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.012986557272759436, 'n_estimators': 33}\n",
      "100%|███████| 10/10 [00:00<00:00, 410.44trial/s, best loss: -0.8790322580645161]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 250.91trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.8021434105174583, 'n_estimators': 39}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 294.27trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': None, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 39.65trial/s, best loss: -0.6254244482173175]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 8}\n",
      "100%|█████████| 10/10 [00:00<00:00, 53.41trial/s, best loss: -0.708664531563513]\n",
      "Ridge:  {'alpha': 0.934607530642571, 'max_iter': 4401, 'solver': 'saga'}\n",
      " 60%|█████▍   | 6/10 [00:00<00:00, 25.07trial/s, best loss: -0.7515338015125792]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (77) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 31.15trial/s, best loss: -0.7515338015125792]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.009390789706680856, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 77}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 122.22trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.7024169870608294, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Bruakfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed61ffc2-0ea8-4641-86f4-feecb9dd7d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 41.94trial/s, best loss: -0.6126524154962186]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 0.49604059540472045, 'n_estimators': 10}\n",
      "100%|███████| 10/10 [00:00<00:00, 409.84trial/s, best loss: -0.6062760456860627]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|█████████| 10/10 [00:00<00:00, 27.54trial/s, best loss: -0.620388948911869]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.5800932587686565, 'n_estimators': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 282.40trial/s, best loss: -0.6217587590677575]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 1, 'max_features': None, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 40.03trial/s, best loss: -0.5905232288933477]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      " 40%|███▌     | 4/10 [00:00<00:00, 10.59trial/s, best loss: -0.6136363636363636]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 13.07trial/s, best loss: -0.6136363636363636]\n",
      "Ridge:  {'alpha': 0.3416580380495726, 'max_iter': 5435, 'solver': 'cholesky'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 23.48trial/s, best loss: -0.5775968513659516]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (22) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (72) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (68) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████ | 9/10 [00:00<00:00, 18.93trial/s, best loss: -0.6151991048001235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (69) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 17.94trial/s, best loss: -0.6151991048001235]\n",
      "MLP:  {'activation': 'relu', 'alpha': 0.009397201826314039, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 88}\n",
      "100%|████████| 10/10 [16:33<00:00, 99.38s/trial, best loss: -0.6438107732674796]\n",
      "SVM:  {'C': 0.43605001803453863, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Data Selection\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38677c28-b45f-4f36-8393-df08e51810b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 32.71trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.520584151595054, 'n_estimators': 5}\n",
      "100%|███████| 10/10 [00:00<00:00, 426.17trial/s, best loss: -0.8741935483870968]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 262.03trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.23748376032395363, 'n_estimators': 1}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 305.33trial/s, best loss: -0.8]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "100%|████████| 10/10 [00:00<00:00, 121.83trial/s, best loss: -0.604066575154427]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 8}\n",
      "100%|████████| 10/10 [00:00<00:00, 208.67trial/s, best loss: -0.775531914893617]\n",
      "Ridge:  {'alpha': 0.404338797234261, 'max_iter': 8594, 'solver': 'sparse_cg'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 17.16trial/s, best loss: -0.5995367192862046]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (41) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (39) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (45) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 22.89trial/s, best loss: -0.9104838709677419]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.008807416157068731, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 85}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (85) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (19) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (34) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (82) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (63) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 173.51trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 0.4512532572546901, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DSBF\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dsbf = DSBF()\n",
    "X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e41dd8d1-3f8c-4f7f-b1b2-cdc79bc5d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 29.60trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 0.5676171484789554, 'n_estimators': 11}\n",
      "100%|███████| 10/10 [00:00<00:00, 411.51trial/s, best loss: -0.6176396820496991]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 238.76trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.4477906281272683, 'n_estimators': 19}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 292.23trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 39.16trial/s, best loss: -0.6285788701960179]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 14}\n",
      "100%|████████| 10/10 [00:00<00:00, 18.04trial/s, best loss: -0.6481710140453775]\n",
      "Ridge:  {'alpha': 0.9550962785578007, 'max_iter': 2259, 'solver': 'sparse_cg'}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (33) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▌    | 5/10 [00:00<00:00, 20.50trial/s, best loss: -0.6431451612903226]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 16.64trial/s, best loss: -0.6431451612903226]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.00036438784401110756, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 64}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (96) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (88) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [08:19<00:00, 49.91s/trial, best loss: -0.7960622781293409]\n",
      "SVM:  {'C': 0.08170231896654463, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: DTB\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "dtb = DTB()\n",
    "X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "317c9940-287d-4e99-9256-8f60f0866fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:00<00:00, 36.37trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 6, 'min_samples_split': 0.5664486252958774, 'n_estimators': 12}\n",
      "100%|███████| 10/10 [00:00<00:00, 379.57trial/s, best loss: -0.6246237845346505]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 236.85trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.42811869154654975, 'n_estimators': 42}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 284.87trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': None, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 39.45trial/s, best loss: -0.5909476771106652]\n",
      "KNN:  {'algorithm': 'kd_tree', 'n_neighbors': 6}\n",
      "100%|█████████| 10/10 [00:00<00:00, 14.57trial/s, best loss: -0.567844188918043]\n",
      "Ridge:  {'alpha': 0.28252662874702106, 'max_iter': 13137, 'solver': 'svd'}\n",
      " 50%|████▌    | 5/10 [00:00<00:00, 24.34trial/s, best loss: -0.5871276431548078]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (97) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (23) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (93) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 26.83trial/s, best loss: -0.5892498842413953]\n",
      "MLP:  {'activation': 'tanh', 'alpha': 0.0013900596134676347, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 58}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (58) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [06:08<00:00, 36.87s/trial, best loss: -0.7948853989813243]\n",
      "SVM:  {'C': 0.5258165269401519, 'degree': 3, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Peterfilter\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "daaea8e7-9341-4986-ac3e-b6b6223e41eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 10/10 [00:00<00:00, 30.49trial/s, best loss: -0.5046689303904923]\n",
      "Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.26985154487799556, 'n_estimators': 3}\n",
      "100%|███████| 10/10 [00:00<00:00, 418.23trial/s, best loss: -0.7287775891341257]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|████████| 10/10 [00:00<00:00, 25.92trial/s, best loss: -0.5008488964346349]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.19572487200809052, 'n_estimators': 23}\n",
      "100%|███████| 10/10 [00:00<00:00, 294.52trial/s, best loss: -0.6120157431702424]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_split': 9, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 39.89trial/s, best loss: -0.6617051242475691]\n",
      "KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "100%|████████| 10/10 [00:00<00:00, 267.28trial/s, best loss: -0.640222256521068]\n",
      "Ridge:  {'alpha': 0.12719372035763504, 'max_iter': 1393, 'solver': 'saga'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 24.89trial/s, best loss: -0.7041595925297114]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (59) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (49) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 23.69trial/s, best loss: -0.7092529711375213]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.006521726408834202, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 30}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (51) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (47) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 136.22trial/s, best loss: -0.700339558573854]\n",
      "SVM:  {'C': 3.254792505813339, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: TCA\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "tca = TCA()\n",
    "X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "788447a2-6a8d-44dc-a96b-eb1875d70ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 30.59trial/s, best loss: -1.0]\n",
      "Random Forest:  {'criterion': 'entropy', 'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 0.3638853943845124, 'n_estimators': 6}\n",
      "100%|███████| 10/10 [00:00<00:00, 270.62trial/s, best loss: -0.8238539898132428]\n",
      "Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 196.82trial/s, best loss: -1.0]\n",
      "AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.46021287795596433, 'n_estimators': 43}\n",
      "100%|██████████████████████| 10/10 [00:00<00:00, 220.58trial/s, best loss: -1.0]\n",
      "CART:  {'criterion': 'log_loss', 'max_depth': 9, 'max_features': 'log2', 'min_samples_split': 5, 'splitter': 'best'}\n",
      "100%|████████| 10/10 [00:00<00:00, 37.41trial/s, best loss: -0.7414338632505016]\n",
      "KNN:  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "100%|████████| 10/10 [00:00<00:00, 37.89trial/s, best loss: -0.9078947368421052]\n",
      "Ridge:  {'alpha': 0.9953270428681119, 'max_iter': 14506, 'solver': 'saga'}\n",
      " 30%|██▋      | 3/10 [00:00<00:00, 19.65trial/s, best loss: -0.9061969439728353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (27) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (66) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (28) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (61) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 10/10 [00:00<00:00, 24.31trial/s, best loss: -0.9061969439728353]\n",
      "MLP:  {'activation': 'identity', 'alpha': 0.0027688804516557805, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 64}\n",
      "  0%|                                    | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (13) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (94) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (11) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 113.36trial/s, best loss: -1.0]\n",
      "SVM:  {'C': 1.7456064678686147, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Domain Adaptation: Universal\n",
    "X_source, Y_source, X_target, Y_target = data_loading()\n",
    "universal = Universal()\n",
    "X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "hyperopt_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c5f06-9840-46d8-8794-e353e31e7e07",
   "metadata": {},
   "source": [
    "# Voilin Plots RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dafd3b6-e7ac-4ccf-9c6c-05d09bf37449",
   "metadata": {},
   "source": [
    "## TargetProject: Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabbfde-5ebe-4e21-8751-282bdcbc26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_classifier():\n",
    "    #implement Hyperopt on Random Forest\n",
    "    best_params_rf = fmin(\n",
    "        fn=objective_rf,\n",
    "        space=rf_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"Random Forest: \", space_eval(rf_space, best_params_rf))\n",
    "    \n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    \n",
    "    #implement Hyperopt on AdaBoost\n",
    "    best_params_ada = fmin(\n",
    "        fn=objective_ada,\n",
    "        space=ada_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"AdaBoost: \", space_eval(ada_space, best_params_ada))\n",
    "    \n",
    "    #implement Hyperopt on CART\n",
    "    best_params_cart = fmin(\n",
    "        fn=objective_cart,\n",
    "        space=cart_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"CART: \", space_eval(cart_space, best_params_cart))\n",
    "    \n",
    "    #implement Hyperopt on KNN\n",
    "    best_params_knn = fmin(\n",
    "        fn=objective_knn,\n",
    "        space=knn_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"KNN: \", space_eval(knn_space, best_params_knn))\n",
    "    \n",
    "    #implement Hyperopt on Ridge\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    \n",
    "    #implement Hyperopt on MLP\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    \n",
    "    #implement Hyperopt on SVM\n",
    "    best_params_svm = fmin(\n",
    "        fn=objective_svm,\n",
    "        space=svm_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=10)\n",
    "    \n",
    "    print(\"SVM: \", space_eval(svm_space, best_params_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9c6568ce-c103-4972-8459-7f04beac06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "def data_loading_lj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data1 = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, jax_test_data1\n",
    "\n",
    "def data_loading_rj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data1 = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, jax_test_data1\n",
    "\n",
    "def data_loading_tj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data1 = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, jax_test_data1\n",
    "\n",
    "def data_loading_yj():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_test_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data1 = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = jax_test_data.drop(columns='Buggy')\n",
    "    Y_target = jax_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, jax_test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d91851be-0b18-4041-b254-60dd3794f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 selected CPDP techniques\n",
    "# Peterfilter-SVM\n",
    "# TCA-MLP\n",
    "# TCA-SVM\n",
    "# Peterfilter-Ridge\n",
    "# DTB-Naive Bayes\n",
    "# BruakFilter-Random Forest\n",
    "# Peterfilter-Naive Bayes\n",
    "# DSBF-MLP\n",
    "# DTB-MLP\n",
    "# TCA-Naive Bayes\n",
    "def jax_violin_plot():\n",
    "    # Peterfilter-SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lj()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "    print(\"Peterfilter-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    peterfilter_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "    #TCA-MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lj()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"TCA-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    tca_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "\n",
    "    # TCA-SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lj()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "    print(\"TCA-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    tca_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "    # Peterfilter-ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_tj()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"Peterfilter-Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    peterfilter_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "\n",
    "    # DTB-Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lj()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"DTB - Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    dtb_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "    \n",
    "    # Bruakfilter- Random Forest\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yj()\n",
    "    bruakfilter = Bruakfilter()\n",
    "    X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Random Forest\n",
    "    rf_trials = Trials()\n",
    "    best_params_rf = fmin(\n",
    "        fn=objective_rf,\n",
    "        space=rf_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=rf_trials)\n",
    "    \n",
    "    print(\"Bruakfilter - Random Forest: \", space_eval(rf_space, best_params_rf))\n",
    "    bruakfilter_rf = [format(-result['loss'], '.2f') for result in rf_trials.results]\n",
    "    \n",
    "    # Peterfilter - Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lj()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"Peterfilter - Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    peterfilter_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "    \n",
    "    # DSBF - MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yj()\n",
    "    dsbf = DSBF()\n",
    "    X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"DSBF-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    dsbf_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # DTB - MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rj()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"DTB-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    dtb_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # TCA - Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lj()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"TCA - Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    tca_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "\n",
    "    return peterfilter_svm, tca_mlp, tca_svm, peterfilter_ridge, dtb_nb, bruakfilter_rf, peterfilter_nb, dsbf_mlp, dtb_mlp, tca_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ee0b452b-e9f3-4fe2-9023-66106a95ab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 123.55trial/s, best loss: -1.0]\n",
      "Peterfilter-SVM:  {'C': 2.4163640275122855, 'degree': 2, 'kernel': 'linear'}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 50/50 [00:02<00:00, 17.73trial/s, best loss: -0.9533106960950765]\n",
      "TCA-MLP:  {'activation': 'identity', 'alpha': 0.001336532594868923, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 85}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 154.18trial/s, best loss: -1.0]\n",
      "TCA-SVM:  {'C': 4.488923242668391, 'degree': 3, 'kernel': 'linear'}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 50/50 [00:01<00:00, 29.52trial/s, best loss: -0.9066213921901528]\n",
      "Peterfilter-Ridge:  {'alpha': 0.9238466169304057, 'max_iter': 5119, 'solver': 'sparse_cg'}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████| 50/50 [00:00<00:00, 249.67trial/s, best loss: -0.8238539898132428]\n",
      "DTB - Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████████████████████| 50/50 [00:01<00:00, 33.89trial/s, best loss: -1.0]\n",
      "Bruakfilter - Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 0.3818779407829266, 'n_estimators': 12}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████| 50/50 [00:00<00:00, 259.20trial/s, best loss: -0.8238539898132428]\n",
      "Peterfilter - Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 50/50 [00:03<00:00, 16.03trial/s, best loss: -0.9949066213921902]\n",
      "DSBF-MLP:  {'activation': 'tanh', 'alpha': 0.004029691444394367, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 98}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|████████| 50/50 [00:03<00:00, 16.40trial/s, best loss: -0.9949066213921902]\n",
      "DTB-MLP:  {'activation': 'tanh', 'alpha': 0.006969787207095821, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 95}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "100%|███████| 50/50 [00:00<00:00, 212.86trial/s, best loss: -0.8238539898132428]\n",
      "TCA - Naive Bayes:  {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "peterfilter_svm, tca_mlp, tca_svm, peterfilter_ridge, dtb_nb, bruakfilter_rf, peterfilter_nb, dsbf_mlp, dtb_mlp, tca_nb = jax_violin_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bba5c2a6-b551-4c33-b667-d6879dea58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jax = pd.DataFrame({\n",
    "      'Classifier': ['Peterfilter_SVM'] * len(peterfilter_svm) +\n",
    "                    ['TCA_MLP'] * len(tca_mlp) +\n",
    "                    ['TCA_SVM'] * len(tca_svm) +\n",
    "                    ['Peterfilter_Ridge'] * len(peterfilter_ridge) +\n",
    "                    ['DTB_NB'] * len(dtb_nb) +\n",
    "                    ['Bruakfilter_RF'] * len(bruakfilter_rf) +\n",
    "                    ['Peterfilter_NB'] * len(peterfilter_nb) +\n",
    "                    ['DSBF_MLP'] * len(dsbf_mlp) +\n",
    "                    ['DTB_MLP'] * len(dtb_mlp) +\n",
    "                    ['TCA_NB'] * len(tca_nb),\n",
    "      'ROC AUC': peterfilter_svm + tca_mlp + tca_svm + peterfilter_ridge + dtb_nb + bruakfilter_rf + peterfilter_nb + dsbf_mlp + dtb_mlp + tca_nb\n",
    "  })\n",
    "\n",
    "data_jax['ROC AUC'] = pd.to_numeric(data_jax['ROC AUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a499906b-b518-471f-a339-4a860c1526c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "violin_plots(data_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be93ccdb-04de-41b1-a211-25aff029e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def violin_plots(data_jax):\n",
    "  \n",
    "  # Create subplots\n",
    "  #fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 6))\n",
    "  plt.figure(figsize= (8,4))\n",
    "  # Plot violin plots\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_jax)\n",
    "  plt.title('Jax')\n",
    "  plt.xticks(rotation=45)\n",
    "  # Tilt x-axis labels\n",
    "  #tick_params(axis='x', rotation=45)\n",
    "\n",
    "  #plt.savefig('wpdp_results.png', bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb340630-ad25-44b1-b3fd-449af4088918",
   "metadata": {},
   "source": [
    "## Target Project: Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5c9ad1ec-1113-4c7f-9e75-8380c4667f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data1 = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, lightning_test_data1\n",
    "\n",
    "def data_loading_rl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data1 = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "\n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, lightning_test_data1\n",
    "\n",
    "def data_loading_tl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "      \n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data1 = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "   \n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, lightning_test_data1\n",
    "\n",
    "def data_loading_yl():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_test_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data1 = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = lightning_test_data.drop(columns='Buggy')\n",
    "    Y_target = lightning_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, lightning_test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d931761d-e8c1-47a1-a4c6-8099f0ba7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 selected CPDP techniques\n",
    "# Peterfilter-SVM\n",
    "# TCA-MLP\n",
    "# TCA-SVM\n",
    "# Peterfilter-Ridge\n",
    "# DTB-Naive Bayes\n",
    "# BruakFilter-Random Forest\n",
    "# Peterfilter-Naive Bayes\n",
    "# DSBF-MLP\n",
    "# DTB-MLP\n",
    "# TCA-Naive Bayes\n",
    "def lightning_violin_plot():\n",
    "    # DS-SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_jl()\n",
    "    ds = DataSelection()\n",
    "    loc = [0]\n",
    "    X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "    print(\"Data Selection-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    ds_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "    #Universal-KNN\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yl()\n",
    "    universal = Universal()\n",
    "    X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    knn_trials = Trials()\n",
    "    best_params_knn = fmin(\n",
    "        fn=objective_knn,\n",
    "        space=knn_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=knn_trials)\n",
    "    \n",
    "    print(\"Universal-KNN: \", space_eval(knn_space, best_params_knn))\n",
    "    universal_knn = [format(-result['loss'], '.2f') for result in knn_trials.results]\n",
    "\n",
    "    # Bruakfilter-MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yl()\n",
    "    bruakfilter = Bruakfilter()\n",
    "    X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "      fn=objective_mlp,\n",
    "      space=mlp_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=mlp_trials)\n",
    "    print(\"Bruakfilter MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    bruakfilter_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "\n",
    "    # DTB-Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rl()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"DTB-Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    dtb_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "\n",
    "    # DSBF-MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_tl()\n",
    "    dsbf = DSBF()\n",
    "    X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"DSBF-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    dsbf_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # DTB-MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_tl()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"DTB-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    dtb_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # TCA-SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rl()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "        fn=objective_svm,\n",
    "        space=svm_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=svm_trials)\n",
    "    \n",
    "    print(\"TCA_SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    tca_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "    \n",
    "    # DS-Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_tl()\n",
    "    ds = DataSelection()\n",
    "    loc = [0]\n",
    "    X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"DS-Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    ds_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "    \n",
    "    # Peterfilter_Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_tl()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"Peterfilter_Ridge\", space_eval(ridge_space, best_params_ridge))\n",
    "    peterfilter_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "    \n",
    "    # Bruakfilter-Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rl()\n",
    "    bruakfilter = Bruakfilter()\n",
    "    X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"Bruakfilter- Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    bruakfilter_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "\n",
    "    return ds_svm, universal_knn, bruakfilter_mlp, dtb_ridge, dsbf_mlp, dtb_mlp, tca_svm, ds_ridge, peterfilter_ridge, bruakfilter_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b6ddd302-c7ff-48f1-8b2b-4aa0384feebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 151.74trial/s, best loss: -1.0]\n",
      "Data Selection-SVM:  {'C': 1.285410349807519, 'degree': 1, 'kernel': 'linear'}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 50/50 [00:01<00:00, 36.51trial/s, best loss: -0.7414338632505016]\n",
      "Universal-KNN:  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 50/50 [00:02<00:00, 18.16trial/s, best loss: -0.9851443123938879]\n",
      "Bruakfilter MLP:  {'activation': 'identity', 'alpha': 0.005719361234901967, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 93}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 50/50 [00:01<00:00, 32.49trial/s, best loss: -0.9061969439728353]\n",
      "DTB-Ridge:  {'alpha': 0.9152727538972655, 'max_iter': 1938, 'solver': 'sparse_cg'}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 50/50 [00:02<00:00, 17.26trial/s, best loss: -0.8862478777589133]\n",
      "DSBF-MLP:  {'activation': 'relu', 'alpha': 0.004521878167021115, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 95}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 50/50 [00:02<00:00, 16.92trial/s, best loss: -0.9881154499151104]\n",
      "DTB-MLP:  {'activation': 'identity', 'alpha': 0.007388722335039306, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 99}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 162.62trial/s, best loss: -1.0]\n",
      "TCA_SVM:  {'C': 0.9724102586419131, 'degree': 4, 'kernel': 'linear'}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 50/50 [00:01<00:00, 27.13trial/s, best loss: -0.9078947368421052]\n",
      "DS-Ridge:  {'alpha': 0.9997816098950189, 'max_iter': 14886, 'solver': 'saga'}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|████████| 50/50 [00:01<00:00, 25.65trial/s, best loss: -0.9066213921901528]\n",
      "Peterfilter_Ridge {'alpha': 0.9104132091784902, 'max_iter': 12291, 'solver': 'sparse_cg'}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "100%|███████| 50/50 [00:00<00:00, 249.79trial/s, best loss: -0.8238539898132428]\n",
      "Bruakfilter- Naive Bayes:  {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "ds_svm, universal_knn, bruakfilter_mlp, dtb_ridge, dsbf_mlp, dtb_mlp, tca_svm, ds_ridge, peterfilter_ridge, bruakfilter_nb = lightning_violin_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a9de6285-3705-4593-874e-2244b8fe225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lightning = pd.DataFrame({\n",
    "      'Classifier': ['DataSelection_SVM'] * len(ds_svm) +\n",
    "                    ['Universal_KNN'] * len(universal_knn) +\n",
    "                    ['Bruakfilter_MLP'] * len(bruakfilter_mlp) +\n",
    "                    ['DTB_ridge'] * len(dtb_ridge) +\n",
    "                    ['DSBF_MLP'] * len(dsbf_mlp) +\n",
    "                    ['DTB_MLP'] * len(dtb_mlp) +\n",
    "                    ['TCA_SVM'] * len(tca_svm) +\n",
    "                    ['DataSelection_Ridge'] * len(ds_ridge) +\n",
    "                    ['Peterfilter_Ridge'] * len(peterfilter_ridge) +\n",
    "                    ['Bruakfilter_NB'] * len(bruakfilter_nb),\n",
    "      'ROC AUC': ds_svm + universal_knn + bruakfilter_mlp + dtb_ridge + dsbf_mlp + dtb_mlp + tca_svm + ds_ridge + peterfilter_ridge + bruakfilter_nb\n",
    "  })\n",
    "\n",
    "data_lightning['ROC AUC'] = pd.to_numeric(data_lightning['ROC AUC'])\n",
    "#violin_plots(data_jax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d3815-773e-4855-8623-622909db7fee",
   "metadata": {},
   "source": [
    "## Target Project: Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56673a6e-bc20-45a7-8f73-99744d10ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_tr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv(../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_jr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_lr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_yr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "24b790a5-b32f-4750-a910-21204411eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ray_violin_plot():\n",
    "    # DSBF-Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yr()\n",
    "    dsbf = DSBF()\n",
    "    X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "      fn=objective_ridge,\n",
    "      space=ridge_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=ridge_trials)\n",
    "    print(\"DSBF_Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    dsbf_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "\n",
    "    #DTB-SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_jr()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "        fn=objective_svm,\n",
    "        space=svm_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=svm_trials)\n",
    "    \n",
    "    print(\"DTB-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    dtb_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "    # TCA_SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_jr()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "    print(\"TCA-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    tca_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "    # Bruakfilter-KNN\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lr()\n",
    "    bruakfilter = Bruakfilter()\n",
    "    X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on KNN\n",
    "    knn_trials = Trials()\n",
    "    best_params_knn = fmin(\n",
    "        fn=objective_knn,\n",
    "        space=knn_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=knn_trials)\n",
    "    \n",
    "    print(\"Bruakfilter-KNN: \", space_eval(knn_space, best_params_knn))\n",
    "    bruakfilter_knn = [format(-result['loss'], '.2f') for result in knn_trials.results]\n",
    "\n",
    "    # TCA-Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lr()\n",
    "    tca= TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"TCA-Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    tca_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "    \n",
    "    # Peterfilter_SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_jr()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "        fn=objective_svm,\n",
    "        space=svm_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=svm_trials)\n",
    "    \n",
    "    print(\"Peterfilter-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    peterfilter_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "    \n",
    "    # TCA-MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_jr()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"TCA-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    tca_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # Bruakfilter - MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yr()\n",
    "    bruakfilter = Bruakfilter()\n",
    "    X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"Bruakfilter-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    bruakfilter_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # DTB - MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lr()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"DTB-MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    dtb_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # DTB-Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_tr()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"DTB-Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    dtb_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "\n",
    "    return dsbf_ridge, dtb_svm, tca_svm, bruakfilter_knn, tca_ridge, peterfilter_svm, tca_mlp, bruakfilter_mlp, dtb_mlp, dtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e12fae0d-10bf-407b-88bf-f0e774f02775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 50/50 [00:01<00:00, 29.39trial/s, best loss: -0.9070458404074703]\n",
      "DSBF_Ridge:  {'alpha': 0.9994722280241827, 'max_iter': 10277, 'solver': 'sparse_cg'}\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 168.79trial/s, best loss: -1.0]\n",
      "DTB-SVM:  {'C': 1.703398693240141, 'degree': 1, 'kernel': 'linear'}\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 159.23trial/s, best loss: -1.0]\n",
      "TCA-SVM:  {'C': 0.49151449357828736, 'degree': 4, 'kernel': 'linear'}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 50/50 [00:01<00:00, 36.52trial/s, best loss: -0.7414338632505016]\n",
      "Bruakfilter-KNN:  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 50/50 [00:02<00:00, 24.72trial/s, best loss: -0.9078947368421052]\n",
      "TCA-Ridge:  {'alpha': 0.9991702540466569, 'max_iter': 4930, 'solver': 'saga'}\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 173.03trial/s, best loss: -1.0]\n",
      "Peterfilter-SVM:  {'C': 1.7436772636042333, 'degree': 4, 'kernel': 'linear'}\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|██████████| 50/50 [00:02<00:00, 17.40trial/s, best loss: -0.91383701188455]\n",
      "TCA-MLP:  {'activation': 'identity', 'alpha': 0.004435298403231614, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 70}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 50/50 [00:02<00:00, 18.76trial/s, best loss: -0.9864176570458404]\n",
      "Bruakfilter-MLP:  {'activation': 'identity', 'alpha': 0.0012155857193275985, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 96}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 50/50 [00:02<00:00, 18.39trial/s, best loss: -0.9949066213921902]\n",
      "DTB-MLP:  {'activation': 'tanh', 'alpha': 0.001038228712469033, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 98}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "100%|████████| 50/50 [00:01<00:00, 30.53trial/s, best loss: -0.9066213921901528]\n",
      "DTB-Ridge:  {'alpha': 0.9641184483587357, 'max_iter': 14131, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "dsbf_ridge, dtb_svm, tca_svm, bruakfilter_knn, tca_ridge, peterfilter_svm, tca_mlp, bruakfilter_mlp, dtb_mlp, dtb_ridge = ray_violin_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a319a86-6b5b-44c8-b73b-7cb556282f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ray = pd.DataFrame({\n",
    "      'Classifier': ['DSBF_Ridge'] * len(dsbf_ridge) +\n",
    "                    ['DTB_SVM'] * len(dtb_svm) +\n",
    "                    ['TCA_SVM'] * len(tca_svm) +\n",
    "                    ['Bruakfilter_KNN'] * len(bruakfilter_knn) +\n",
    "                    ['TCA_Ridge'] * len(tca_ridge) +\n",
    "                    ['Peterfilter_SVM'] * len(peterfilter_svm) +\n",
    "                    ['TCA_MLP'] * len(tca_mlp) +\n",
    "                    ['Bruakfilter_MLP'] * len(bruakfilter_mlp) +\n",
    "                    ['DTB_MLP'] * len(dtb_mlp) +\n",
    "                    ['DTB_Ridge'] * len(dtb_ridge),\n",
    "      'ROC AUC': dsbf_ridge + dtb_svm + tca_svm + bruakfilter_knn + tca_ridge + peterfilter_svm + tca_mlp + bruakfilter_mlp + dtb_mlp + dtb_ridge\n",
    "  })\n",
    "\n",
    "data_ray['ROC AUC'] = pd.to_numeric(data_ray['ROC AUC'])\n",
    "#violin_plots(data_jax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad124c95-c40c-4772-8f94-785582a9111b",
   "metadata": {},
   "source": [
    "## Target Project: Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c9b35a0e-2398-43f5-8311-ffc3500029f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_lt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_rt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_yt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee710bc7-e661-45be-8b76-5720c19d3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transformers_violin_plot():\n",
    "    # TCA-CART\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_lt()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on CART\n",
    "    cart_trials = Trials()\n",
    "    best_params_cart = fmin(\n",
    "      fn=objective_cart,\n",
    "      space=cart_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=cart_trials)\n",
    "    print(\"TCA_CART: \", space_eval(cart_space, best_params_cart))\n",
    "    tca_cart = [format(-result['loss'], '.2f') for result in cart_trials.results]\n",
    "\n",
    "    #TCA-RandomForest\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rt()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on RandomForest\n",
    "    rf_trials = Trials()\n",
    "    best_params_rf = fmin(\n",
    "        fn=objective_rf,\n",
    "        space=rf_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=rf_trials)\n",
    "    \n",
    "    print(\"TCA-RandomForest: \", space_eval(rf_space, best_params_rf))\n",
    "    tca_rf = [format(-result['loss'], '.2f') for result in rf_trials.results]\n",
    "\n",
    "    # Peterfilter-RandomForest\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yt()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on RandomForest\n",
    "    rf_trials = Trials()\n",
    "    best_params_rf = fmin(\n",
    "      fn=objective_rf,\n",
    "      space=rf_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=rf_trials)\n",
    "    print(\"Peterfilter-RandomForest: \", space_eval(rf_space, best_params_rf))\n",
    "    peterfilter_rf = [format(-result['loss'], '.2f') for result in rf_trials.results]\n",
    "\n",
    "    # Universal_Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yt()\n",
    "    universal = Universal()\n",
    "    X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"Universal-Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    universal_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "\n",
    "    # DSBF-Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_yt()\n",
    "    dsbf = DSBF()\n",
    "    X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"DSBF - Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    dsbf_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "    \n",
    "    # Bruakfilter- KNN\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rt()\n",
    "    bruakfilter = Bruakfilter()\n",
    "    X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on KNN\n",
    "    knn_trials = Trials()\n",
    "    best_params_knn = fmin(\n",
    "        fn=objective_knn,\n",
    "        space=knn_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=knn_trials)\n",
    "    \n",
    "    print(\"Bruakfilter - KNN: \", space_eval(knn_space, best_params_knn))\n",
    "    bruakfilter_knn = [format(-result['loss'], '.2f') for result in knn_trials.results]\n",
    "    \n",
    "    # DTB-MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rt()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"DTB - MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "    dtb_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "    \n",
    "    # Peterfilter-Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rt()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"Peterfilter- Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    peterfilter_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "    \n",
    "    # TCA - Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_jt()\n",
    "    tca = TCA()\n",
    "    X_source, Y_source, X_target, Y_target = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"TCA - Ridge:\", space_eval(ridge_space, best_params_ridge))\n",
    "    tca_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "    \n",
    "    # DTB - SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_rt()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "        fn=objective_svm,\n",
    "        space=svm_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=svm_trials)\n",
    "    \n",
    "    print(\"DTB-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    dtb_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "    return tca_cart, tca_rf, peterfilter_rf, universal_ridge, dsbf_nb, bruakfilter_knn, dtb_mlp, peterfilter_nb, tca_ridge, dtb_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ae4d3e8d-2549-4c56-a4fe-6a4b3807be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 160.65trial/s, best loss: -1.0]\n",
      "TCA_CART:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 50/50 [00:01<00:00, 33.19trial/s, best loss: -1.0]\n",
      "TCA-RandomForest:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 0.5972528762157073, 'n_estimators': 18}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 50/50 [00:01<00:00, 33.53trial/s, best loss: -1.0]\n",
      "Peterfilter-RandomForest:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.22709291306483337, 'n_estimators': 7}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:01<00:00, 26.18trial/s, best loss: -0.9078947368421052]\n",
      "Universal-Ridge:  {'alpha': 0.9915666217937944, 'max_iter': 7048, 'solver': 'saga'}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████| 50/50 [00:00<00:00, 259.53trial/s, best loss: -0.8238539898132428]\n",
      "DSBF - Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:01<00:00, 36.97trial/s, best loss: -0.7414338632505016]\n",
      "Bruakfilter - KNN:  {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:03<00:00, 16.33trial/s, best loss: -0.9872665534804753]\n",
      "DTB - MLP:  {'activation': 'identity', 'alpha': 0.000672135313289246, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'max_iter': 98}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████| 50/50 [00:00<00:00, 253.14trial/s, best loss: -0.8238539898132428]\n",
      "Peterfilter- Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:02<00:00, 23.00trial/s, best loss: -0.9078947368421052]\n",
      "TCA - Ridge: {'alpha': 0.9939226030756676, 'max_iter': 3871, 'solver': 'saga'}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 170.65trial/s, best loss: -1.0]\n",
      "DTB-SVM:  {'C': 1.7662123752859655, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tca_cart, tca_rf, peterfilter_rf, universal_ridge, dsbf_nb, bruakfilter_knn, dtb_mlp, peterfilter_nb, tca_ridge, dtb_svm = transformers_violin_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "53a409db-d863-45ce-acf5-b1c9ef7596fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 155.63trial/s, best loss: -1.0]\n",
      "TCA_CART:  {'criterion': 'log_loss', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 6, 'splitter': 'best'}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 50/50 [00:01<00:00, 32.26trial/s, best loss: -1.0]\n",
      "TCA-RandomForest:  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 0.4906404290493932, 'n_estimators': 13}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████████████████████| 50/50 [00:01<00:00, 29.83trial/s, best loss: -1.0]\n",
      "Peterfilter-RandomForest:  {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 0.22338506864382335, 'n_estimators': 1}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:02<00:00, 24.48trial/s, best loss: -0.9078947368421052]\n",
      "Universal-Ridge:  {'alpha': 0.9858651871625962, 'max_iter': 6245, 'solver': 'saga'}\n",
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████| 50/50 [00:00<00:00, 217.39trial/s, best loss: -0.8238539898132428]\n",
      "DSBF - Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:01<00:00, 36.51trial/s, best loss: -0.7414338632505016]\n",
      "Bruakfilter - KNN:  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:02<00:00, 18.67trial/s, best loss: -0.9876910016977929]\n",
      "DTB - MLP:  {'activation': 'tanh', 'alpha': 0.004244291857124302, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'invscaling', 'max_iter': 88}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|███████| 50/50 [00:00<00:00, 254.29trial/s, best loss: -0.8238539898132428]\n",
      "Peterfilter- Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|████████| 50/50 [00:01<00:00, 28.45trial/s, best loss: -0.9078947368421052]\n",
      "TCA - Ridge: {'alpha': 0.9942050290656026, 'max_iter': 13400, 'solver': 'saga'}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 170.93trial/s, best loss: -1.0]\n",
      "DTB-SVM:  {'C': 1.5183846086032813, 'degree': 4, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tca_cart, tca_rf, peterfilter_rf, universal_ridge, dsbf_nb, bruakfilter_knn, dtb_mlp, peterfilter_nb, tca_ridge, dtb_svm = transformers_violin_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d30c08b7-fa11-4c5d-be0d-39e59fb45e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformers = pd.DataFrame({\n",
    "      'Classifier': ['TCA_CART'] * len(tca_cart) +\n",
    "                    ['TCA_RF'] * len(tca_rf) +\n",
    "                    ['Peterfilter_RF'] * len(peterfilter_rf) +\n",
    "                    ['Universal_Ridge'] * len(universal_ridge) +\n",
    "                    ['DSBF_NB'] * len(dsbf_nb) +\n",
    "                    ['Bruakfilter_KNN'] * len(bruakfilter_knn) +\n",
    "                    ['DTB_MLP'] * len(dtb_mlp) +\n",
    "                    ['Peterfilter_NB'] * len(peterfilter_nb) +\n",
    "                    ['TCA_Ridge'] * len(tca_ridge) +\n",
    "                    ['DTB_SVM'] * len(dtb_svm),\n",
    "      'ROC AUC': tca_cart + tca_rf + peterfilter_rf + universal_ridge + dsbf_nb + bruakfilter_knn + dtb_mlp + peterfilter_nb + tca_ridge + dtb_svm\n",
    "  })\n",
    "\n",
    "data_transformers['ROC AUC'] = pd.to_numeric(data_transformers['ROC AUC'])\n",
    "#violin_plots(data_jax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad8daa-3165-47b9-b308-1c05de70525b",
   "metadata": {},
   "source": [
    "## Target Project: Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b12aab6f-cc4d-4260-b818-4df36af9779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jy():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_ly():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "\n",
    "def data_loading_ry():\n",
    "    # Load your dataset (replace X and y with your features and labels)    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "def data_loading_ty():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7fd5c32f-d507-42d5-b2b6-a085f2a1b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yolov5_violin_plot():\n",
    "    # DTB-SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ry()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "    print(\"DTB-SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    dtb_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "    # Data Selection - Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ly()\n",
    "    ds = DataSelection()\n",
    "    loc = [0]\n",
    "    X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"DataSelection - Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    ds_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "\n",
    "    # Bruakfilter - KNN\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ry()\n",
    "    bruakfilter = Bruakfilter()\n",
    "    X_source, Y_source, X_target, Y_target = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on KNN\n",
    "    knn_trials = Trials()\n",
    "    best_params_knn = fmin(\n",
    "      fn=objective_knn,\n",
    "      space=knn_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=knn_trials)\n",
    "    print(\"Bruakfilter - KNN : \", space_eval(knn_space, best_params_knn))\n",
    "    bruakfilter_knn = [format(-result['loss'], '.2f') for result in knn_trials.results]\n",
    "\n",
    "    # DSBF - MLP\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ty()\n",
    "    dsbf = DSBF()\n",
    "    X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on MLP\n",
    "    mlp_trials = Trials()\n",
    "    best_params_mlp = fmin(\n",
    "        fn=objective_mlp,\n",
    "        space=mlp_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=mlp_trials)\n",
    "    \n",
    "    print(\"DSBF-MLP : \", space_eval(mlp_space, best_params_mlp))\n",
    "    dsbf_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "\n",
    "    # Peterfilter - SVM\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_jy()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on SVM\n",
    "    svm_trials = Trials()\n",
    "    best_params_svm = fmin(\n",
    "        fn=objective_svm,\n",
    "        space=svm_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=svm_trials)\n",
    "    \n",
    "    print(\"Peterfilter - SVM: \", space_eval(svm_space, best_params_svm))\n",
    "    peterfilter_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "    \n",
    "    # DSBF - Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ly()\n",
    "    dsbf = DSBF()\n",
    "    X_source, Y_source, X_target, Y_target = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"DSBF-Ridge \", space_eval(ridge_space, best_params_ridge))\n",
    "    dsbf_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "    \n",
    "    # Universal - AdaBoost\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ry()\n",
    "    universal = Universal()\n",
    "    X_source, Y_source, X_target, Y_target = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on AdaBoost\n",
    "    ada_trials = Trials()\n",
    "    best_params_ada = fmin(\n",
    "        fn=objective_ada,\n",
    "        space=ada_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ada_trials)\n",
    "    \n",
    "    print(\"Universal - AdaBoost: \", space_eval(ada_space, best_params_ada))\n",
    "    universal_ada = [format(-result['loss'], '.2f') for result in ada_trials.results]\n",
    "    \n",
    "    # DS - Random Forest\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ty()\n",
    "    ds = DataSelection()\n",
    "    loc = [0]\n",
    "    X_source, Y_source, X_target, Y_target = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "    #implement Hyperopt on Random Forest\n",
    "    rf_trials = Trials()\n",
    "    best_params_rf = fmin(\n",
    "        fn=objective_rf,\n",
    "        space=rf_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=rf_trials)\n",
    "    \n",
    "    print(\"DS - Random Forest: \", space_eval(rf_space, best_params_rf))\n",
    "    ds_rf = [format(-result['loss'], '.2f') for result in rf_trials.results]\n",
    "    \n",
    "    # DTB - Naive Bayes\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ry()\n",
    "    dtb = DTB()\n",
    "    X_source, Y_source, X_target, Y_target = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Naive Bayes\n",
    "    nb_trials = Trials()\n",
    "    best_params_nb = fmin(\n",
    "        fn=objective_nb,\n",
    "        space=nb_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=nb_trials)\n",
    "    \n",
    "    print(\"DTB-Naive Bayes: \", space_eval(nb_space, best_params_nb))\n",
    "    dtb_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "    \n",
    "    # Peterfilter - Ridge\n",
    "    X_source, Y_source, X_target, Y_target = data_loading_ly()\n",
    "    peterfilter = Peterfilter()\n",
    "    X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "    #implement Hyperopt on Ridge\n",
    "    ridge_trials = Trials()\n",
    "    best_params_ridge = fmin(\n",
    "        fn=objective_ridge,\n",
    "        space=ridge_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=50,\n",
    "        trials=ridge_trials)\n",
    "    \n",
    "    print(\"Peterfilter- Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "    peterfilter_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "\n",
    "    return dtb_svm, ds_nb, bruakfilter_knn, dsbf_mlp, peterfilter_svm, dsbf_ridge, universal_ada, ds_rf, dtb_nb, peterfilter_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbfd8699-fd74-4704-9d5c-3f687c96441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 169.36trial/s, best loss: -1.0]\n",
      "DTB-SVM:  {'C': 0.5623786388413984, 'degree': 1, 'kernel': 'linear'}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████| 50/50 [00:00<00:00, 256.95trial/s, best loss: -0.8238539898132428]\n",
      "DataSelection - Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 50/50 [00:01<00:00, 36.31trial/s, best loss: -0.7414338632505016]\n",
      "Bruakfilter - KNN :  {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 50/50 [00:03<00:00, 15.22trial/s, best loss: -0.8862478777589133]\n",
      "DSBF-MLP :  {'activation': 'relu', 'alpha': 0.0026919899819994406, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 99}\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 174.78trial/s, best loss: -1.0]\n",
      "Peterfilter - SVM:  {'C': 1.453440343482263, 'degree': 4, 'kernel': 'linear'}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 50/50 [00:01<00:00, 27.30trial/s, best loss: -0.9078947368421052]\n",
      "DSBF-Ridge  {'alpha': 0.9944983387453428, 'max_iter': 4020, 'solver': 'saga'}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|██████████████████████| 50/50 [00:00<00:00, 165.09trial/s, best loss: -1.0]\n",
      "Universal - AdaBoost:  {'algorithm': 'SAMME', 'learning_rate': 0.3917172742206881, 'n_estimators': 18}\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████████████████████| 50/50 [00:01<00:00, 34.25trial/s, best loss: -1.0]\n",
      "DS - Random Forest:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 0.10129072074774514, 'n_estimators': 44}\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|███████| 50/50 [00:00<00:00, 248.81trial/s, best loss: -0.8238539898132428]\n",
      "DTB-Naive Bayes:  {'var_smoothing': 1e-09}\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "100%|████████| 50/50 [00:01<00:00, 36.12trial/s, best loss: -0.9066213921901528]\n",
      "Peterfilter- Ridge:  {'alpha': 0.9394060912849344, 'max_iter': 3077, 'solver': 'sparse_cg'}\n"
     ]
    }
   ],
   "source": [
    "dtb_svm, ds_nb, bruakfilter_knn, dsbf_mlp, peterfilter_svm, dsbf_ridge, universal_ada, ds_rf, dtb_nb, peterfiler_ridge = yolov5_violin_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cd5b5eb0-6715-4d3c-b22b-f55a4628b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yolov5 = pd.DataFrame({\n",
    "      'Classifier': ['DTB_SVM'] * len(dtb_svm) +\n",
    "                    ['DS_NB'] * len(ds_nb) +\n",
    "                    ['Bruakfilter_KNN'] * len(bruakfilter_knn) +\n",
    "                    ['DSBF_MLP'] * len(dsbf_mlp) +\n",
    "                    ['Peterfilter_SVM'] * len(peterfilter_svm) +\n",
    "                    ['DSBF_Ridge'] * len(dsbf_ridge) +\n",
    "                    ['Universal_AdaBoost'] * len(universal_ada) +\n",
    "                    ['DS_RF'] * len(ds_rf) +\n",
    "                    ['DTB_NB'] * len(dtb_nb) +\n",
    "                    ['Peterfilter_Ridge'] * len(peterfilter_ridge),\n",
    "      'ROC AUC': dtb_svm + ds_nb + bruakfilter_knn + dsbf_mlp + peterfilter_svm + dsbf_ridge + universal_ada + ds_rf + dtb_nb + peterfilter_ridge\n",
    "  })\n",
    "\n",
    "data_yolov5['ROC AUC'] = pd.to_numeric(data_yolov5['ROC AUC'])\n",
    "#violin_plots(data_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "34c2e06c-c312-4e15-8068-546bb6737f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def violin_plots(data_jax, data_lightning, data_ray, data_transformers, data_yolov5):\n",
    "  # Create a DataFrame for Seaborn\n",
    "  \n",
    "  # Create subplots\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(30, 4))\n",
    "\n",
    "  # Plot violin plots\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_jax, ax=axes[0])\n",
    "  axes[0].set_title('Jax')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_lightning, ax=axes[1])\n",
    "  axes[1].set_title('Lightning')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_ray, ax=axes[2])\n",
    "  axes[2].set_title('Ray')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_transformers, ax=axes[3])\n",
    "  axes[3].set_title('Transformers')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_yolov5, ax=axes[4])\n",
    "  axes[4].set_title('Yolov5')\n",
    "\n",
    "\n",
    "  # Tilt x-axis labels\n",
    "  axes[0].tick_params(axis='x', rotation=60)\n",
    "  axes[1].tick_params(axis='x', rotation=60)\n",
    "  axes[2].tick_params(axis='x', rotation=60)\n",
    "  axes[3].tick_params(axis='x', rotation=60)\n",
    "  axes[4].tick_params(axis='x', rotation=60)\n",
    "  plt.savefig('cpdp_results.png', bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0d84e6f4-4ad4-4231-9bcd-02fc2cb7aa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "violin_plots(data_jax, data_lightning, data_ray, data_transformers, data_yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4442f7-5dd0-4348-9764-5899aca77579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae7daa4f-3d64-49f7-a47e-96aa818fc312",
   "metadata": {},
   "source": [
    "# RQ3 - Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01449245-cad8-49a3-8e38-bde6c9e45043",
   "metadata": {},
   "source": [
    "## Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b135c728-b256-45d3-bb81-68f35af6acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ML files:  (294, 1)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "Peterfiler-SVM\n",
      "Number of correctly predicted defect-prone ML files: 3\n",
      "Number of incorrectly predicted defect-prone ML files: 56\n",
      "Number of correctly predicted defect-prone Non-ML files: 2\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 26\n"
     ]
    }
   ],
   "source": [
    "#jax_test_data = pd.read_csv('/home/user/CS21D002_Eashaan/MSR_2024/Dataset/jax_0.3.15.csv')\n",
    "jax_ml = pd.read_csv('../Dataset_ML_Files/jax_ml_files.csv')\n",
    "len_jax_ml = jax_ml.shape\n",
    "print(\"Number of ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, jax_test_data = data_loading_lj()\n",
    "#Peterfilter_SVM\n",
    "print(\"Peterfiler-SVM\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source, Y_source, X_target, Y_target = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(random_state=42)\n",
    "model.fit(X_source, Y_source)\n",
    "y_pred = model.predict(X_target)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a6c63c1d-facd-4069-91db-db975232980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jax's ML files:  (294, 1)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "Peterfiler-SVM\n",
      "Number of total correctly predicted defect-prone files: 60\n",
      "Number of total incorrectly predicted defect-prone files: 32\n",
      "Number of correctly predicted defect-prone ML files: 38\n",
      "Number of incorrectly predicted defect-prone ML files: 17\n",
      "Number of correctly predicted defect-prone Non-ML files: 22\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 15\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 99\n",
      "Number of total incorrectly predicted defect-prone files: 287\n",
      "Number of correctly predicted defect-prone ML files: 63\n",
      "Number of incorrectly predicted defect-prone ML files: 202\n",
      "Number of correctly predicted defect-prone Non-ML files: 36\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 85\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 97\n",
      "Number of total incorrectly predicted defect-prone files: 302\n",
      "Number of correctly predicted defect-prone ML files: 60\n",
      "Number of incorrectly predicted defect-prone ML files: 218\n",
      "Number of correctly predicted defect-prone Non-ML files: 37\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 84\n",
      "*******************************************************************************\n",
      "Peterfilter- Ridge\n",
      "Number of total correctly predicted defect-prone files: 33\n",
      "Number of total incorrectly predicted defect-prone files: 147\n",
      "Number of correctly predicted defect-prone ML files: 25\n",
      "Number of incorrectly predicted defect-prone ML files: 100\n",
      "Number of correctly predicted defect-prone Non-ML files: 8\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 47\n",
      "*******************************************************************************\n",
      "DTB-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 66\n",
      "Number of total incorrectly predicted defect-prone files: 17\n",
      "Number of correctly predicted defect-prone ML files: 40\n",
      "Number of incorrectly predicted defect-prone ML files: 13\n",
      "Number of correctly predicted defect-prone Non-ML files: 26\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 4\n",
      "*******************************************************************************\n",
      "Bruakfilter-Random Forest\n",
      "Number of total correctly predicted defect-prone files: 88\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 34\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter- NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 109\n",
      "Number of total incorrectly predicted defect-prone files: 269\n",
      "Number of correctly predicted defect-prone ML files: 68\n",
      "Number of incorrectly predicted defect-prone ML files: 195\n",
      "Number of correctly predicted defect-prone Non-ML files: 41\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 74\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 28\n",
      "Number of total incorrectly predicted defect-prone files: 6\n",
      "Number of correctly predicted defect-prone ML files: 18\n",
      "Number of incorrectly predicted defect-prone ML files: 3\n",
      "Number of correctly predicted defect-prone Non-ML files: 10\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 3\n",
      "*******************************************************************************\n",
      "TCA-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 68\n",
      "Number of total incorrectly predicted defect-prone files: 23\n",
      "Number of correctly predicted defect-prone ML files: 43\n",
      "Number of incorrectly predicted defect-prone ML files: 16\n",
      "Number of correctly predicted defect-prone Non-ML files: 25\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 7\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "jax_ml = pd.read_csv('../Dataset_ML_Files/jax_ml_files.csv')\n",
    "len_jax_ml = jax_ml.shape\n",
    "print(\"Number of Jax's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, jax_test_data = data_loading_lj()\n",
    "\n",
    "#Peterfilter_SVM\n",
    "print(\"Peterfiler-SVM\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=2.4, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=4.49, degree=3, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- Ridge\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=RidgeClassifier(alpha=0.92, max_iter=5119, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Naive Bayes\")\n",
    "# DTB-Naive Bayes\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-Random Forest\")\n",
    "# Bruakfilter- Random Forest\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=0.4, n_estimators=12)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- NaiveBayes\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Naive Bayes\")\n",
    "# TCA - Naive Bayes\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2f089d79-ada9-43df-b6fc-2167c8419c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jax's ML files:  (294, 1)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "Peterfiler-SVM\n",
      "Number of total correctly predicted defect-prone files: 90\n",
      "Number of total incorrectly predicted defect-prone files: 85\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 61\n",
      "Number of correctly predicted defect-prone Non-ML files: 36\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 24\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 90\n",
      "Number of total incorrectly predicted defect-prone files: 63\n",
      "Number of correctly predicted defect-prone ML files: 55\n",
      "Number of incorrectly predicted defect-prone ML files: 60\n",
      "Number of correctly predicted defect-prone Non-ML files: 35\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 3\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 91\n",
      "Number of total incorrectly predicted defect-prone files: 36\n",
      "Number of correctly predicted defect-prone ML files: 56\n",
      "Number of incorrectly predicted defect-prone ML files: 35\n",
      "Number of correctly predicted defect-prone Non-ML files: 35\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "Peterfilter- Ridge\n",
      "Number of total correctly predicted defect-prone files: 28\n",
      "Number of total incorrectly predicted defect-prone files: 34\n",
      "Number of correctly predicted defect-prone ML files: 18\n",
      "Number of incorrectly predicted defect-prone ML files: 17\n",
      "Number of correctly predicted defect-prone Non-ML files: 10\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 17\n",
      "*******************************************************************************\n",
      "DTB-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 58\n",
      "Number of total incorrectly predicted defect-prone files: 138\n",
      "Number of correctly predicted defect-prone ML files: 37\n",
      "Number of incorrectly predicted defect-prone ML files: 101\n",
      "Number of correctly predicted defect-prone Non-ML files: 21\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 37\n",
      "*******************************************************************************\n",
      "Bruakfilter-Random Forest\n",
      "Number of total correctly predicted defect-prone files: 73\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 46\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 27\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter- NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 109\n",
      "Number of total incorrectly predicted defect-prone files: 252\n",
      "Number of correctly predicted defect-prone ML files: 68\n",
      "Number of incorrectly predicted defect-prone ML files: 182\n",
      "Number of correctly predicted defect-prone Non-ML files: 41\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 70\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 40\n",
      "Number of total incorrectly predicted defect-prone files: 5\n",
      "Number of correctly predicted defect-prone ML files: 24\n",
      "Number of incorrectly predicted defect-prone ML files: 2\n",
      "Number of correctly predicted defect-prone Non-ML files: 16\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 3\n",
      "*******************************************************************************\n",
      "TCA-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 65\n",
      "Number of total incorrectly predicted defect-prone files: 21\n",
      "Number of correctly predicted defect-prone ML files: 41\n",
      "Number of incorrectly predicted defect-prone ML files: 21\n",
      "Number of correctly predicted defect-prone Non-ML files: 24\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DSBF-MLP\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 664 does not match index length 1266",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [156], line 283\u001b[0m\n\u001b[1;32m    281\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_target1)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# Assuming 'files_column' is the column containing file names or identifiers\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjax_test_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjax_test_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBuggy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Identify correct and incorrect predictions for all defect-prone files\u001b[39;00m\n\u001b[1;32m    286\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m results[(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py:688\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    684\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    685\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    687\u001b[0m         )\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 664 does not match index length 1266"
     ]
    }
   ],
   "source": [
    "jax_ml = pd.read_csv('../Dataset_ML_Files/jax_ml_files.csv')\n",
    "len_jax_ml = jax_ml.shape\n",
    "print(\"Number of Jax's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, jax_test_data = data_loading_rj()\n",
    "\n",
    "#Peterfilter_SVM\n",
    "print(\"Peterfiler-SVM\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=2.4, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=4.49, degree=3, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- Ridge\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=RidgeClassifier(alpha=0.92, max_iter=5119, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Naive Bayes\")\n",
    "# DTB-Naive Bayes\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-Random Forest\")\n",
    "# Bruakfilter- Random Forest\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=0.4, n_estimators=12)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- NaiveBayes\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Naive Bayes\")\n",
    "# TCA - Naive Bayes\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e34955a0-d887-41f4-b6a4-433c894d9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jax's ML files:  (294, 1)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "Peterfiler-SVM\n",
      "Number of total correctly predicted defect-prone files: 29\n",
      "Number of total incorrectly predicted defect-prone files: 11\n",
      "Number of correctly predicted defect-prone ML files: 21\n",
      "Number of incorrectly predicted defect-prone ML files: 7\n",
      "Number of correctly predicted defect-prone Non-ML files: 8\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 4\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 67\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 42\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 25\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 85\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 52\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 33\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter- Ridge\n",
      "Number of total correctly predicted defect-prone files: 9\n",
      "Number of total incorrectly predicted defect-prone files: 20\n",
      "Number of correctly predicted defect-prone ML files: 5\n",
      "Number of incorrectly predicted defect-prone ML files: 17\n",
      "Number of correctly predicted defect-prone Non-ML files: 4\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 3\n",
      "*******************************************************************************\n",
      "DTB-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 50\n",
      "Number of total incorrectly predicted defect-prone files: 126\n",
      "Number of correctly predicted defect-prone ML files: 31\n",
      "Number of incorrectly predicted defect-prone ML files: 105\n",
      "Number of correctly predicted defect-prone Non-ML files: 19\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 21\n",
      "*******************************************************************************\n",
      "Bruakfilter-Random Forest\n",
      "Number of total correctly predicted defect-prone files: 2\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 2\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 0\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter- NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 66\n",
      "Number of total incorrectly predicted defect-prone files: 161\n",
      "Number of correctly predicted defect-prone ML files: 42\n",
      "Number of incorrectly predicted defect-prone ML files: 126\n",
      "Number of correctly predicted defect-prone Non-ML files: 24\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 35\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 45\n",
      "Number of total incorrectly predicted defect-prone files: 154\n",
      "Number of correctly predicted defect-prone ML files: 27\n",
      "Number of incorrectly predicted defect-prone ML files: 120\n",
      "Number of correctly predicted defect-prone Non-ML files: 18\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 34\n",
      "*******************************************************************************\n",
      "TCA-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 42\n",
      "Number of total incorrectly predicted defect-prone files: 3\n",
      "Number of correctly predicted defect-prone ML files: 28\n",
      "Number of incorrectly predicted defect-prone ML files: 3\n",
      "Number of correctly predicted defect-prone Non-ML files: 14\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "jax_ml = pd.read_csv('../Dataset_ML_Files/jax_ml_files.csv')\n",
    "len_jax_ml = jax_ml.shape\n",
    "print(\"Number of Jax's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, jax_test_data = data_loading_tj()\n",
    "\n",
    "#Peterfilter_SVM\n",
    "print(\"Peterfiler-SVM\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=2.4, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=4.49, degree=3, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- Ridge\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=RidgeClassifier(alpha=0.92, max_iter=5119, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Naive Bayes\")\n",
    "# DTB-Naive Bayes\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-Random Forest\")\n",
    "# Bruakfilter- Random Forest\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=0.4, n_estimators=12)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- NaiveBayes\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Naive Bayes\")\n",
    "# TCA - Naive Bayes\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31fc8971-6dce-4720-bb48-a05c42e89c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jax's ML files:  (294, 1)\n",
      "(103, 17)\n",
      "(103,)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "Peterfiler-SVM\n",
      "Number of total correctly predicted defect-prone files: 90\n",
      "Number of total incorrectly predicted defect-prone files: 277\n",
      "Number of correctly predicted defect-prone ML files: 59\n",
      "Number of incorrectly predicted defect-prone ML files: 217\n",
      "Number of correctly predicted defect-prone Non-ML files: 31\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 60\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 118\n",
      "Number of total incorrectly predicted defect-prone files: 686\n",
      "Number of correctly predicted defect-prone ML files: 75\n",
      "Number of incorrectly predicted defect-prone ML files: 527\n",
      "Number of correctly predicted defect-prone Non-ML files: 43\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 159\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 118\n",
      "Number of total incorrectly predicted defect-prone files: 668\n",
      "Number of correctly predicted defect-prone ML files: 75\n",
      "Number of incorrectly predicted defect-prone ML files: 514\n",
      "Number of correctly predicted defect-prone Non-ML files: 43\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 154\n",
      "*******************************************************************************\n",
      "Peterfilter- Ridge\n",
      "Number of total correctly predicted defect-prone files: 124\n",
      "Number of total incorrectly predicted defect-prone files: 1100\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 722\n",
      "Number of correctly predicted defect-prone Non-ML files: 43\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 378\n",
      "*******************************************************************************\n",
      "DTB-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 68\n",
      "Number of total incorrectly predicted defect-prone files: 325\n",
      "Number of correctly predicted defect-prone ML files: 44\n",
      "Number of incorrectly predicted defect-prone ML files: 244\n",
      "Number of correctly predicted defect-prone Non-ML files: 24\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 81\n",
      "*******************************************************************************\n",
      "Bruakfilter-Random Forest\n",
      "Number of total correctly predicted defect-prone files: 109\n",
      "Number of total incorrectly predicted defect-prone files: 261\n",
      "Number of correctly predicted defect-prone ML files: 68\n",
      "Number of incorrectly predicted defect-prone ML files: 184\n",
      "Number of correctly predicted defect-prone Non-ML files: 41\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 77\n",
      "*******************************************************************************\n",
      "Peterfilter- NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 64\n",
      "Number of total incorrectly predicted defect-prone files: 261\n",
      "Number of correctly predicted defect-prone ML files: 41\n",
      "Number of incorrectly predicted defect-prone ML files: 198\n",
      "Number of correctly predicted defect-prone Non-ML files: 23\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 63\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 80\n",
      "Number of total incorrectly predicted defect-prone files: 404\n",
      "Number of correctly predicted defect-prone ML files: 53\n",
      "Number of incorrectly predicted defect-prone ML files: 288\n",
      "Number of correctly predicted defect-prone Non-ML files: 27\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 116\n",
      "*******************************************************************************\n",
      "TCA-Naive Bayes\n",
      "Number of total correctly predicted defect-prone files: 114\n",
      "Number of total incorrectly predicted defect-prone files: 613\n",
      "Number of correctly predicted defect-prone ML files: 72\n",
      "Number of incorrectly predicted defect-prone ML files: 469\n",
      "Number of correctly predicted defect-prone Non-ML files: 42\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 144\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "jax_ml = pd.read_csv('../Dataset_ML_Files/jax_ml_files.csv')\n",
    "len_jax_ml = jax_ml.shape\n",
    "print(\"Number of Jax's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, jax_test_data = data_loading_yj()\n",
    "\n",
    "#Peterfilter_SVM\n",
    "print(\"Peterfiler-SVM\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=2.4, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=4.49, degree=3, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- Ridge\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=RidgeClassifier(alpha=0.92, max_iter=5119, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Naive Bayes\")\n",
    "# DTB-Naive Bayes\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-Random Forest\")\n",
    "# Bruakfilter- Random Forest\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=0.4, n_estimators=12)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter- NaiveBayes\")\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Naive Bayes\")\n",
    "# TCA - Naive Bayes\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': jax_test_data['Files'], 'Actual': jax_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(jax_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3542ae8-58bc-4bb8-afe6-0fcd33ac79bb",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "921573b5-e2a1-490a-84b1-b15d10798723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lightning's ML files:  (294, 1)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "DS-SVM\n",
      "Number of total correctly predicted defect-prone files: 499\n",
      "Number of total incorrectly predicted defect-prone files: 79\n",
      "Number of correctly predicted defect-prone ML files: 62\n",
      "Number of incorrectly predicted defect-prone ML files: 20\n",
      "Number of correctly predicted defect-prone Non-ML files: 437\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 59\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 259\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 25\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 234\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Universal-KNN\n",
      "Number of total correctly predicted defect-prone files: 543\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 80\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 463\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 558\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 80\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 206\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 5\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 201\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 555\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 78\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 477\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-Ridge\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-NB\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 391\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 39\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 352\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lightning_ml = pd.read_csv('../Dataset_ML_Files/lightning_ml_files.csv')\n",
    "len_lightning_ml = jax_ml.shape\n",
    "print(\"Number of Lightning's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, lightning_test_data = data_loading_jl()\n",
    "\n",
    "#DS_SVM\n",
    "print(\"DS-SVM\")\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = SVC(C=1.28, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-KNN\")\n",
    "# Universal KNN\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.006, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=93, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "# DTB-Ridge\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=1938, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "# DSBF-MLP\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.004, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TAC-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.97, degree=4, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-Ridge\")\n",
    "# DS-Ridge\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=12291, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-NB\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB() \n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2b84a263-c731-43e3-a3b8-82fe85e57dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lightning's ML files:  (294, 1)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "DS-SVM\n",
      "Number of total correctly predicted defect-prone files: 557\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 79\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 390\n",
      "Number of total incorrectly predicted defect-prone files: 5\n",
      "Number of correctly predicted defect-prone ML files: 50\n",
      "Number of incorrectly predicted defect-prone ML files: 1\n",
      "Number of correctly predicted defect-prone Non-ML files: 340\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 4\n",
      "*******************************************************************************\n",
      "Universal-KNN\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-Ridge\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-NB\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lightning_ml = pd.read_csv('../Dataset_ML_Files/lightning_ml_files.csv')\n",
    "len_lightning_ml = jax_ml.shape\n",
    "print(\"Number of Lightning's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, lightning_test_data = data_loading_rl()\n",
    "\n",
    "#DS_SVM\n",
    "print(\"DS-SVM\")\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = SVC(C=1.28, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-KNN\")\n",
    "# Universal KNN\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.006, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=93, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "# DTB-Ridge\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=1938, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "# DSBF-MLP\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.004, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TAC-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.97, degree=4, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-Ridge\")\n",
    "# DS-Ridge\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=12291, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-NB\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB() \n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0ffe671b-d851-4bfa-a0ce-1a642dcb810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lightning's ML files:  (294, 1)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "DS-SVM\n",
      "Number of total correctly predicted defect-prone files: 329\n",
      "Number of total incorrectly predicted defect-prone files: 6\n",
      "Number of correctly predicted defect-prone ML files: 36\n",
      "Number of incorrectly predicted defect-prone ML files: 4\n",
      "Number of correctly predicted defect-prone Non-ML files: 293\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 2\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 168\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 3\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 165\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Universal-KNN\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 551\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 79\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 472\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-Ridge\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-NB\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lightning_ml = pd.read_csv('../Dataset_ML_Files/lightning_ml_files.csv')\n",
    "len_lightning_ml = jax_ml.shape\n",
    "print(\"Number of Lightning's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, lightning_test_data = data_loading_tl()\n",
    "\n",
    "#DS_SVM\n",
    "print(\"DS-SVM\")\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = SVC(C=1.28, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-KNN\")\n",
    "# Universal KNN\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.006, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=93, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "# DTB-Ridge\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=1938, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "# DSBF-MLP\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.004, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TAC-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.97, degree=4, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-Ridge\")\n",
    "# DS-Ridge\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=12291, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-NB\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB() \n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "70ae2eae-0628-4dfe-96eb-dbfce49a71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lightning's ML files:  (294, 1)\n",
      "(103, 17)\n",
      "(103,)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "DS-SVM\n",
      "Number of total correctly predicted defect-prone files: 447\n",
      "Number of total incorrectly predicted defect-prone files: 300\n",
      "Number of correctly predicted defect-prone ML files: 51\n",
      "Number of incorrectly predicted defect-prone ML files: 97\n",
      "Number of correctly predicted defect-prone Non-ML files: 396\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 203\n",
      "*******************************************************************************\n",
      "TCA - MLP\n",
      "Number of total correctly predicted defect-prone files: 519\n",
      "Number of total incorrectly predicted defect-prone files: 715\n",
      "Number of correctly predicted defect-prone ML files: 73\n",
      "Number of incorrectly predicted defect-prone ML files: 257\n",
      "Number of correctly predicted defect-prone Non-ML files: 446\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 458\n",
      "*******************************************************************************\n",
      "Universal-KNN\n",
      "Number of total correctly predicted defect-prone files: 556\n",
      "Number of total incorrectly predicted defect-prone files: 183\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 82\n",
      "Number of correctly predicted defect-prone Non-ML files: 475\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 101\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 558\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 477\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 558\n",
      "Number of total incorrectly predicted defect-prone files: 483\n",
      "Number of correctly predicted defect-prone ML files: 80\n",
      "Number of incorrectly predicted defect-prone ML files: 170\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 313\n",
      "*******************************************************************************\n",
      "DS-Ridge\n",
      "Number of total correctly predicted defect-prone files: 558\n",
      "Number of total incorrectly predicted defect-prone files: 2\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 1\n",
      "Number of correctly predicted defect-prone Non-ML files: 477\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "Bruakfilter-NB\n",
      "Number of total correctly predicted defect-prone files: 559\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 478\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lightning_ml = pd.read_csv('../Dataset_ML_Files/lightning_ml_files.csv')\n",
    "len_lightning_ml = jax_ml.shape\n",
    "print(\"Number of Lightning's ML files: \", len_jax_ml)\n",
    "X_source, Y_source, X_target, Y_target, lightning_test_data = data_loading_yl()\n",
    "\n",
    "#DS_SVM\n",
    "print(\"DS-SVM\")\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = SVC(C=1.28, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA - MLP\")\n",
    "#TCA-MLP\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=85, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-KNN\")\n",
    "# Universal KNN\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.006, hidden_layer_sizes=(50,50), learning_rate='constant', max_iter=93, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "# DTB-Ridge\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=1938, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "# DSBF-MLP\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.004, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=95, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='identity', alpha=0.007, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TAC-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.97, degree=4, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-Ridge\")\n",
    "# DS-Ridge\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RidgeClassifier(alpha=0.91, max_iter=12291, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-NB\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB() \n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': lightning_test_data['Files'], 'Actual': lightning_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(lightning_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b507c1-a4dc-4c74-8e41-25a919f3f410",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7651289f-e6b4-4995-a515-5f6614ee7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_tr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data1 = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, ray_test_data1\n",
    "\n",
    "def data_loading_jr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data1 = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, ray_test_data1\n",
    "\n",
    "def data_loading_lr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data1 = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, ray_test_data1\n",
    "\n",
    "def data_loading_yr():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_test_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data1 = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = ray_test_data.drop(columns='Buggy')\n",
    "    Y_target = ray_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, ray_test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ea7bbf2c-251a-4f2f-b763-a08b84b68b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ray's ML files:  (650, 1)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 1364\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 217\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 1147\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 1051\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 168\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 883\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter- KNN\n",
      "Number of total correctly predicted defect-prone files: 1\n",
      "Number of total incorrectly predicted defect-prone files: 22\n",
      "Number of correctly predicted defect-prone ML files: 0\n",
      "Number of incorrectly predicted defect-prone ML files: 7\n",
      "Number of correctly predicted defect-prone Non-ML files: 1\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 15\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 823\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 122\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 701\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter-SVM\n",
      "Number of total correctly predicted defect-prone files: 1043\n",
      "Number of total incorrectly predicted defect-prone files: 233\n",
      "Number of correctly predicted defect-prone ML files: 173\n",
      "Number of incorrectly predicted defect-prone ML files: 57\n",
      "Number of correctly predicted defect-prone Non-ML files: 870\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 176\n",
      "*******************************************************************************\n",
      "TCA-MLP\n",
      "Number of total correctly predicted defect-prone files: 1327\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 232\n",
      "Number of incorrectly predicted defect-prone ML files: 1\n",
      "Number of correctly predicted defect-prone Non-ML files: 1095\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 103\n",
      "Number of total incorrectly predicted defect-prone files: 236\n",
      "Number of correctly predicted defect-prone ML files: 33\n",
      "Number of incorrectly predicted defect-prone ML files: 117\n",
      "Number of correctly predicted defect-prone Non-ML files: 70\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 119\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 688\n",
      "Number of total incorrectly predicted defect-prone files: 903\n",
      "Number of correctly predicted defect-prone ML files: 143\n",
      "Number of incorrectly predicted defect-prone ML files: 317\n",
      "Number of correctly predicted defect-prone Non-ML files: 545\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 586\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 1313\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 226\n",
      "Number of incorrectly predicted defect-prone ML files: 1\n",
      "Number of correctly predicted defect-prone Non-ML files: 1087\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "ray_ml = pd.read_csv('../Dataset_ML_Files/ray_ml_files.csv')\n",
    "len_ray_ml = ray_ml.shape\n",
    "print(\"Number of Ray's ML files: \", len_ray_ml)\n",
    "X_source, Y_source, X_target, Y_target, ray_test_data = data_loading_jr()\n",
    "\n",
    "DSBF-Ridge\n",
    "print(\"DSBF-Ridge\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=10277, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DTB-SVM\")\n",
    "#DTB-SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.49, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter- KNN\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "# TCA_Ridge\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=4930, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-MLP\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.004, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=70, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.96, max_iter=1412, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "# Bruakfilter-MLP\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=96, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "72dbcfcb-d220-4985-961a-943f376a7fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ray's ML files:  (650, 1)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 1608\n",
      "Number of total incorrectly predicted defect-prone files: 15\n",
      "Number of correctly predicted defect-prone ML files: 273\n",
      "Number of incorrectly predicted defect-prone ML files: 6\n",
      "Number of correctly predicted defect-prone Non-ML files: 1335\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 9\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 1588\n",
      "Number of total incorrectly predicted defect-prone files: 9\n",
      "Number of correctly predicted defect-prone ML files: 263\n",
      "Number of incorrectly predicted defect-prone ML files: 3\n",
      "Number of correctly predicted defect-prone Non-ML files: 1325\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 6\n",
      "*******************************************************************************\n",
      "Bruakfilter- KNN\n",
      "Number of total correctly predicted defect-prone files: 486\n",
      "Number of total incorrectly predicted defect-prone files: 861\n",
      "Number of correctly predicted defect-prone ML files: 81\n",
      "Number of incorrectly predicted defect-prone ML files: 267\n",
      "Number of correctly predicted defect-prone Non-ML files: 405\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 594\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 1311\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 232\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 1079\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter-SVM\n",
      "Number of total correctly predicted defect-prone files: 1554\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 255\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 1299\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "TCA-MLP\n",
      "Number of total correctly predicted defect-prone files: 1614\n",
      "Number of total incorrectly predicted defect-prone files: 18\n",
      "Number of correctly predicted defect-prone ML files: 274\n",
      "Number of incorrectly predicted defect-prone ML files: 8\n",
      "Number of correctly predicted defect-prone Non-ML files: 1340\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 10\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 779\n",
      "Number of total incorrectly predicted defect-prone files: 1032\n",
      "Number of correctly predicted defect-prone ML files: 149\n",
      "Number of incorrectly predicted defect-prone ML files: 314\n",
      "Number of correctly predicted defect-prone Non-ML files: 630\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 718\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 1254\n",
      "Number of total incorrectly predicted defect-prone files: 142\n",
      "Number of correctly predicted defect-prone ML files: 195\n",
      "Number of incorrectly predicted defect-prone ML files: 56\n",
      "Number of correctly predicted defect-prone Non-ML files: 1059\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 86\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 1617\n",
      "Number of total incorrectly predicted defect-prone files: 32\n",
      "Number of correctly predicted defect-prone ML files: 275\n",
      "Number of incorrectly predicted defect-prone ML files: 15\n",
      "Number of correctly predicted defect-prone Non-ML files: 1342\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 17\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "ray_ml = pd.read_csv('../Dataset_ML_Files/ray_ml_files.csv')\n",
    "len_ray_ml = ray_ml.shape\n",
    "print(\"Number of Ray's ML files: \", len_ray_ml)\n",
    "X_source, Y_source, X_target, Y_target, ray_test_data = data_loading_lr()\n",
    "\n",
    "DSBF-Ridge\n",
    "print(\"DSBF-Ridge\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=10277, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DTB-SVM\")\n",
    "#DTB-SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.49, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter- KNN\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "# TCA_Ridge\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=4930, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-MLP\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.004, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=70, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.96, max_iter=1412, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "# Bruakfilter-MLP\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=96, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2cc646dc-8e8e-4838-9cdb-aab2e601ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ray's ML files:  (650, 1)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 868\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 132\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 736\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 788\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 116\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 672\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter- KNN\n",
      "Number of total correctly predicted defect-prone files: 2\n",
      "Number of total incorrectly predicted defect-prone files: 5\n",
      "Number of correctly predicted defect-prone ML files: 1\n",
      "Number of incorrectly predicted defect-prone ML files: 1\n",
      "Number of correctly predicted defect-prone Non-ML files: 1\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 4\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 630\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 90\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 540\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter-SVM\n",
      "Number of total correctly predicted defect-prone files: 1087\n",
      "Number of total incorrectly predicted defect-prone files: 25\n",
      "Number of correctly predicted defect-prone ML files: 173\n",
      "Number of incorrectly predicted defect-prone ML files: 9\n",
      "Number of correctly predicted defect-prone Non-ML files: 914\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 16\n",
      "*******************************************************************************\n",
      "TCA-MLP\n",
      "Number of total correctly predicted defect-prone files: 756\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 113\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 643\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 171\n",
      "Number of total incorrectly predicted defect-prone files: 265\n",
      "Number of correctly predicted defect-prone ML files: 51\n",
      "Number of incorrectly predicted defect-prone ML files: 128\n",
      "Number of correctly predicted defect-prone Non-ML files: 120\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 137\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 1016\n",
      "Number of total incorrectly predicted defect-prone files: 164\n",
      "Number of correctly predicted defect-prone ML files: 182\n",
      "Number of incorrectly predicted defect-prone ML files: 70\n",
      "Number of correctly predicted defect-prone Non-ML files: 834\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 94\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 760\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 113\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 647\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "ray_ml = pd.read_csv('../Dataset_ML_Files/ray_ml_files.csv')\n",
    "len_ray_ml = ray_ml.shape\n",
    "print(\"Number of Ray's ML files: \", len_ray_ml)\n",
    "X_source, Y_source, X_target, Y_target, ray_test_data = data_loading_tr()\n",
    "\n",
    "DSBF-Ridge\n",
    "print(\"DSBF-Ridge\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=10277, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DTB-SVM\")\n",
    "#DTB-SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.49, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter- KNN\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "# TCA_Ridge\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=4930, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-MLP\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.004, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=70, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.96, max_iter=1412, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "# Bruakfilter-MLP\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=96, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c4a8fe87-5474-46df-9674-cabf1f53b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ray's ML files:  (650, 1)\n",
      "(103, 17)\n",
      "(103,)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 1384\n",
      "Number of total incorrectly predicted defect-prone files: 2801\n",
      "Number of correctly predicted defect-prone ML files: 249\n",
      "Number of incorrectly predicted defect-prone ML files: 847\n",
      "Number of correctly predicted defect-prone Non-ML files: 1135\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1954\n",
      "*******************************************************************************\n",
      "TCA-SVM\n",
      "Number of total correctly predicted defect-prone files: 1271\n",
      "Number of total incorrectly predicted defect-prone files: 2629\n",
      "Number of correctly predicted defect-prone ML files: 236\n",
      "Number of incorrectly predicted defect-prone ML files: 813\n",
      "Number of correctly predicted defect-prone Non-ML files: 1035\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1816\n",
      "*******************************************************************************\n",
      "Bruakfilter- KNN\n",
      "Number of total correctly predicted defect-prone files: 1151\n",
      "Number of total incorrectly predicted defect-prone files: 3168\n",
      "Number of correctly predicted defect-prone ML files: 216\n",
      "Number of incorrectly predicted defect-prone ML files: 803\n",
      "Number of correctly predicted defect-prone Non-ML files: 935\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 2365\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 1418\n",
      "Number of total incorrectly predicted defect-prone files: 3027\n",
      "Number of correctly predicted defect-prone ML files: 253\n",
      "Number of incorrectly predicted defect-prone ML files: 875\n",
      "Number of correctly predicted defect-prone Non-ML files: 1165\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 2152\n",
      "*******************************************************************************\n",
      "Peterfilter-SVM\n",
      "Number of total correctly predicted defect-prone files: 1512\n",
      "Number of total incorrectly predicted defect-prone files: 1798\n",
      "Number of correctly predicted defect-prone ML files: 253\n",
      "Number of incorrectly predicted defect-prone ML files: 572\n",
      "Number of correctly predicted defect-prone Non-ML files: 1259\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1226\n",
      "*******************************************************************************\n",
      "TCA-MLP\n",
      "Number of total correctly predicted defect-prone files: 1605\n",
      "Number of total incorrectly predicted defect-prone files: 2941\n",
      "Number of correctly predicted defect-prone ML files: 273\n",
      "Number of incorrectly predicted defect-prone ML files: 862\n",
      "Number of correctly predicted defect-prone Non-ML files: 1332\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 2079\n",
      "*******************************************************************************\n",
      "DTB-Ridge\n",
      "Number of total correctly predicted defect-prone files: 195\n",
      "Number of total incorrectly predicted defect-prone files: 348\n",
      "Number of correctly predicted defect-prone ML files: 58\n",
      "Number of incorrectly predicted defect-prone ML files: 171\n",
      "Number of correctly predicted defect-prone Non-ML files: 137\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 177\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 493\n",
      "Number of total incorrectly predicted defect-prone files: 1175\n",
      "Number of correctly predicted defect-prone ML files: 117\n",
      "Number of incorrectly predicted defect-prone ML files: 393\n",
      "Number of correctly predicted defect-prone Non-ML files: 376\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 782\n",
      "*******************************************************************************\n",
      "Bruakfilter-MLP\n",
      "Number of total correctly predicted defect-prone files: 1615\n",
      "Number of total incorrectly predicted defect-prone files: 2966\n",
      "Number of correctly predicted defect-prone ML files: 274\n",
      "Number of incorrectly predicted defect-prone ML files: 856\n",
      "Number of correctly predicted defect-prone Non-ML files: 1341\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 2110\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "ray_ml = pd.read_csv('../Dataset_ML_Files/ray_ml_files.csv')\n",
    "len_ray_ml = ray_ml.shape\n",
    "print(\"Number of Ray's ML files: \", len_ray_ml)\n",
    "X_source, Y_source, X_target, Y_target, ray_test_data = data_loading_yr()\n",
    "\n",
    "DSBF-Ridge\n",
    "print(\"DSBF-Ridge\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=10277, solver='sparse_cg', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DTB-SVM\")\n",
    "#DTB-SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=1, kernel='linear', random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-SVM\")\n",
    "# TCA-SVM\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.49, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter- KNN\")\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model=KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "# TCA_Ridge\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=4930, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.7, degree=4, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"TCA-MLP\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.004, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=70, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-Ridge\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.96, max_iter=1412, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "# DTB - MLP\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-MLP\")\n",
    "# Bruakfilter-MLP\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = model = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(50,50), learning_rate='invscaling', max_iter=96, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': ray_test_data['Files'], 'Actual': ray_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(ray_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04870e-3566-4e15-8adc-f5a1ecd47a94",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cd7d81d8-4c3d-4fbd-b8c4-da48a73cf9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data1 = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, transformers_test_data1\n",
    "\n",
    "\n",
    "def data_loading_lt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data1 = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, transformers_test_data1\n",
    "\n",
    "def data_loading_rt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data1 = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, transformers_test_data1\n",
    "\n",
    "def data_loading_yt():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    transformers_2_0 = pd.read_csv('../transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_test_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data1 = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "    Y_source = yolov5_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, transformers_test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3e17cf6e-ec64-4415-8692-2da0c3af1f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transformers's ML files:  (1210, 1)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "TCA-CART\n",
      "Number of total correctly predicted defect-prone files: 214\n",
      "Number of total incorrectly predicted defect-prone files: 139\n",
      "Number of correctly predicted defect-prone ML files: 161\n",
      "Number of incorrectly predicted defect-prone ML files: 99\n",
      "Number of correctly predicted defect-prone Non-ML files: 53\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 40\n",
      "*******************************************************************************\n",
      "TCA-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 169\n",
      "Number of total incorrectly predicted defect-prone files: 4\n",
      "Number of correctly predicted defect-prone ML files: 119\n",
      "Number of incorrectly predicted defect-prone ML files: 2\n",
      "Number of correctly predicted defect-prone Non-ML files: 50\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 2\n",
      "*******************************************************************************\n",
      "Peterfilter-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Universal-Ridge\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 244\n",
      "Number of total incorrectly predicted defect-prone files: 22\n",
      "Number of correctly predicted defect-prone ML files: 188\n",
      "Number of incorrectly predicted defect-prone ML files: 15\n",
      "Number of correctly predicted defect-prone Non-ML files: 56\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 7\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 72\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 32\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 40\n",
      "*******************************************************************************\n",
      "Peterfilter - NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 9\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 4\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 5\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "transformers_ml = pd.read_csv('../Dataset_ML_Files/transformers_ml_files.csv')\n",
    "len_transformers_ml = transformers_ml.shape\n",
    "print(\"Number of Transformers's ML files: \", len_transformers_ml)\n",
    "X_source, Y_source, X_target, Y_target, transformers_test_data = data_loading_jt()\n",
    "\n",
    "# TCA-CART\n",
    "print(\"TCA-CART\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=8, max_features='sqrt', min_samples_split=6, splitter='best', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA-RandomForest\")\n",
    "#TCA_RandomForest\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=2, max_features='sqrt', min_samples_leaf=2, min_samples_split=0.59, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-RandomForest\")\n",
    "# Peterfilter-RandomForest\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth=4, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.2, n_estimators=7, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-Ridge\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model= RidgeClassifier(alpha=0.99, max_iter=7048, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-NaiveBayes\")\n",
    "# DSBF-NaiveBayes\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.0006, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter - NaiveBayes\")\n",
    "# Peterfilter - Naive Bayes\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=3871, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-SVM\")\n",
    "# DTB - SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.76, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "75891e8d-b967-45b3-9d32-5954a583fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transformers's ML files:  (1210, 1)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "TCA-CART\n",
      "Number of total correctly predicted defect-prone files: 249\n",
      "Number of total incorrectly predicted defect-prone files: 1092\n",
      "Number of correctly predicted defect-prone ML files: 188\n",
      "Number of incorrectly predicted defect-prone ML files: 512\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 580\n",
      "*******************************************************************************\n",
      "TCA-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 225\n",
      "Number of total incorrectly predicted defect-prone files: 116\n",
      "Number of correctly predicted defect-prone ML files: 169\n",
      "Number of incorrectly predicted defect-prone ML files: 62\n",
      "Number of correctly predicted defect-prone Non-ML files: 56\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 54\n",
      "*******************************************************************************\n",
      "Peterfilter-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Universal-Ridge\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter - NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "transformers_ml = pd.read_csv('../Dataset_ML_Files/transformers_ml_files.csv')\n",
    "len_transformers_ml = transformers_ml.shape\n",
    "print(\"Number of Transformers's ML files: \", len_transformers_ml)\n",
    "X_source, Y_source, X_target, Y_target, transformers_test_data = data_loading_lt()\n",
    "\n",
    "# TCA-CART\n",
    "print(\"TCA-CART\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=8, max_features='sqrt', min_samples_split=6, splitter='best', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA-RandomForest\")\n",
    "#TCA_RandomForest\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=2, max_features='sqrt', min_samples_leaf=2, min_samples_split=0.59, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-RandomForest\")\n",
    "# Peterfilter-RandomForest\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth=4, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.2, n_estimators=7, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-Ridge\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model= RidgeClassifier(alpha=0.99, max_iter=7048, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-NaiveBayes\")\n",
    "# DSBF-NaiveBayes\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.0006, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter - NaiveBayes\")\n",
    "# Peterfilter - Naive Bayes\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=3871, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-SVM\")\n",
    "# DTB - SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.76, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c5484b6c-7966-485b-941c-85e310d2f1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transformers's ML files:  (1210, 1)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "TCA-CART\n",
      "Number of total correctly predicted defect-prone files: 246\n",
      "Number of total incorrectly predicted defect-prone files: 360\n",
      "Number of correctly predicted defect-prone ML files: 186\n",
      "Number of incorrectly predicted defect-prone ML files: 218\n",
      "Number of correctly predicted defect-prone Non-ML files: 60\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 142\n",
      "*******************************************************************************\n",
      "TCA-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 193\n",
      "Number of total incorrectly predicted defect-prone files: 19\n",
      "Number of correctly predicted defect-prone ML files: 141\n",
      "Number of incorrectly predicted defect-prone ML files: 10\n",
      "Number of correctly predicted defect-prone Non-ML files: 52\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 9\n",
      "*******************************************************************************\n",
      "Peterfilter-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Universal-Ridge\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter - NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "transformers_ml = pd.read_csv('../Dataset_ML_Files/transformers_ml_files.csv')\n",
    "len_transformers_ml = transformers_ml.shape\n",
    "print(\"Number of Transformers's ML files: \", len_transformers_ml)\n",
    "X_source, Y_source, X_target, Y_target, transformers_test_data = data_loading_rt()\n",
    "\n",
    "# TCA-CART\n",
    "print(\"TCA-CART\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=8, max_features='sqrt', min_samples_split=6, splitter='best', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA-RandomForest\")\n",
    "#TCA_RandomForest\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=2, max_features='sqrt', min_samples_leaf=2, min_samples_split=0.59, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-RandomForest\")\n",
    "# Peterfilter-RandomForest\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth=4, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.2, n_estimators=7, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-Ridge\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model= RidgeClassifier(alpha=0.99, max_iter=7048, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-NaiveBayes\")\n",
    "# DSBF-NaiveBayes\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.0006, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter - NaiveBayes\")\n",
    "# Peterfilter - Naive Bayes\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=3871, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-SVM\")\n",
    "# DTB - SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.76, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "faf35446-af4b-4223-9226-c158f895f288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transformers's ML files:  (1210, 1)\n",
      "(103, 17)\n",
      "(103,)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "TCA-CART\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 3576\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 1673\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1903\n",
      "*******************************************************************************\n",
      "TCA-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 3566\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 1674\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1892\n",
      "*******************************************************************************\n",
      "Peterfilter-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 962\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 691\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 271\n",
      "*******************************************************************************\n",
      "Universal-Ridge\n",
      "Number of total correctly predicted defect-prone files: 248\n",
      "Number of total incorrectly predicted defect-prone files: 323\n",
      "Number of correctly predicted defect-prone ML files: 189\n",
      "Number of incorrectly predicted defect-prone ML files: 194\n",
      "Number of correctly predicted defect-prone Non-ML files: 59\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 129\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 1491\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 615\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 876\n",
      "*******************************************************************************\n",
      "DTB-MLP\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter - NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 1089\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 784\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 305\n",
      "*******************************************************************************\n",
      "TCA-Ridge\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 2442\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 1413\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1029\n",
      "*******************************************************************************\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 252\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 191\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 61\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "transformers_ml = pd.read_csv('../Dataset_ML_Files/transformers_ml_files.csv')\n",
    "len_transformers_ml = transformers_ml.shape\n",
    "print(\"Number of Transformers's ML files: \", len_transformers_ml)\n",
    "X_source, Y_source, X_target, Y_target, transformers_test_data = data_loading_yt()\n",
    "\n",
    "# TCA-CART\n",
    "print(\"TCA-CART\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=8, max_features='sqrt', min_samples_split=6, splitter='best', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"TCA-RandomForest\")\n",
    "#TCA_RandomForest\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=2, max_features='sqrt', min_samples_leaf=2, min_samples_split=0.59, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-RandomForest\")\n",
    "# Peterfilter-RandomForest\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RandomForestClassifier(criterion='entropy', max_depth=4, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.2, n_estimators=7, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal-Ridge\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model= RidgeClassifier(alpha=0.99, max_iter=7048, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-NaiveBayes\")\n",
    "# DSBF-NaiveBayes\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-MLP\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = MLPClassifier(activation='identity', alpha=0.0006, hidden_layer_sizes=(50,50), learning_rate='adaptive', max_iter=98, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter - NaiveBayes\")\n",
    "# Peterfilter - Naive Bayes\n",
    "peterfilter = peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"TCA-Ridge\")\n",
    "tca = TCA()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = tca.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.99, max_iter=3871, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DTB-SVM\")\n",
    "# DTB - SVM\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.76, degree=2, kernel='linear', random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': transformers_test_data['Files'], 'Actual': transformers_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(transformers_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bd6ed-d838-46f8-9b11-50dc095c9dbd",
   "metadata": {},
   "source": [
    "## Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fe8c2633-a5d9-4248-88c1-24c73c14b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_jy():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "    jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "    jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "    jax_3_15 = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "    \n",
    "    \n",
    "    jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28, jax_3_15])\n",
    "    jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data1 = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = jax_train_data.drop(columns='Buggy')\n",
    "    Y_source = jax_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, yolov5_test_data1\n",
    "\n",
    "def data_loading_ly():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "    lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "    lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "    lightning_1_8 = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "    \n",
    "    \n",
    "    lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5, lightning_1_8])\n",
    "    lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data1 = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = lightning_train_data.drop(columns='Buggy')\n",
    "    Y_source = lightning_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, yolov5_test_data1\n",
    "\n",
    "def data_loading_ry():\n",
    "    # Load your dataset (replace X and y with your features and labels)    \n",
    "    ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "    ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "    ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "    ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "    ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "    ray_2_0 = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "    \n",
    "    ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9, ray_2_0])\n",
    "    ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data1 = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = ray_train_data.drop(columns='Buggy')\n",
    "    Y_source = ray_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, yolov5_test_data1\n",
    "\n",
    "def data_loading_ty():\n",
    "    # Load your dataset (replace X and y with your features and labels)\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    transformers_4_23 = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "    \n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13, transformers_4_23])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "    yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "    yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "    \n",
    "    yolov5_test_data = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data1 = pd.concat([yolov5_4_0, yolov5_6_0, yolov5_7_0])\n",
    "    yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "    \n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "    Y_target = yolov5_test_data['Buggy']\n",
    "    \n",
    "    print(X_source.shape)\n",
    "    print(Y_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(Y_target.shape)\n",
    "    X_source = X_source.to_numpy()\n",
    "    X_target = X_target.to_numpy()\n",
    "    Y_source = Y_source.to_numpy()\n",
    "    Y_target = Y_target.to_numpy()\n",
    "    return X_source, Y_source, X_target, Y_target, yolov5_test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b8ecb141-09cb-4aca-a9b0-dd74ed878d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Yolov5's ML files:  (30, 1)\n",
      "(1266, 17)\n",
      "(1266,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 20\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 6\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 14\n",
      "*******************************************************************************\n",
      "DS-NB\n",
      "Number of total correctly predicted defect-prone files: 28\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 23\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 5\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 43\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 35\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 8\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Peterfilter-SVM\n",
      "Number of total correctly predicted defect-prone files: 63\n",
      "Number of total incorrectly predicted defect-prone files: 2\n",
      "Number of correctly predicted defect-prone ML files: 50\n",
      "Number of incorrectly predicted defect-prone ML files: 1\n",
      "Number of correctly predicted defect-prone Non-ML files: 13\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "Universal Adaboost\n",
      "Number of total correctly predicted defect-prone files: 48\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 39\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 9\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 3\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 3\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 0\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter-Ridge\n",
      "Number of total correctly predicted defect-prone files: 48\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 39\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 9\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "yolov5_ml = pd.read_csv('../Dataset_ML_Files/yolov5_ml_files.csv')\n",
    "len_yolov5_ml = yolov5_ml.shape\n",
    "print(\"Number of Yolov5's ML files: \", len_yolov5_ml)\n",
    "X_source, Y_source, X_target, Y_target, yolov5_test_data = data_loading_jy()\n",
    "\n",
    "# DTB-SVM\n",
    "print(\"DTB-SVM\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.56, degree=1, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DS-NB\")\n",
    "#DS-NB\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.0002, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-Ridge\")\n",
    "# DSBF-Ridge\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(aplha=0.99, max_iter=4020, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.45, degree=4, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal Adaboost\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.39, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-RandomForest\")\n",
    "# DS-RandomForest\n",
    "ds = DataSelection()\n",
    "loc=[0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.1, n_estimators=44)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"DTB-NaiveBayes\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-Ridge\")\n",
    "# Peterfilter-Ridge\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.9, max_iter=3077, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5df096b-c472-4c0a-bca5-fe0fe3a6ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Yolov5's ML files:  (30, 1)\n",
      "(1820, 17)\n",
      "(1820,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 52\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 41\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 11\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-NB\n",
      "Number of total correctly predicted defect-prone files: 72\n",
      "Number of total incorrectly predicted defect-prone files: 4\n",
      "Number of correctly predicted defect-prone ML files: 53\n",
      "Number of incorrectly predicted defect-prone ML files: 1\n",
      "Number of correctly predicted defect-prone Non-ML files: 19\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 3\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 63\n",
      "Number of total incorrectly predicted defect-prone files: 11\n",
      "Number of correctly predicted defect-prone ML files: 49\n",
      "Number of incorrectly predicted defect-prone ML files: 2\n",
      "Number of correctly predicted defect-prone Non-ML files: 14\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 9\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Peterfilter-SVM\n",
      "Number of total correctly predicted defect-prone files: 67\n",
      "Number of total incorrectly predicted defect-prone files: 15\n",
      "Number of correctly predicted defect-prone ML files: 50\n",
      "Number of incorrectly predicted defect-prone ML files: 10\n",
      "Number of correctly predicted defect-prone Non-ML files: 17\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 5\n",
      "*******************************************************************************\n",
      "Universal Adaboost\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter-Ridge\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "yolov5_ml = pd.read_csv('../Dataset_ML_Files/yolov5_ml_files.csv')\n",
    "len_yolov5_ml = yolov5_ml.shape\n",
    "print(\"Number of Yolov5's ML files: \", len_yolov5_ml)\n",
    "X_source, Y_source, X_target, Y_target, yolov5_test_data = data_loading_ly()\n",
    "\n",
    "# DTB-SVM\n",
    "print(\"DTB-SVM\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.56, degree=1, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DS-NB\")\n",
    "#DS-NB\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.0002, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-Ridge\")\n",
    "# DSBF-Ridge\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(aplha=0.99, max_iter=4020, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.45, degree=4, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal Adaboost\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.39, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-RandomForest\")\n",
    "# DS-RandomForest\n",
    "ds = DataSelection()\n",
    "loc=[0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.1, n_estimators=44)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"DTB-NaiveBayes\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-Ridge\")\n",
    "# Peterfilter-Ridge\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.9, max_iter=3077, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "99787d2a-e23e-4acc-9cfd-0048568e85ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Yolov5's ML files:  (30, 1)\n",
      "(3839, 17)\n",
      "(3839,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 25\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 22\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 3\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "DS-NB\n",
      "Number of total correctly predicted defect-prone files: 43\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 35\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 8\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 42\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 32\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 10\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Peterfilter-SVM\n",
      "Number of total correctly predicted defect-prone files: 4\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 3\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 1\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "Universal Adaboost\n",
      "Number of total correctly predicted defect-prone files: 48\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 39\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 9\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 48\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 39\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 9\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 48\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 39\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 9\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter-Ridge\n",
      "Number of total correctly predicted defect-prone files: 48\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 39\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 9\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "yolov5_ml = pd.read_csv('../Dataset_ML_Files/yolov5_ml_files.csv')\n",
    "len_yolov5_ml = yolov5_ml.shape\n",
    "print(\"Number of Yolov5's ML files: \", len_yolov5_ml)\n",
    "X_source, Y_source, X_target, Y_target, yolov5_test_data = data_loading_ty()\n",
    "\n",
    "# DTB-SVM\n",
    "print(\"DTB-SVM\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.56, degree=1, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DS-NB\")\n",
    "#DS-NB\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.0002, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-Ridge\")\n",
    "# DSBF-Ridge\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(aplha=0.99, max_iter=4020, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.45, degree=4, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal Adaboost\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.39, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-RandomForest\")\n",
    "# DS-RandomForest\n",
    "ds = DataSelection()\n",
    "loc=[0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.1, n_estimators=44)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"DTB-NaiveBayes\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-Ridge\")\n",
    "# Peterfilter-Ridge\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.9, max_iter=3077, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fca6480c-5216-4752-bf4d-af11a6b1637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Yolov5's ML files:  (30, 1)\n",
      "(6778, 17)\n",
      "(6778,)\n",
      "(103, 17)\n",
      "(103,)\n",
      "DTB-SVM\n",
      "Number of total correctly predicted defect-prone files: 61\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 45\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 16\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "DS-NB\n",
      "Number of total correctly predicted defect-prone files: 72\n",
      "Number of total incorrectly predicted defect-prone files: 1\n",
      "Number of correctly predicted defect-prone ML files: 53\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 19\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 1\n",
      "*******************************************************************************\n",
      "Bruakfilter-KNN\n",
      "Number of total correctly predicted defect-prone files: 65\n",
      "Number of total incorrectly predicted defect-prone files: 11\n",
      "Number of correctly predicted defect-prone ML files: 48\n",
      "Number of incorrectly predicted defect-prone ML files: 2\n",
      "Number of correctly predicted defect-prone Non-ML files: 17\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 9\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Universal Adaboost\n",
      "Number of total correctly predicted defect-prone files: 55\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 44\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 11\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DS-RandomForest\n",
      "Number of total correctly predicted defect-prone files: 55\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 44\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 11\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "DTB-NaiveBayes\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 0\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 0\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 0\n",
      "*******************************************************************************\n",
      "Peterfilter-Ridge\n",
      "Number of total correctly predicted defect-prone files: 74\n",
      "Number of total incorrectly predicted defect-prone files: 29\n",
      "Number of correctly predicted defect-prone ML files: 54\n",
      "Number of incorrectly predicted defect-prone ML files: 12\n",
      "Number of correctly predicted defect-prone Non-ML files: 20\n",
      "Number of incorrectly predicted defect-prone Non-ML files: 17\n",
      "*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "yolov5_ml = pd.read_csv('../Dataset_ML_Files/yolov5_ml_files.csv')\n",
    "len_yolov5_ml = yolov5_ml.shape\n",
    "print(\"Number of Yolov5's ML files: \", len_yolov5_ml)\n",
    "X_source, Y_source, X_target, Y_target, yolov5_test_data = data_loading_ry()\n",
    "\n",
    "# DTB-SVM\n",
    "print(\"DTB-SVM\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=0.56, degree=1, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"DS-NB\")\n",
    "#DS-NB\n",
    "ds = DataSelection()\n",
    "loc = [0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1,Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Bruakfilter-KNN\")\n",
    "# Bruakfilter-KNN\n",
    "bruakfilter = Bruakfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = bruakfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = KNeighborsClassifier(algorithm='brute', n_neighbors=6)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-MLP\")\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model= MLPClassifier(activation='relu', alpha=0.0002, hidden_layer_sizes=(100,), learning_rate='invscaling', max_iter=99, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DSBF-Ridge\")\n",
    "# DSBF-Ridge\n",
    "dsbf = DSBF()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dsbf.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(aplha=0.99, max_iter=4020, solver='saga')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-SVM\")\n",
    "# Peterfilter-SVM\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = SVC(C=1.45, degree=1, kernel='linear')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Universal Adaboost\")\n",
    "universal = Universal()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = universal.run(X_source, Y_source, X_target, Y_target)\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.39, n_estimators=18, random_state=42)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"DS-RandomForest\")\n",
    "# DS-RandomForest\n",
    "ds = DataSelection()\n",
    "loc=[0]\n",
    "X_source1, Y_source1, X_target1, Y_target1 = ds.run(X_source, Y_source, X_target, Y_target, loc)\n",
    "model = RandomForestClassifier(criterion='gini', max_depth=3, max_features='sqrt', min_samples_leaf=1, min_samples_split=0.1, n_estimators=44)\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "\n",
    "print(\"DTB-NaiveBayes\")\n",
    "dtb = DTB()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = dtb.run(X_source, Y_source, X_target, Y_target)\n",
    "model = GaussianNB()\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n",
    "print(\"Peterfilter-Ridge\")\n",
    "# Peterfilter-Ridge\n",
    "peterfilter = Peterfilter()\n",
    "X_source1, Y_source1, X_target1, Y_target1 = peterfilter.run(X_source, Y_source, X_target, Y_target)\n",
    "model = RidgeClassifier(alpha=0.9, max_iter=3077, solver='sparse_cg')\n",
    "model.fit(X_source1, Y_source1)\n",
    "y_pred = model.predict(X_target1)\n",
    "# Assuming 'files_column' is the column containing file names or identifiers\n",
    "results = pd.DataFrame({'File': yolov5_test_data['Files'], 'Actual': yolov5_test_data['Buggy'], 'Prediction': y_pred})\n",
    "\n",
    "# Identify correct and incorrect predictions for all defect-prone files\n",
    "correct_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 1)]\n",
    "incorrect_predictions = results[(results['Prediction'] == 1) & (results['Actual'] == 0)]\n",
    "\n",
    "# Identify correct and incorrect predictions for ML files\n",
    "correct_ml_predictions = correct_predictions[correct_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "incorrect_ml_predictions = incorrect_predictions[incorrect_predictions['File'].isin(yolov5_ml['ML Files'])]\n",
    "\n",
    "# Example: Count of correctly and incorrectly predicted defect-prone ML files\n",
    "num_correct_ml_defects = len(correct_ml_predictions)\n",
    "num_incorrect_ml_defects = len(incorrect_ml_predictions)\n",
    "\n",
    "print(f\"Number of total correctly predicted defect-prone files: {len(correct_predictions)}\")\n",
    "print(f\"Number of total incorrectly predicted defect-prone files: {len(incorrect_predictions)}\")\n",
    "print(f\"Number of correctly predicted defect-prone ML files: {num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone ML files: {num_incorrect_ml_defects}\")\n",
    "print(f\"Number of correctly predicted defect-prone Non-ML files: {len(correct_predictions)- num_correct_ml_defects}\")\n",
    "print(f\"Number of incorrectly predicted defect-prone Non-ML files: {len(incorrect_predictions)- num_incorrect_ml_defects}\")\n",
    "print(\"*******************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3b787-b822-4b87-81ed-e8034de6e613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
