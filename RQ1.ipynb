{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e5ea8-1cc2-4941-bff1-892a479a7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268eac5-85c4-40a8-917a-413128d99220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for each classifier\n",
    "rf_space = {\n",
    "    'n_estimators': hp.randint('n_estimators', 1, 50),\n",
    "    'max_depth': hp.randint('max_depth',1,10),\n",
    "    'min_samples_split':hp.uniform('min_samples_split', 0, 1),\n",
    "    'min_samples_leaf':hp.randint('min_samples_leaf',1,10),\n",
    "    'criterion':hp.choice('criterion',['gini','entropy']),\n",
    "    'max_features':hp.choice('max_features',['sqrt','log2'])\n",
    "}\n",
    "\n",
    "ada_space = {\n",
    "    'n_estimators': hp.randint('n_estimators', 1, 50),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 1.0),\n",
    "    'algorithm': hp.choice('algorithm', ['SAMME', 'SAMME.R'])\n",
    "}\n",
    "\n",
    "nb_space = {\n",
    "    'var_smoothing': hp.choice('var_smoothing', [1e-09])\n",
    "}\n",
    "\n",
    "cart_space = {\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "    'max_features': hp.choice('max_features', [None, 'sqrt', 'log2']),\n",
    "    'splitter': hp.choice('splitter', ['best', 'random']),\n",
    "    'max_depth': hp.randint('max_depth',1,10),\n",
    "    'min_samples_split': hp.randint('min_samples_split', 2, 10)\n",
    "}\n",
    "\n",
    "knn_space = {\n",
    "    'n_neighbors': hp.randint('n_neighbors', 5, 20),\n",
    "    'algorithm': hp.choice('algorithm', ['ball_tree', 'kd_tree', 'brute'])\n",
    "}\n",
    "\n",
    "ridge_space = {\n",
    "    'alpha': hp.uniform('alpha', 0.1, 1.0),\n",
    "    'solver': hp.choice('solver', ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']),\n",
    "    'max_iter': hp.randint('max_iter', 1000,15000)\n",
    "}\n",
    "\n",
    "svm_space = {\n",
    "    'C': hp.lognormal('C', 0.1, 1.0),\n",
    "    # 'kernel': hp.choice('kernel', ['linear', 'rbf', 'poly', 'sigmoid']),\n",
    "    'kernel': hp.choice('kernel', ['linear']),\n",
    "    'degree': hp.randint('degree', 1,5),\n",
    "    #'gamma': hp.choice('gamma', ['scale', 'auto'])\n",
    "}\n",
    "\n",
    "mlp_space = {\n",
    "    'activation': hp.choice('activation', ['identity', 'logistic', 'tanh', 'relu']),\n",
    "    'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(50,), (100,), (50, 50)]),\n",
    "    'alpha': hp.uniform('alpha', 0.0001, 0.01),\n",
    "    'learning_rate': hp.choice('learning_rate', ['constant', 'invscaling', 'adaptive']),\n",
    "    'max_iter': hp.randint('max_iter', 10, 100)\n",
    "}\n",
    "\n",
    "# Create a dictionary mapping classifiers to their search spaces\n",
    "classifiers = {\n",
    "    'RandomForest': (RandomForestClassifier, rf_space),\n",
    "    'AdaBoost': (AdaBoostClassifier, ada_space),\n",
    "    'NaiveBayes': (GaussianNB, nb_space),\n",
    "    'DecisionTree': (DecisionTreeClassifier, cart_space),\n",
    "    'KNN': (KNeighborsClassifier, knn_space),\n",
    "    'Ridge': (RidgeClassifier, ridge_space),\n",
    "    'SVM': (SVC, svm_space),\n",
    "    'MLP': (MLPClassifier, mlp_space),\n",
    "}\n",
    "\n",
    "algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a37a3-efbc-4250-91d1-c56a1c825d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset files for each ML project by specifying correct path\n",
    "def data_loading_transformers():\n",
    "    transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "    transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "    transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "    \n",
    "    transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13])\n",
    "    transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    transformers_test_data = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "  # test_data1 = pd.read_csv('transformers_4.23.0.csv')\n",
    "  # ml_files = pd.read_csv('transformers_ml_files.csv')\n",
    "    transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "    X_source = transformers_train_data.drop(columns='Buggy')\n",
    "    Y_source = transformers_train_data['Buggy']\n",
    "    X_target = transformers_test_data.drop(columns='Buggy')\n",
    "    Y_target = transformers_test_data['Buggy']\n",
    "    \n",
    "    return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_yolov5():\n",
    "  yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "  yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "  \n",
    "\n",
    "  yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0])\n",
    "  yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  yolov5_test_data = yolov5_7_0 = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "  # test_data1 = pd.read_csv('yolov5_7.0.csv')\n",
    "  # ml_files = pd.read_csv('yolov5_ml_files.csv')\n",
    "  yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "  X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "  Y_source = yolov5_train_data['Buggy']\n",
    "  X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "  Y_target = yolov5_test_data['Buggy']\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_jax():\n",
    "  jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "  jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv') \n",
    "  jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "  \n",
    "  jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28])\n",
    "  jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  jax_test_data = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "  # test_data1 = pd.read_csv('jax_0.3.15.csv')\n",
    "  # ml_files = pd.read_csv('jax_ml_files.csv')\n",
    "  jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "  #jax_test_data.shape\n",
    "\n",
    "  X_source = jax_train_data.drop(columns='Buggy')\n",
    "  Y_source = jax_train_data['Buggy']\n",
    "  X_target = jax_test_data.drop(columns='Buggy')\n",
    "  Y_target = jax_test_data['Buggy']\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  print(X_source.shape)\n",
    "  print(Y_source.shape)\n",
    "  print(X_target.shape)\n",
    "  print(Y_target.shape)\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_lightning():\n",
    "  lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "  lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "  lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv') \n",
    "  \n",
    "\n",
    "  lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5])\n",
    "  lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  lightning_test_data = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "  # test_data1 = pd.read_csv('lightning_1.8.0.csv')\n",
    "  # ml_files = pd.read_csv('lightning_ml_files.csv')\n",
    "  lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "  X_source = lightning_train_data.drop(columns='Buggy')\n",
    "  Y_source = lightning_train_data['Buggy']\n",
    "  X_target = lightning_test_data.drop(columns='Buggy')\n",
    "  Y_target = lightning_test_data['Buggy']\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_ray():\n",
    "  ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "  ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "  ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv') \n",
    "  ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "  ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "  \n",
    "\n",
    "  ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9])\n",
    "  ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  ray_test_data = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "  # test_data1 = pd.read_csv('ray_2.0.0.csv')\n",
    "  # ml_files = pd.read_csv('ray_ml_files.csv')\n",
    "  ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "  X_source = ray_train_data.drop(columns='Buggy')\n",
    "  Y_source = ray_train_data['Buggy']\n",
    "  X_target = ray_test_data.drop(columns='Buggy')\n",
    "  Y_target = ray_test_data['Buggy']\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08397214-cc1a-405e-a9b7-2054d0a3aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for hyperparameter optimization\n",
    "def objective_rf(search_space):\n",
    "    model = RandomForestClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    #print(\"auc: \", roc_auc)\n",
    "    # Record the AUC for this trial\n",
    "    #rf_trials.results.append({'auc': roc_auc, 'params': search_space, 'status': 'ok'})\n",
    "    return -roc_auc\n",
    "\n",
    "def objective_ada(search_space):\n",
    "    model = AdaBoostClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    return -roc_auc\n",
    "\n",
    "def objective_nb(search_space):\n",
    "    model = GaussianNB(**search_space)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    return -roc_auc\n",
    "\n",
    "def objective_cart(search_space):\n",
    "    model = DecisionTreeClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    return -roc_auc\n",
    "\n",
    "def objective_knn(search_space):\n",
    "    model = KNeighborsClassifier(**search_space)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    return -roc_auc\n",
    "\n",
    "def objective_ridge(search_space):\n",
    "    model = RidgeClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    return -roc_auc\n",
    "\n",
    "def objective_mlp(search_space):\n",
    "    model = MLPClassifier(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    return -roc_auc\n",
    "\n",
    "def objective_svm(search_space):\n",
    "    model = SVC(**search_space, random_state=42)\n",
    "    model.fit(X_source, Y_source)\n",
    "    y_pred = model.predict(X_target)\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_target, y_pred)\n",
    "\n",
    "    return -roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf7d9c-fcb9-4a7b-9e41-bd883fb17c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hyperopt_classifier():\n",
    "  #implement Hyperopt on Random Forest\n",
    "  # Create a Trials object to store information about each trial\n",
    "  rf_trials = Trials()\n",
    "  best_params_rf = fmin(\n",
    "      fn=objective_rf,\n",
    "      space=rf_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=rf_trials)\n",
    "  print(\"Random Forest: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_rf = [format(-result['loss'], '.2f') for result in rf_trials.results]\n",
    "  #print(\"AUC values for RandomForest:\", all_auc_values_rf)\n",
    "\n",
    "  #implement Hyperopt on Naive Bayes\n",
    "  nb_trials = Trials()\n",
    "  best_params_nb = fmin(\n",
    "      fn=objective_nb,\n",
    "      space=nb_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=nb_trials)\n",
    "  print(\"Naive Bayes: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_nb = [format(-result['loss'], '.2f') for result in nb_trials.results]\n",
    "  #print(\"AUC values for Naive Bayes:\", all_auc_values_nb)\n",
    "\n",
    "  #implement Hyperopt on AdaBoost\n",
    "  ada_trials = Trials()\n",
    "  best_params_ada = fmin(\n",
    "      fn=objective_ada,\n",
    "      space=ada_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=ada_trials)\n",
    "  print(\"AdaBoost: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_ada = [format(-result['loss'], '.2f') for result in ada_trials.results]\n",
    "  #print(\"AUC values for AdaBoost:\", all_auc_values_ada)\n",
    "\n",
    "  #implement Hyperopt on CART\n",
    "  cart_trials = Trials()\n",
    "  best_params_cart = fmin(\n",
    "      fn=objective_cart,\n",
    "      space=cart_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=cart_trials)\n",
    "  print(\"CART: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_cart = [format(-result['loss'], '.2f') for result in cart_trials.results]\n",
    "\n",
    "  #print(\"AUC values for CART:\", all_auc_values_cart)\n",
    "\n",
    "  #print(\"CART: \", space_eval(cart_space, best_params_cart))\n",
    "\n",
    "  #implement Hyperopt on KNN\n",
    "  knn_trials = Trials()\n",
    "  best_params_knn = fmin(\n",
    "      fn=objective_knn,\n",
    "      space=knn_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=knn_trials)\n",
    "  print(\"KNN: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_knn = [format(-result['loss'], '.2f') for result in knn_trials.results]\n",
    "  #print(\"AUC values for KNN:\", all_auc_values_knn)\n",
    "\n",
    "  # print(\"KNN: \", space_eval(knn_space, best_params_knn))\n",
    "\n",
    "  #implement Hyperopt on Ridge\n",
    "  ridge_trials = Trials()\n",
    "  best_params_ridge = fmin(\n",
    "      fn=objective_ridge,\n",
    "      space=ridge_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=ridge_trials)\n",
    "  print(\"Ridge: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_ridge = [format(-result['loss'], '.2f') for result in ridge_trials.results]\n",
    "  #print(\"AUC values for Ridge:\", all_auc_values_ridge)\n",
    "  # print(\"Ridge: \", space_eval(ridge_space, best_params_ridge))\n",
    "\n",
    "  #implement Hyperopt on MLP\n",
    "  mlp_trials = Trials()\n",
    "  best_params_mlp = fmin(\n",
    "      fn=objective_mlp,\n",
    "      space=mlp_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=mlp_trials)\n",
    "  print(\"MLP: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_mlp = [format(-result['loss'], '.2f') for result in mlp_trials.results]\n",
    "\n",
    "\n",
    "  #print(\"AUC values for MLP:\", all_auc_values_mlp)\n",
    "\n",
    "  # print(\"MLP: \", space_eval(mlp_space, best_params_mlp))\n",
    "  svm_trials = Trials()\n",
    "  best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=10,\n",
    "      trials=svm_trials)\n",
    "  print(\"SVM: \", space_eval(rf_space, best_params_rf))\n",
    "  all_auc_values_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "\n",
    "  #print(\"AUC values for SVM:\", all_auc_values_svm)\n",
    "  #print(\"SVM: \", space_eval(svm_space, best_params_svm))\n",
    "  return all_auc_values_rf, all_auc_values_nb, all_auc_values_ada, all_auc_values_cart, all_auc_values_knn, all_auc_values_ridge, all_auc_values_mlp, all_auc_values_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c173ca-c3fb-4b4d-b359-a17269662981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace X and y with your features and labels)\n",
    "X_source = scaler.fit_transform(X_source)\n",
    "def data_loading_transformers_svm():\n",
    "  transformers_2_0 = pd.read_csv('../Dataset/transformers_2.0.0.csv')\n",
    "  transformers_3_5 = pd.read_csv('../Dataset/transformers_3.5.0.csv')\n",
    "  transformers_4_13 = pd.read_csv('../Dataset/transformers_4.13.0.csv')\n",
    "\n",
    "\n",
    "\n",
    "  transformers_train_data = pd.concat([transformers_2_0, transformers_3_5, transformers_4_13])\n",
    "  transformers_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  transformers_test_data = pd.read_csv('../Dataset/transformers_4.23.0.csv')\n",
    "  # test_data1 = pd.read_csv('transformers_4.23.0.csv')\n",
    "  # ml_files = pd.read_csv('transformers_ml_files.csv')\n",
    "  transformers_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "  X_source = transformers_train_data.drop(columns='Buggy')\n",
    "  X_source = scaler.fit_transform(X_source)\n",
    "  Y_source = transformers_train_data['Buggy']\n",
    "  X_target = transformers_test_data.drop(columns='Buggy')\n",
    "  Y_target = transformers_test_data['Buggy']\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_yolov5_svm():\n",
    "  yolov5_4_0 = pd.read_csv('../Dataset/yolov5_4.0.csv')\n",
    "  yolov5_6_0 = pd.read_csv('../Dataset/yolov5_6.0.csv')\n",
    "\n",
    "  yolov5_train_data = pd.concat([yolov5_4_0, yolov5_6_0])\n",
    "  yolov5_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  yolov5_test_data = pd.read_csv('../Dataset/yolov5_7.0.csv')\n",
    "  # test_data1 = pd.read_csv('yolov5_7.0.csv')\n",
    "  # ml_files = pd.read_csv('yolov5_ml_files.csv')\n",
    "  yolov5_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "  X_source = yolov5_train_data.drop(columns='Buggy')\n",
    "  X_source = scaler.fit_transform(X_source)\n",
    "  Y_source = yolov5_train_data['Buggy']\n",
    "  X_target = yolov5_test_data.drop(columns='Buggy')\n",
    "  Y_target = yolov5_test_data['Buggy']\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_jax_svm():\n",
    "  jax_1_73 = pd.read_csv('../Dataset/jax_0.1.73.csv')\n",
    "  jax_2_21 = pd.read_csv('../Dataset/jax_0.2.21.csv')\n",
    "  jax_2_28 = pd.read_csv('../Dataset/jax_0.2.28.csv')\n",
    "\n",
    "  jax_train_data = pd.concat([jax_1_73, jax_2_21, jax_2_28])\n",
    "  jax_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  jax_test_data = pd.read_csv('../Dataset/jax_0.3.15.csv')\n",
    "  # test_data1 = pd.read_csv('jax_0.3.15.csv')\n",
    "  # ml_files = pd.read_csv('jax_ml_files.csv')\n",
    "  jax_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "  #jax_test_data.shape\n",
    "\n",
    "  X_source = jax_train_data.drop(columns='Buggy')\n",
    "  X_source = scaler.fit_transform(X_source)\n",
    "  Y_source = jax_train_data['Buggy']\n",
    "  X_target = jax_test_data.drop(columns='Buggy')\n",
    "  Y_target = jax_test_data['Buggy']\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_lightning_svm():\n",
    "  lightning_0_5 = pd.read_csv('../Dataset/lightning_0.5.1.csv')\n",
    "  lightning_1_0 = pd.read_csv('../Dataset/lightning_1.0.0.csv')\n",
    "  lightning_1_5 = pd.read_csv('../Dataset/lightning_1.5.0.csv')\n",
    "\n",
    "  lightning_train_data = pd.concat([lightning_0_5, lightning_1_0, lightning_1_5])\n",
    "  lightning_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  lightning_test_data = pd.read_csv('../Dataset/lightning_1.8.0.csv')\n",
    "  # test_data1 = pd.read_csv('lightning_1.8.0.csv')\n",
    "  # ml_files = pd.read_csv('lightning_ml_files.csv')\n",
    "  lightning_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "  X_source = lightning_train_data.drop(columns='Buggy')\n",
    "  X_source = scaler.fit_transform(X_source)\n",
    "  Y_source = lightning_train_data['Buggy']\n",
    "  X_target = lightning_test_data.drop(columns='Buggy')\n",
    "  Y_target = lightning_test_data['Buggy']\n",
    "\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)\n",
    "\n",
    "# Load your dataset (replace X and y with your features and labels)\n",
    "def data_loading_ray_svm():\n",
    "  ray_0_3 = pd.read_csv('../Dataset/ray_0.3.0.csv')\n",
    "  ray_0_6 = pd.read_csv('../Dataset/ray_0.6.1.csv')\n",
    "  ray_0_8 = pd.read_csv('../Dataset/ray_0.8.0.csv')\n",
    "  ray_1_1 = pd.read_csv('../Dataset/ray_1.1.0.csv')\n",
    "  ray_1_9 = pd.read_csv('../Dataset/ray_1.9.0.csv')\n",
    "\n",
    "\n",
    "  ray_train_data = pd.concat([ray_0_3, ray_0_6, ray_0_8, ray_1_1, ray_1_9])\n",
    "  ray_train_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "  ray_test_data = pd.read_csv('../Dataset/ray_2.0.0.csv')\n",
    "  # test_data1 = pd.read_csv('ray_2.0.0.csv')\n",
    "  # ml_files = pd.read_csv('ray_ml_files.csv')\n",
    "  ray_test_data.drop(['Unnamed: 0','Project', 'Files'], axis=1, inplace=True)\n",
    "\n",
    "  X_source = ray_train_data.drop(columns='Buggy')\n",
    "  X_source = scaler.fit_transform(X_source)\n",
    "  Y_source = ray_train_data['Buggy']\n",
    "  X_target = ray_test_data.drop(columns='Buggy')\n",
    "  Y_target = ray_test_data['Buggy']\n",
    "\n",
    "  return X_source, Y_source, X_target, Y_target\n",
    "\n",
    "  # print(X_source.shape)\n",
    "  # print(Y_source.shape)\n",
    "  # print(X_target.shape)\n",
    "  # print(Y_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ba6cc-e918-4807-a672-092ef7f9283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement Hyperopt on SVM\n",
    "def SVM_hyperopt_jax():\n",
    "  X_source, Y_source, X_target, Y_target = data_loading_jax_svm()\n",
    "  svm_trials = Trials()\n",
    "  best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "  print(\"SVM: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "  return all_auc_values_svm\n",
    "\n",
    "def SVM_hyperopt_lightning():\n",
    "  X_source, Y_source, X_target, Y_target = data_loading_lightning_svm()\n",
    "  svm_trials = Trials()\n",
    "  best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "  print(\"SVM: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "  return all_auc_values_svm\n",
    "\n",
    "def SVM_hyperopt_ray():\n",
    "  X_source, Y_source, X_target, Y_target = data_loading_ray_svm()\n",
    "  svm_trials = Trials()\n",
    "  best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "  print(\"SVM: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "  return all_auc_values_svm\n",
    "\n",
    "def SVM_hyperopt_transformers():\n",
    "  X_source, Y_source, X_target, Y_target = data_loading_transformers_svm()\n",
    "  svm_trials = Trials()\n",
    "  best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "  print(\"SVM: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "  return all_auc_values_svm\n",
    "\n",
    "def SVM_hyperopt_yolov5():\n",
    "  X_source, Y_source, X_target, Y_target = data_loading_yolov5_svm()\n",
    "  svm_trials = Trials()\n",
    "  best_params_svm = fmin(\n",
    "      fn=objective_svm,\n",
    "      space=svm_space,\n",
    "      algo=algorithm,\n",
    "      max_evals=50,\n",
    "      trials=svm_trials)\n",
    "  print(\"SVM: \", space_eval(rf_space, best_params_rf))\n",
    "\n",
    "  all_auc_values_svm = [format(-result['loss'], '.2f') for result in svm_trials.results]\n",
    "  return all_auc_values_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f276e-4cbb-4395-83b0-06f7ed88df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def violin_plots(data_jax, data_lightning, data_ray, data_transformers, data_yolov5):\n",
    "  # Create a DataFrame for Seaborn\n",
    "  # data = pd.DataFrame({\n",
    "  #     'Classifier': ['Random Forest'] * len(all_auc_values_rf) +\n",
    "  #                   ['Naive Bayes'] * len(all_auc_values_nb) +\n",
    "  #                   ['AdaBoost'] * len(all_auc_values_ada) +\n",
    "  #                   ['CART'] * len(all_auc_values_cart) +\n",
    "  #                   ['KNN'] * len(all_auc_values_knn) +\n",
    "  #                   ['Ridge'] * len(all_auc_values_ridge) +\n",
    "  #                   ['MLP'] * len(all_auc_values_mlp) ,\n",
    "  #     'ROC AUC': all_auc_values_rf + all_auc_values_nb + all_auc_values_ada + all_auc_values_cart + all_auc_values_knn + all_auc_values_ridge + all_auc_values_mlp\n",
    "  # })\n",
    "\n",
    "  # #print(data)\n",
    "  # data['ROC AUC'] = pd.to_numeric(data['ROC AUC'])\n",
    "\n",
    "  # Create subplots\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(30, 4))\n",
    "\n",
    "  # Plot violin plots\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_jax, ax=axes[0])\n",
    "  axes[0].set_title('Jax')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_lightning, ax=axes[1])\n",
    "  axes[1].set_title('Lightning')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_ray, ax=axes[2])\n",
    "  axes[2].set_title('Ray')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_transformers, ax=axes[3])\n",
    "  axes[3].set_title('Transformers')\n",
    "\n",
    "  sns.violinplot(x='Classifier', y='ROC AUC', data=data_yolov5, ax=axes[4])\n",
    "  axes[4].set_title('Yolov5')\n",
    "\n",
    "\n",
    "  # Tilt x-axis labels\n",
    "  axes[0].tick_params(axis='x', rotation=45)\n",
    "  axes[1].tick_params(axis='x', rotation=45)\n",
    "  axes[2].tick_params(axis='x', rotation=45)\n",
    "  axes[3].tick_params(axis='x', rotation=45)\n",
    "  axes[4].tick_params(axis='x', rotation=45)\n",
    "  plt.savefig('wpdp_results.png', bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06756fb0-d542-4da5-b2f2-b2e09e3fb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jax parameters hyper optimization: \")\n",
    "# for jax\n",
    "X_source, Y_source, X_target, Y_target = data_loading_jax()\n",
    "\n",
    "all_auc_values_rf, all_auc_values_nb, all_auc_values_ada, all_auc_values_cart, all_auc_values_knn, all_auc_values_ridge, all_auc_values_mlp, all_auc_values_svm = hyperopt_classifier()\n",
    "#all_auc_values_svm = SVM_hyperopt_jax()\n",
    "data_jax = pd.DataFrame({\n",
    "      'Classifier': ['Random Forest'] * len(all_auc_values_rf) +\n",
    "                    ['Naive Bayes'] * len(all_auc_values_nb) +\n",
    "                    ['AdaBoost'] * len(all_auc_values_ada) +\n",
    "                    ['CART'] * len(all_auc_values_cart) +\n",
    "                    ['KNN'] * len(all_auc_values_knn) +\n",
    "                    ['Ridge'] * len(all_auc_values_ridge) +\n",
    "                    ['MLP'] * len(all_auc_values_mlp) +\n",
    "                    ['SVM'] * len(all_auc_values_svm),\n",
    "      'ROC AUC': all_auc_values_rf + all_auc_values_nb + all_auc_values_ada + all_auc_values_cart + all_auc_values_knn + all_auc_values_ridge + all_auc_values_mlp + all_auc_values_svm\n",
    "  })\n",
    "\n",
    "data_jax['ROC AUC'] = pd.to_numeric(data_jax['ROC AUC'])\n",
    "\n",
    "print(\"*****************************************************\")\n",
    "\n",
    "print(\"Lightning parameters hyper optimization: \")\n",
    "# for Lightning\n",
    "X_source, Y_source, X_target, Y_target = data_loading_lightning()\n",
    "all_auc_values_rf, all_auc_values_nb, all_auc_values_ada, all_auc_values_cart, all_auc_values_knn, all_auc_values_ridge, all_auc_values_mlp, all_auc_values_svm = hyperopt_classifier()\n",
    "#all_auc_values_svm = SVM_hyperopt_lightning()\n",
    "data_lightning = pd.DataFrame({\n",
    "      'Classifier': ['Random Forest'] * len(all_auc_values_rf) +\n",
    "                    ['Naive Bayes'] * len(all_auc_values_nb) +\n",
    "                    ['AdaBoost'] * len(all_auc_values_ada) +\n",
    "                    ['CART'] * len(all_auc_values_cart) +\n",
    "                    ['KNN'] * len(all_auc_values_knn) +\n",
    "                    ['Ridge'] * len(all_auc_values_ridge) +\n",
    "                    ['MLP'] * len(all_auc_values_mlp) +\n",
    "                    ['SVM'] * len(all_auc_values_svm),\n",
    "      'ROC AUC': all_auc_values_rf + all_auc_values_nb + all_auc_values_ada + all_auc_values_cart + all_auc_values_knn + all_auc_values_ridge + all_auc_values_mlp + all_auc_values_svm\n",
    "  })\n",
    "\n",
    "data_lightning['ROC AUC'] = pd.to_numeric(data_lightning['ROC AUC'])\n",
    "\n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"Ray parameters hyper optimization: \")\n",
    "# for Ray\n",
    "X_source, Y_source, X_target, Y_target = data_loading_ray()\n",
    "all_auc_values_rf, all_auc_values_nb, all_auc_values_ada, all_auc_values_cart, all_auc_values_knn, all_auc_values_ridge, all_auc_values_mlp, all_auc_values_svm = hyperopt_classifier()\n",
    "#all_auc_values_svm = SVM_hyperopt_ray()\n",
    "data_ray = pd.DataFrame({\n",
    "      'Classifier': ['Random Forest'] * len(all_auc_values_rf) +\n",
    "                    ['Naive Bayes'] * len(all_auc_values_nb) +\n",
    "                    ['AdaBoost'] * len(all_auc_values_ada) +\n",
    "                    ['CART'] * len(all_auc_values_cart) +\n",
    "                    ['KNN'] * len(all_auc_values_knn) +\n",
    "                    ['Ridge'] * len(all_auc_values_ridge) +\n",
    "                    ['MLP'] * len(all_auc_values_mlp) +\n",
    "                    ['SVM'] * len(all_auc_values_svm),\n",
    "      'ROC AUC': all_auc_values_rf + all_auc_values_nb + all_auc_values_ada + all_auc_values_cart + all_auc_values_knn + all_auc_values_ridge + all_auc_values_mlp + all_auc_values_svm\n",
    "  })\n",
    "\n",
    "data_ray['ROC AUC'] = pd.to_numeric(data_ray['ROC AUC'])\n",
    "\n",
    "print(\"***********************************************************\")\n",
    "\n",
    "print(\"Transformers parameters hyper optimization: \")\n",
    "X_source, Y_source, X_target, Y_target = data_loading_transformers()\n",
    "all_auc_values_rf, all_auc_values_nb, all_auc_values_ada, all_auc_values_cart, all_auc_values_knn, all_auc_values_ridge, all_auc_values_mlp, all_auc_values_svm = hyperopt_classifier()\n",
    "#all_auc_values_svm = SVM_hyperopt_transformers()\n",
    "data_transformers = pd.DataFrame({\n",
    "      'Classifier': ['Random Forest'] * len(all_auc_values_rf) +\n",
    "                    ['Naive Bayes'] * len(all_auc_values_nb) +\n",
    "                    ['AdaBoost'] * len(all_auc_values_ada) +\n",
    "                    ['CART'] * len(all_auc_values_cart) +\n",
    "                    ['KNN'] * len(all_auc_values_knn) +\n",
    "                    ['Ridge'] * len(all_auc_values_ridge) +\n",
    "                    ['MLP'] * len(all_auc_values_mlp) +\n",
    "                    ['SVM'] * len(all_auc_values_svm),\n",
    "      'ROC AUC': all_auc_values_rf + all_auc_values_nb + all_auc_values_ada + all_auc_values_cart + all_auc_values_knn + all_auc_values_ridge + all_auc_values_mlp + all_auc_values_svm\n",
    "  })\n",
    "data_transformers['ROC AUC'] = pd.to_numeric(data_transformers['ROC AUC'])\n",
    "\n",
    "print(\"*************************************************************\")\n",
    "\n",
    "print(\"Yolov5 parameters hyper optimization: \")\n",
    "# for yolov5\n",
    "X_source, Y_source, X_target, Y_target = data_loading_yolov5()\n",
    "all_auc_values_rf, all_auc_values_nb, all_auc_values_ada, all_auc_values_cart, all_auc_values_knn, all_auc_values_ridge, all_auc_values_mlp, all_auc_values_svm = hyperopt_classifier()\n",
    "#all_auc_values_svm = SVM_hyperopt_yolov5()\n",
    "data_yolov5 = pd.DataFrame({\n",
    "      'Classifier': ['Random Forest'] * len(all_auc_values_rf) +\n",
    "                    ['Naive Bayes'] * len(all_auc_values_nb) +\n",
    "                    ['AdaBoost'] * len(all_auc_values_ada) +\n",
    "                    ['CART'] * len(all_auc_values_cart) +\n",
    "                    ['KNN'] * len(all_auc_values_knn) +\n",
    "                    ['Ridge'] * len(all_auc_values_ridge) +\n",
    "                    ['MLP'] * len(all_auc_values_mlp) +\n",
    "                    ['SVM'] * len(all_auc_values_svm),\n",
    "      'ROC AUC': all_auc_values_rf + all_auc_values_nb + all_auc_values_ada + all_auc_values_cart + all_auc_values_knn + all_auc_values_ridge + all_auc_values_mlp + all_auc_values_svm\n",
    "  })\n",
    "\n",
    "data_yolov5['ROC AUC'] = pd.to_numeric(data_yolov5['ROC AUC'])\n",
    "\n",
    "violin_plots(data_jax, data_lightning, data_ray, data_transformers, data_yolov5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
